{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "## Adding libs"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import tqdm\n",
    "import re\n",
    "import tqdm\n",
    "import sys\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from keras.utils import np_utils\n",
    "from keras.models import load_model\n",
    "import tensorflow as tf\n",
    "from IPython.display import clear_output\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from keras.callbacks import LambdaCallback\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "import re\n",
    "from data_loader import BooksDataLoader\n",
    "from model.rnn import MultiLSTMModel\n",
    "import gc\n",
    "from tensorflow.keras import backend as k"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Config GPU"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-14 14:22:24.189512: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-05-14 14:22:24.241978: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-05-14 14:22:24.247944: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-05-14 14:22:24.248187: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-05-14 14:22:24.652474: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-05-14 14:22:24.652707: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-05-14 14:22:24.652939: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-05-14 14:22:24.653062: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 3318 MB memory:  -> device: 0, name: NVIDIA GeForce GTX 1650, pci bus id: 0000:01:00.0, compute capability: 7.5\n"
     ]
    }
   ],
   "source": [
    "# from tensorflow.compat.v1 import ConfigProto\n",
    "# from tensorflow.compat.v1 import InteractiveSession\n",
    "# config = ConfigProto()\n",
    "# config.gpu_options.allow_growth = True\n",
    "# session = InteractiveSession(config=config)\n",
    "# config = tf.compat.v1.ConfigProto()\n",
    "# config.gpu_options.per_process_gpu_memory_fraction = 0.8\n",
    "# # physical_devices = tf.config.experimental.list_physical_devices('GPU')\n",
    "# # config = tf.config.experimental.set_memory_growth(physical_devices[0], True)\n",
    "# tf.compat.v1.Session(config=config)\n",
    "#\n",
    "# os.environ['TF_GPU_ALLOCATOR'] = 'cuda_malloc_async'\n",
    "# print(os.getenv('TF_GPU_ALLOCATOR'))\n",
    "config = tf.compat.v1.ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "config.gpu_options.per_process_gpu_memory_fraction = 0.85\n",
    "session = tf.compat.v1.Session(config=config)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Loading data from directory"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:00<00:00, 92.16it/s]\n"
     ]
    }
   ],
   "source": [
    "dataset = BooksDataLoader(limit=2)\n",
    "dataset_loader = dataset.loader(chapter_split=1)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Preprocessing"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "seq_length = 20\n",
    "token_type = 'word'"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "data": {
      "text/plain": "[['\\n\\n\\n\\n\\nA NEW ACQUAINTANCE—THE STROLLER’S TALE—A DISAGREEABLE INTERRUPTION, AND AN UNPLEASANT ENCOUNTERMr. Pickwick had felt some apprehensions in consequence of the unusual absence of his two friends, which their mysterious behaviour during the whole morning had by no means tended to diminish. It was, therefore, with more than ordinary pleasure that he rose to greet them when they again entered; and with more than ordinary interest that he inquired what had occurred to detain them from his society. In reply to his questions on this point, Mr. Snodgrass was about to offer an historical account of the circumstances just now detailed, when he was suddenly checked by observing that there were present, not only Mr. Tupman and their stage-coach companion of the preceding day, but another stranger of equally singular appearance. It was a careworn-looking man, whose sallow face, and deeply-sunken eyes, were rendered still more striking than Nature had made them, by the straight black hair which hung in matted disorder half-way down his face. His eyes were almost unnaturally bright and piercing; his cheek-bones were high and prominent; and his jaws were so long and lank, that an observer would have supposed that he was drawing the flesh of his face in, for a moment, by some contraction of the muscles, if his half-opened mouth and immovable expression had not announced that it was his ordinary appearance. Round his neck he wore a green shawl, with the large ends straggling over his chest, and making their appearance occasionally beneath the worn button-holes of his old waistcoat. His upper garment was a long black surtout; and below it he wore wide drab trousers, and large boots, running rapidly to seed.It was on this uncouth-looking person that Mr. Winkle’s eye rested, and it was towards him that Mr. Pickwick extended his hand when he said, ‘A friend of our friend’s here. We discovered this morning that our friend was connected with the theatre in this place, though he is not desirous to have it generally known, and this gentleman is a member of the same profession. He was about to favour us with a little anecdote connected with it, when you entered.’‘Lots of anecdote,’ said the green-coated stranger of the day before, advancing to Mr. Winkle and speaking in a low and confidential tone. ‘Rum fellow—does the heavy business—no actor—strange man—all sorts of miseries—Dismal Jemmy, we call him on the circuit.’ Mr. Winkle and Mr. Snodgrass politely welcomed the gentleman, elegantly designated as ‘Dismal Jemmy’; and calling for brandy-and-water, in imitation of the remainder of the company, seated themselves at the table.‘Now sir,’ said Mr. Pickwick, ‘will you oblige us by proceeding with what you were going to relate?’The dismal individual took a dirty roll of paper from his pocket, and turning to Mr. Snodgrass, who had just taken out his note-book, said in a hollow voice, perfectly in keeping with his outward man—‘Are you the poet?’‘I—I do a little in that way,’ replied Mr. Snodgrass, rather taken aback by the abruptness of the question.‘Ah! poetry makes life what light and music do the stage—strip the one of the false embellishments, and the other of its illusions, and what is there real in either to live or care for?’‘Very true, Sir,’ replied Mr. Snodgrass.‘To be before the footlights,’ continued the dismal man, ‘is like sitting at a grand court show, and admiring the silken dresses of the gaudy throng; to be behind them is to be the people who make that finery, uncared for and unknown, and left to sink or swim, to starve or live, as fortune wills it.’‘Certainly,’ said Mr. Snodgrass: for the sunken eye of the dismal man rested on him, and he felt it necessary to say something.‘Go on, Jemmy,’ said the Spanish traveller, ‘like black-eyed Susan—all in the Downs—no croaking—speak out—look lively.’‘Will you make another glass before you begin, Sir?’ said Mr. Pickwick.The dismal man took the hint, and having mixed a glass of brandy-and-water, and slowly swallowed half of it, opened the roll of paper and proceeded, partly to read, and partly to relate, the following incident, which we find recorded on the Transactions of the Club as ‘The Stroller’s Tale.’THE STROLLER’S TALE ‘There is nothing of the marvellous in what I am going to relate,’ said the dismal man; ‘there is nothing even uncommon in it. Want and sickness are too common in many stations of life to deserve more notice than is usually bestowed on the most ordinary vicissitudes of human nature. I have thrown these few notes together, because the subject of them was well known to me for many years. I traced his progress downwards, step by step, until at last he reached that excess of destitution from which he never rose again.‘The man of whom I speak was a low pantomime actor; and, like many people of his class, an habitual drunkard. In his better days, before he had become enfeebled by dissipation and emaciated by disease, he had been in the receipt of a good salary, which, if he had been careful and prudent, he might have continued to receive for some years—not many; because these men either die early, or by unnaturally taxing their bodily energies, lose, prematurely, those physical powers on which alone they can depend for subsistence. His besetting sin gained so fast upon him, however, that it was found impossible to employ him in the situations in which he really was useful to the theatre. The public-house had a fascination for him which he could not resist. Neglected disease and hopeless poverty were as certain to be his portion as death itself, if he persevered in the same course; yet he did persevere, and the result may be guessed. He could obtain no engagement, and he wanted bread.‘Everybody who is at all acquainted with theatrical matters knows what a host of shabby, poverty-stricken men hang about the stage of a large establishment—not regularly engaged actors, but ballet people, procession men, tumblers, and so forth, who are taken on during the run of a pantomime, or an Easter piece, and are then discharged, until the production of some heavy spectacle occasions a new demand for their services. To this mode of life the man was compelled to resort; and taking the chair every night, at some low theatrical house, at once put him in possession of a few more shillings weekly, and enabled him to gratify his old propensity. Even this resource shortly failed him; his irregularities were too great to admit of his earning the wretched pittance he might thus have procured, and he was actually reduced to a state bordering on starvation, only procuring a trifle occasionally by borrowing it of some old companion, or by obtaining an appearance at one or other of the commonest of the minor theatres; and when he did earn anything it was spent in the old way.‘About this time, and when he had been existing for upwards of a year no one knew how, I had a short engagement at one of the theatres on the Surrey side of the water, and here I saw this man, whom I had lost sight of for some time; for I had been travelling in the provinces, and he had been skulking in the lanes and alleys of London. I was dressed to leave the house, and was crossing the stage on my way out, when he tapped me on the shoulder. Never shall I forget the repulsive sight that met my eye when I turned round. He was dressed for the pantomimes in all the absurdity of a clown’s costume. The spectral figures in the Dance of Death, the most frightful shapes that the ablest painter ever portrayed on canvas, never presented an appearance half so ghastly. His bloated body and shrunken legs—their deformity enhanced a hundredfold by the fantastic dress—the glassy eyes, contrasting fearfully with the thick white paint with which the face was besmeared; the grotesquely-ornamented head, trembling with paralysis, and the long skinny hands, rubbed with white chalk—all gave him a hideous and unnatural appearance, of which no description could convey an adequate idea, and which, to this day, I shudder to think of. His voice was hollow and tremulous as he took me aside, and in broken words recounted a long catalogue of sickness and privations, terminating as usual with an urgent request for the loan of a trifling sum of money. I put a few shillings in his hand, and as I turned away I heard the roar of laughter which followed his first tumble on the stage.‘A few nights afterwards, a boy put a dirty scrap of paper in my hand, on which were scrawled a few words in pencil, intimating that the man was dangerously ill, and begging me, after the performance, to see him at his lodgings in some street—I forget the name of it now—at no great distance from the theatre. I promised to comply, as soon as I could get away; and after the curtain fell, sallied forth on my melancholy errand.‘It was late, for I had been playing in the last piece; and, as it was a benefit night, the performances had been protracted to an unusual length. It was a dark, cold night, with a chill, damp wind, which blew the rain heavily against the windows and house-fronts. Pools of water had collected in the narrow and little-frequented streets, and as many of the thinly-scattered oil-lamps had been blown out by the violence of the wind, the walk was not only a comfortless, but most uncertain one. I had fortunately taken the right course, however, and succeeded, after a little difficulty, in finding the house to which I had been directed—a coal-shed, with one storey above it, in the back room of which lay the object of my search.‘A wretched-looking woman, the man’s wife, met me on the stairs, and, telling me that he had just fallen into a kind of doze, led me softly in, and placed a chair for me at the bedside. The sick man was lying with his face turned towards the wall; and as he took no heed of my presence, I had leisure to observe the place in which I found myself.‘He was lying on an old bedstead, which turned up during the day. The tattered remains of a checked curtain were drawn round the bed’s head, to exclude the wind, which, however, made its way into the comfortless room through the numerous chinks in the door, and blew it to and fro every instant. There was a low cinder fire in a rusty, unfixed grate; and an old three-cornered stained table, with some medicine bottles, a broken glass, and a few other domestic articles, was drawn out before it. A little child was sleeping on a temporary bed which had been made for it on the floor, and the woman sat on a chair by its side. There were a couple of shelves, with a few plates and cups and saucers; and a pair of stage shoes and a couple of foils hung beneath them. With the exception of little heaps of rags and bundles which had been carelessly thrown into the corners of the room, these were the only things in the apartment.‘I had had time to note these little particulars, and to mark the heavy breathing and feverish startings of the sick man, before he was aware of my presence. In the restless attempts to procure some easy resting-place for his head, he tossed his hand out of the bed, and it fell on mine. He started up, and stared eagerly in my face.‘“Mr. Hutley, John,” said his wife; “Mr. Hutley, that you sent for to-night, you know.”‘“Ah!” said the invalid, passing his hand across his forehead; “Hutley—Hutley—let me see.” He seemed endeavouring to collect his thoughts for a few seconds, and then grasping me tightly by the wrist said, “Don’t leave me—don’t leave me, old fellow. She’ll murder me; I know she will.”‘“Has he been long so?” said I, addressing his weeping wife.‘“Since yesterday night,” she replied. “John, John, don’t you know me?”‘“Don’t let her come near me,” said the man, with a shudder, as she stooped over him. “Drive her away; I can’t bear her near me.” He stared wildly at her, with a look of deadly apprehension, and then whispered in my ear, “I beat her, Jem; I beat her yesterday, and many times before. I have starved her and the boy too; and now I am weak and helpless, Jem, she’ll murder me for it; I know she will. If you’d seen her cry, as I have, you’d know it too. Keep her off.” He relaxed his grasp, and sank back exhausted on the pillow.‘I knew but too well what all this meant. If I could have entertained any doubt of it, for an instant, one glance at the woman’s pale face and wasted form would have sufficiently explained the real state of the case. “You had better stand aside,” said I to the poor creature. “You can do him no good. Perhaps he will be calmer, if he does not see you.” She retired out of the man’s sight. He opened his eyes after a few seconds, and looked anxiously round.‘“Is she gone?” he eagerly inquired.‘“Yes—yes,” said I; “she shall not hurt you.”‘“I’ll tell you what, Jem,” said the man, in a low voice, “she does hurt me. There’s something in her eyes wakes such a dreadful fear in my heart, that it drives me mad. All last night, her large, staring eyes and pale face were close to mine; wherever I turned, they turned; and whenever I started up from my sleep, she was at the bedside looking at me.” He drew me closer to him, as he said in a deep alarmed whisper, “Jem, she must be an evil spirit—a devil! Hush! I know she is. If she had been a woman she would have died long ago. No woman could have borne what she has.”‘I sickened at the thought of the long course of cruelty and neglect which must have occurred to produce such an impression on such a man. I could say nothing in reply; for who could offer hope, or consolation, to the abject being before me?‘I sat there for upwards of two hours, during which time he tossed about, murmuring exclamations of pain or impatience, restlessly throwing his arms here and there, and turning constantly from side to side. At length he fell into that state of partial unconsciousness, in which the mind wanders uneasily from scene to scene, and from place to place, without the control of reason, but still without being able to divest itself of an indescribable sense of present suffering. Finding from his incoherent wanderings that this was the case, and knowing that in all probability the fever would not grow immediately worse, I left him, promising his miserable wife that I would repeat my visit next evening, and, if necessary, sit up with the patient during the night.‘I kept my promise. The last four-and-twenty hours had produced a frightful alteration. The eyes, though deeply sunk and heavy, shone with a lustre frightful to behold. The lips were parched, and cracked in many places; the hard, dry skin glowed with a burning heat; and there was an almost unearthly air of wild anxiety in the man’s face, indicating even more strongly the ravages of the disease. The fever was at its height.‘I took the seat I had occupied the night before, and there I sat for hours, listening to sounds which must strike deep to the heart of the most callous among human beings—the awful ravings of a dying man. From what I had heard of the medical attendant’s opinion, I knew there was no hope for him: I was sitting by his death-bed. I saw the wasted limbs—which a few hours before had been distorted for the amusement of a boisterous gallery, writhing under the tortures of a burning fever—I heard the clown’s shrill laugh, blending with the low murmurings of the dying man.‘It is a touching thing to hear the mind reverting to the ordinary occupations and pursuits of health, when the body lies before you weak and helpless; but when those occupations are of a character the most strongly opposed to anything we associate with grave and solemn ideas, the impression produced is infinitely more powerful. The theatre and the public-house were the chief themes of the wretched man’s wanderings. It was evening, he fancied; he had a part to play that night; it was late, and he must leave home instantly. Why did they hold him, and prevent his going?—he should lose the money—he must go. No! they would not let him. He hid his face in his burning hands, and feebly bemoaned his own weakness, and the cruelty of his persecutors. A short pause, and he shouted out a few doggerel rhymes—the last he had ever learned. He rose in bed, drew up his withered limbs, and rolled about in uncouth positions; he was acting—he was at the theatre. A minute’s silence, and he murmured the burden of some roaring song. He had reached the old house at last—how hot the room was. He had been ill, very ill, but he was well now, and happy. Fill up his glass. Who was that, that dashed it from his lips? It was the same persecutor that had followed him before. He fell back upon his pillow and moaned aloud. A short period of oblivion, and he was wandering through a tedious maze of low-arched rooms—so low, sometimes, that he must creep upon his hands and knees to make his way along; it was close and dark, and every way he turned, some obstacle impeded his progress. There were insects, too, hideous crawling things, with eyes that stared upon him, and filled the very air around, glistening horribly amidst the thick darkness of the place. The walls and ceiling were alive with reptiles—the vault expanded to an enormous size—frightful figures flitted to and fro—and the faces of men he knew, rendered hideous by gibing and mouthing, peered out from among them; they were searing him with heated irons, and binding his head with cords till the blood started; and he struggled madly for life.‘At the close of one of these paroxysms, when I had with great difficulty held him down in his bed, he sank into what appeared to be a slumber. Overpowered with watching and exertion, I had closed my eyes for a few minutes, when I felt a violent clutch on my shoulder. I awoke instantly. He had raised himself up, so as to seat himself in bed—a dreadful change had come over his face, but consciousness had returned, for he evidently knew me. The child, who had been long since disturbed by his ravings, rose from its little bed, and ran towards its father, screaming with fright—the mother hastily caught it in her arms, lest he should injure it in the violence of his insanity; but, terrified by the alteration of his features, stood transfixed by the bedside. He grasped my shoulder convulsively, and, striking his breast with the other hand, made a desperate attempt to articulate. It was unavailing; he extended his arm towards them, and made another violent effort. There was a rattling noise in the throat—a glare of the eye—a short stifled groan—and he fell back—dead!’It would afford us the highest gratification to be enabled to record Mr. Pickwick’s opinion of the foregoing anecdote. We have little doubt that we should have been enabled to present it to our readers, but for a most unfortunate occurrence.Mr. Pickwick had replaced on the table the glass which, during the last few sentences of the tale, he had retained in his hand; and had just made up his mind to speak—indeed, we have the authority of Mr. Snodgrass’s note-book for stating, that he had actually opened his mouth—when the waiter entered the room, and said—‘Some gentlemen, Sir.’It has been conjectured that Mr. Pickwick was on the point of delivering some remarks which would have enlightened the world, if not the Thames, when he was thus interrupted; for he gazed sternly on the waiter’s countenance, and then looked round on the company generally, as if seeking for information relative to the new-comers.‘Oh!’ said Mr. Winkle, rising, ‘some friends of mine—show them in. Very pleasant fellows,’ added Mr. Winkle, after the waiter had retired—‘officers of the 97th, whose acquaintance I made rather oddly this morning. You will like them very much.’Mr. Pickwick’s equanimity was at once restored. The waiter returned, and ushered three gentlemen into the room.‘Lieutenant Tappleton,’ said Mr. Winkle, ‘Lieutenant Tappleton, Mr. Pickwick—Doctor Payne, Mr. Pickwick—Mr. Snodgrass you have seen before, my friend Mr. Tupman, Doctor Payne—Doctor Slammer, Mr. Pickwick—Mr. Tupman, Doctor Slam—’Here Mr. Winkle suddenly paused; for strong emotion was visible on the countenance both of Mr. Tupman and the doctor.‘I have met this gentleman before,’ said the Doctor, with marked emphasis.‘Indeed!’ said Mr. Winkle.‘And—and that person, too, if I am not mistaken,’ said the doctor, bestowing a scrutinising glance on the green-coated stranger. ‘I think I gave that person a very pressing invitation last night, which he thought proper to decline.’ Saying which the doctor scowled magnanimously on the stranger, and whispered his friend Lieutenant Tappleton.‘You don’t say so,’ said that gentleman, at the conclusion of the whisper.‘I do, indeed,’ replied Doctor Slammer.‘You are bound to kick him on the spot,’ murmured the owner of the camp-stool, with great importance.‘Do be quiet, Payne,’ interposed the lieutenant. ‘Will you allow me to ask you, sir,’ he said, addressing Mr. Pickwick, who was considerably mystified by this very unpolite by-play—‘will you allow me to ask you, Sir, whether that person belongs to your party?’‘No, Sir,’ replied Mr. Pickwick, ‘he is a guest of ours.’‘He is a member of your club, or I am mistaken?’ said the lieutenant inquiringly.‘Certainly not,’ responded Mr. Pickwick.‘And never wears your club-button?’ said the lieutenant.‘No—never!’ replied the astonished Mr. Pickwick.Lieutenant Tappleton turned round to his friend Doctor Slammer, with a scarcely perceptible shrug of the shoulder, as if implying some doubt of the accuracy of his recollection. The little doctor looked wrathful, but confounded; and Mr. Payne gazed with a ferocious aspect on the beaming countenance of the unconscious Pickwick.‘Sir,’ said the doctor, suddenly addressing Mr. Tupman, in a tone which made that gentleman start as perceptibly as if a pin had been cunningly inserted in the calf of his leg, ‘you were at the ball here last night!’Mr. Tupman gasped a faint affirmative, looking very hard at Mr. Pickwick all the while.‘That person was your companion,’ said the doctor, pointing to the still unmoved stranger.Mr. Tupman admitted the fact.‘Now, sir,’ said the doctor to the stranger, ‘I ask you once again, in the presence of these gentlemen, whether you choose to give me your card, and to receive the treatment of a gentleman; or whether you impose upon me the necessity of personally chastising you on the spot?’‘Stay, sir,’ said Mr. Pickwick, ‘I really cannot allow this matter to go any further without some explanation. Tupman, recount the circumstances.’Mr. Tupman, thus solemnly adjured, stated the case in a few words; touched slightly on the borrowing of the coat; expatiated largely on its having been done ‘after dinner’; wound up with a little penitence on his own account; and left the stranger to clear himself as best he could.He was apparently about to proceed to do so, when Lieutenant Tappleton, who had been eyeing him with great curiosity, said with considerable scorn, ‘Haven’t I seen you at the theatre, Sir?’‘Certainly,’ replied the unabashed stranger.‘He is a strolling actor!’ said the lieutenant contemptuously, turning to Doctor Slammer.—‘He acts in the piece that the officers of the 52nd get up at the Rochester Theatre to-morrow night. You cannot proceed in this affair, Slammer—impossible!’‘Quite!’ said the dignified Payne.‘Sorry to have placed you in this disagreeable situation,’ said Lieutenant Tappleton, addressing Mr. Pickwick; ‘allow me to suggest, that the best way of avoiding a recurrence of such scenes in future will be to be more select in the choice of your companions. Good-evening, Sir!’ and the lieutenant bounced out of the room.‘And allow me to say, Sir,’ said the irascible Doctor Payne, ‘that if I had been Tappleton, or if I had been Slammer, I would have pulled your nose, Sir, and the nose of every man in this company. I would, sir—every man. Payne is my name, sir—Doctor Payne of the 43rd. Good-evening, Sir.’ Having concluded this speech, and uttered the last three words in a loud key, he stalked majestically after his friend, closely followed by Doctor Slammer, who said nothing, but contented himself by withering the company with a look.Rising rage and extreme bewilderment had swelled the noble breast of Mr. Pickwick, almost to the bursting of his waistcoat, during the delivery of the above defiance. He stood transfixed to the spot, gazing on vacancy. The closing of the door recalled him to himself. He rushed forward with fury in his looks, and fire in his eye. His hand was upon the lock of the door; in another instant it would have been on the throat of Doctor Payne of the 43rd, had not Mr. Snodgrass seized his revered leader by the coat tail, and dragged him backwards.‘Restrain him,’ cried Mr. Snodgrass; ‘Winkle, Tupman—he must not peril his distinguished life in such a cause as this.’‘Let me go,’ said Mr. Pickwick.‘Hold him tight,’ shouted Mr. Snodgrass; and by the united efforts of the whole company, Mr. Pickwick was forced into an arm-chair.‘Leave him alone,’ said the green-coated stranger; ‘brandy-and-water—jolly old gentleman—lots of pluck—swallow this—ah!—capital stuff.’ Having previously tested the virtues of a bumper, which had been mixed by the dismal man, the stranger applied the glass to Mr. Pickwick’s mouth; and the remainder of its contents rapidly disappeared.There was a short pause; the brandy-and-water had done its work; the amiable countenance of Mr. Pickwick was fast recovering its customary expression.‘They are not worth your notice,’ said the dismal man.‘You are right, sir,’ replied Mr. Pickwick, ‘they are not. I am ashamed to have been betrayed into this warmth of feeling. Draw your chair up to the table, Sir.’The dismal man readily complied; a circle was again formed round the table, and harmony once more prevailed. Some lingering irritability appeared to find a resting-place in Mr. Winkle’s bosom, occasioned possibly by the temporary abstraction of his coat—though it is scarcely reasonable to suppose that so slight a circumstance can have excited even a passing feeling of anger in a Pickwickian’s breast. With this exception, their good-humour was completely restored; and the evening concluded with the conviviality with which it had begun.\\n']]"
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_dataframe = BooksDataLoader.dataframe_loader_to_text(data_loader=dataset_loader)\n",
    "text_dataframe[2:3]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "start_story = '| ' * seq_length\n",
    "def clean_text():\n",
    "    clean_dataset = []\n",
    "    for dataframe in text_dataframe:\n",
    "        clean = ''\n",
    "        for frame in dataframe:\n",
    "            clean += frame\n",
    "            pass\n",
    "\n",
    "        clean = start_story + clean.strip()\n",
    "        clean = clean.lower()\n",
    "        # text = text.replace('\\n', ' ')\n",
    "        # clean = clean.replace('\\n\\n\\n\\n\\n', start_story)\n",
    "        clean = clean.replace('. . .', '.')\n",
    "        clean = clean.replace('    ', ' ')\n",
    "        clean = re.sub('\\[.*?]', '', clean).strip()\n",
    "        clean = clean.replace('..', '.')\n",
    "        clean = clean.replace('. ', '.')\n",
    "        clean = re.sub('  +', '. ', clean).strip()\n",
    "        clean = re.sub('([!\"#$%&()*+,-./:;<=>?@[\\]^_`{|}~])', r' \\1 ', clean)\n",
    "        clean = re.sub('\\s{2,}', ' ', clean)\n",
    "        clean_dataset.append(clean)\n",
    "        pass\n",
    "    return clean_dataset"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "data": {
      "text/plain": "[' | | | | | | | | | | | | | | | | | | | | a new acquaintance—the stroller’s tale—a disagreeable interruption , and an unpleasant encountermr . pickwick had felt some apprehensions in consequence of the unusual absence of his two friends , which their mysterious behaviour during the whole morning had by no means tended to diminish . it was , therefore , with more than ordinary pleasure that he rose to greet them when they again entered ; and with more than ordinary interest that he inquired what had occurred to detain them from his society . in reply to his questions on this point , mr . snodgrass was about to offer an historical account of the circumstances just now detailed , when he was suddenly checked by observing that there were present , not only mr . tupman and their stage - coach companion of the preceding day , but another stranger of equally singular appearance . it was a careworn - looking man , whose sallow face , and deeply - sunken eyes , were rendered still more striking than nature had made them , by the straight black hair which hung in matted disorder half - way down his face . his eyes were almost unnaturally bright and piercing ; his cheek - bones were high and prominent ; and his jaws were so long and lank , that an observer would have supposed that he was drawing the flesh of his face in , for a moment , by some contraction of the muscles , if his half - opened mouth and immovable expression had not announced that it was his ordinary appearance . round his neck he wore a green shawl , with the large ends straggling over his chest , and making their appearance occasionally beneath the worn button - holes of his old waistcoat . his upper garment was a long black surtout ; and below it he wore wide drab trousers , and large boots , running rapidly to seed . it was on this uncouth - looking person that mr . winkle’s eye rested , and it was towards him that mr . pickwick extended his hand when he said , ‘a friend of our friend’s here . we discovered this morning that our friend was connected with the theatre in this place , though he is not desirous to have it generally known , and this gentleman is a member of the same profession . he was about to favour us with a little anecdote connected with it , when you entered . ’‘lots of anecdote , ’ said the green - coated stranger of the day before , advancing to mr . winkle and speaking in a low and confidential tone . ‘rum fellow—does the heavy business—no actor—strange man—all sorts of miseries—dismal jemmy , we call him on the circuit . ’ mr . winkle and mr . snodgrass politely welcomed the gentleman , elegantly designated as ‘dismal jemmy’ ; and calling for brandy - and - water , in imitation of the remainder of the company , seated themselves at the table . ‘now sir , ’ said mr . pickwick , ‘will you oblige us by proceeding with what you were going to relate ? ’the dismal individual took a dirty roll of paper from his pocket , and turning to mr . snodgrass , who had just taken out his note - book , said in a hollow voice , perfectly in keeping with his outward man—‘are you the poet ? ’‘i—i do a little in that way , ’ replied mr . snodgrass , rather taken aback by the abruptness of the question . ‘ah ! poetry makes life what light and music do the stage—strip the one of the false embellishments , and the other of its illusions , and what is there real in either to live or care for ? ’‘very true , sir , ’ replied mr . snodgrass . ‘to be before the footlights , ’ continued the dismal man , ‘is like sitting at a grand court show , and admiring the silken dresses of the gaudy throng ; to be behind them is to be the people who make that finery , uncared for and unknown , and left to sink or swim , to starve or live , as fortune wills it . ’‘certainly , ’ said mr . snodgrass : for the sunken eye of the dismal man rested on him , and he felt it necessary to say something . ‘go on , jemmy , ’ said the spanish traveller , ‘like black - eyed susan—all in the downs—no croaking—speak out—look lively . ’‘will you make another glass before you begin , sir ? ’ said mr . pickwick . the dismal man took the hint , and having mixed a glass of brandy - and - water , and slowly swallowed half of it , opened the roll of paper and proceeded , partly to read , and partly to relate , the following incident , which we find recorded on the transactions of the club as ‘the stroller’s tale . ’the stroller’s tale ‘there is nothing of the marvellous in what i am going to relate , ’ said the dismal man ; ‘there is nothing even uncommon in it . want and sickness are too common in many stations of life to deserve more notice than is usually bestowed on the most ordinary vicissitudes of human nature . i have thrown these few notes together , because the subject of them was well known to me for many years . i traced his progress downwards , step by step , until at last he reached that excess of destitution from which he never rose again . ‘the man of whom i speak was a low pantomime actor ; and , like many people of his class , an habitual drunkard . in his better days , before he had become enfeebled by dissipation and emaciated by disease , he had been in the receipt of a good salary , which , if he had been careful and prudent , he might have continued to receive for some years—not many ; because these men either die early , or by unnaturally taxing their bodily energies , lose , prematurely , those physical powers on which alone they can depend for subsistence . his besetting sin gained so fast upon him , however , that it was found impossible to employ him in the situations in which he really was useful to the theatre . the public - house had a fascination for him which he could not resist . neglected disease and hopeless poverty were as certain to be his portion as death itself , if he persevered in the same course ; yet he did persevere , and the result may be guessed . he could obtain no engagement , and he wanted bread . ‘everybody who is at all acquainted with theatrical matters knows what a host of shabby , poverty - stricken men hang about the stage of a large establishment—not regularly engaged actors , but ballet people , procession men , tumblers , and so forth , who are taken on during the run of a pantomime , or an easter piece , and are then discharged , until the production of some heavy spectacle occasions a new demand for their services . to this mode of life the man was compelled to resort ; and taking the chair every night , at some low theatrical house , at once put him in possession of a few more shillings weekly , and enabled him to gratify his old propensity . even this resource shortly failed him ; his irregularities were too great to admit of his earning the wretched pittance he might thus have procured , and he was actually reduced to a state bordering on starvation , only procuring a trifle occasionally by borrowing it of some old companion , or by obtaining an appearance at one or other of the commonest of the minor theatres ; and when he did earn anything it was spent in the old way . ‘about this time , and when he had been existing for upwards of a year no one knew how , i had a short engagement at one of the theatres on the surrey side of the water , and here i saw this man , whom i had lost sight of for some time ; for i had been travelling in the provinces , and he had been skulking in the lanes and alleys of london . i was dressed to leave the house , and was crossing the stage on my way out , when he tapped me on the shoulder . never shall i forget the repulsive sight that met my eye when i turned round . he was dressed for the pantomimes in all the absurdity of a clown’s costume . the spectral figures in the dance of death , the most frightful shapes that the ablest painter ever portrayed on canvas , never presented an appearance half so ghastly . his bloated body and shrunken legs—their deformity enhanced a hundredfold by the fantastic dress—the glassy eyes , contrasting fearfully with the thick white paint with which the face was besmeared ; the grotesquely - ornamented head , trembling with paralysis , and the long skinny hands , rubbed with white chalk—all gave him a hideous and unnatural appearance , of which no description could convey an adequate idea , and which , to this day , i shudder to think of . his voice was hollow and tremulous as he took me aside , and in broken words recounted a long catalogue of sickness and privations , terminating as usual with an urgent request for the loan of a trifling sum of money . i put a few shillings in his hand , and as i turned away i heard the roar of laughter which followed his first tumble on the stage . ‘a few nights afterwards , a boy put a dirty scrap of paper in my hand , on which were scrawled a few words in pencil , intimating that the man was dangerously ill , and begging me , after the performance , to see him at his lodgings in some street—i forget the name of it now—at no great distance from the theatre . i promised to comply , as soon as i could get away ; and after the curtain fell , sallied forth on my melancholy errand . ‘it was late , for i had been playing in the last piece ; and , as it was a benefit night , the performances had been protracted to an unusual length . it was a dark , cold night , with a chill , damp wind , which blew the rain heavily against the windows and house - fronts . pools of water had collected in the narrow and little - frequented streets , and as many of the thinly - scattered oil - lamps had been blown out by the violence of the wind , the walk was not only a comfortless , but most uncertain one . i had fortunately taken the right course , however , and succeeded , after a little difficulty , in finding the house to which i had been directed—a coal - shed , with one storey above it , in the back room of which lay the object of my search . ‘a wretched - looking woman , the man’s wife , met me on the stairs , and , telling me that he had just fallen into a kind of doze , led me softly in , and placed a chair for me at the bedside . the sick man was lying with his face turned towards the wall ; and as he took no heed of my presence , i had leisure to observe the place in which i found myself . ‘he was lying on an old bedstead , which turned up during the day . the tattered remains of a checked curtain were drawn round the bed’s head , to exclude the wind , which , however , made its way into the comfortless room through the numerous chinks in the door , and blew it to and fro every instant . there was a low cinder fire in a rusty , unfixed grate ; and an old three - cornered stained table , with some medicine bottles , a broken glass , and a few other domestic articles , was drawn out before it . a little child was sleeping on a temporary bed which had been made for it on the floor , and the woman sat on a chair by its side . there were a couple of shelves , with a few plates and cups and saucers ; and a pair of stage shoes and a couple of foils hung beneath them . with the exception of little heaps of rags and bundles which had been carelessly thrown into the corners of the room , these were the only things in the apartment . ‘i had had time to note these little particulars , and to mark the heavy breathing and feverish startings of the sick man , before he was aware of my presence . in the restless attempts to procure some easy resting - place for his head , he tossed his hand out of the bed , and it fell on mine . he started up , and stared eagerly in my face . ‘“mr . hutley , john , ” said his wife ; “mr . hutley , that you sent for to - night , you know . ”‘“ah ! ” said the invalid , passing his hand across his forehead ; “hutley—hutley—let me see . ” he seemed endeavouring to collect his thoughts for a few seconds , and then grasping me tightly by the wrist said , “don’t leave me—don’t leave me , old fellow . she’ll murder me ; i know she will . ”‘“has he been long so ? ” said i , addressing his weeping wife . ‘“since yesterday night , ” she replied . “john , john , don’t you know me ? ”‘“don’t let her come near me , ” said the man , with a shudder , as she stooped over him . “drive her away ; i can’t bear her near me . ” he stared wildly at her , with a look of deadly apprehension , and then whispered in my ear , “i beat her , jem ; i beat her yesterday , and many times before . i have starved her and the boy too ; and now i am weak and helpless , jem , she’ll murder me for it ; i know she will . if you’d seen her cry , as i have , you’d know it too . keep her off . ” he relaxed his grasp , and sank back exhausted on the pillow . ‘i knew but too well what all this meant . if i could have entertained any doubt of it , for an instant , one glance at the woman’s pale face and wasted form would have sufficiently explained the real state of the case . “you had better stand aside , ” said i to the poor creature . “you can do him no good . perhaps he will be calmer , if he does not see you . ” she retired out of the man’s sight . he opened his eyes after a few seconds , and looked anxiously round . ‘“is she gone ? ” he eagerly inquired . ‘“yes—yes , ” said i ; “she shall not hurt you . ”‘“i’ll tell you what , jem , ” said the man , in a low voice , “she does hurt me . there’s something in her eyes wakes such a dreadful fear in my heart , that it drives me mad . all last night , her large , staring eyes and pale face were close to mine ; wherever i turned , they turned ; and whenever i started up from my sleep , she was at the bedside looking at me . ” he drew me closer to him , as he said in a deep alarmed whisper , “jem , she must be an evil spirit—a devil ! hush ! i know she is . if she had been a woman she would have died long ago . no woman could have borne what she has . ”‘i sickened at the thought of the long course of cruelty and neglect which must have occurred to produce such an impression on such a man . i could say nothing in reply ; for who could offer hope , or consolation , to the abject being before me ? ‘i sat there for upwards of two hours , during which time he tossed about , murmuring exclamations of pain or impatience , restlessly throwing his arms here and there , and turning constantly from side to side . at length he fell into that state of partial unconsciousness , in which the mind wanders uneasily from scene to scene , and from place to place , without the control of reason , but still without being able to divest itself of an indescribable sense of present suffering . finding from his incoherent wanderings that this was the case , and knowing that in all probability the fever would not grow immediately worse , i left him , promising his miserable wife that i would repeat my visit next evening , and , if necessary , sit up with the patient during the night . ‘i kept my promise . the last four - and - twenty hours had produced a frightful alteration . the eyes , though deeply sunk and heavy , shone with a lustre frightful to behold . the lips were parched , and cracked in many places ; the hard , dry skin glowed with a burning heat ; and there was an almost unearthly air of wild anxiety in the man’s face , indicating even more strongly the ravages of the disease . the fever was at its height . ‘i took the seat i had occupied the night before , and there i sat for hours , listening to sounds which must strike deep to the heart of the most callous among human beings—the awful ravings of a dying man . from what i had heard of the medical attendant’s opinion , i knew there was no hope for him : i was sitting by his death - bed . i saw the wasted limbs—which a few hours before had been distorted for the amusement of a boisterous gallery , writhing under the tortures of a burning fever—i heard the clown’s shrill laugh , blending with the low murmurings of the dying man . ‘it is a touching thing to hear the mind reverting to the ordinary occupations and pursuits of health , when the body lies before you weak and helpless ; but when those occupations are of a character the most strongly opposed to anything we associate with grave and solemn ideas , the impression produced is infinitely more powerful . the theatre and the public - house were the chief themes of the wretched man’s wanderings . it was evening , he fancied ; he had a part to play that night ; it was late , and he must leave home instantly . why did they hold him , and prevent his going ? —he should lose the money—he must go . no ! they would not let him . he hid his face in his burning hands , and feebly bemoaned his own weakness , and the cruelty of his persecutors . a short pause , and he shouted out a few doggerel rhymes—the last he had ever learned . he rose in bed , drew up his withered limbs , and rolled about in uncouth positions ; he was acting—he was at the theatre . a minute’s silence , and he murmured the burden of some roaring song . he had reached the old house at last—how hot the room was . he had been ill , very ill , but he was well now , and happy . fill up his glass . who was that , that dashed it from his lips ? it was the same persecutor that had followed him before . he fell back upon his pillow and moaned aloud . a short period of oblivion , and he was wandering through a tedious maze of low - arched rooms—so low , sometimes , that he must creep upon his hands and knees to make his way along ; it was close and dark , and every way he turned , some obstacle impeded his progress . there were insects , too , hideous crawling things , with eyes that stared upon him , and filled the very air around , glistening horribly amidst the thick darkness of the place . the walls and ceiling were alive with reptiles—the vault expanded to an enormous size—frightful figures flitted to and fro—and the faces of men he knew , rendered hideous by gibing and mouthing , peered out from among them ; they were searing him with heated irons , and binding his head with cords till the blood started ; and he struggled madly for life . ‘at the close of one of these paroxysms , when i had with great difficulty held him down in his bed , he sank into what appeared to be a slumber . overpowered with watching and exertion , i had closed my eyes for a few minutes , when i felt a violent clutch on my shoulder . i awoke instantly . he had raised himself up , so as to seat himself in bed—a dreadful change had come over his face , but consciousness had returned , for he evidently knew me . the child , who had been long since disturbed by his ravings , rose from its little bed , and ran towards its father , screaming with fright—the mother hastily caught it in her arms , lest he should injure it in the violence of his insanity ; but , terrified by the alteration of his features , stood transfixed by the bedside . he grasped my shoulder convulsively , and , striking his breast with the other hand , made a desperate attempt to articulate . it was unavailing ; he extended his arm towards them , and made another violent effort . there was a rattling noise in the throat—a glare of the eye—a short stifled groan—and he fell back—dead ! ’it would afford us the highest gratification to be enabled to record mr . pickwick’s opinion of the foregoing anecdote . we have little doubt that we should have been enabled to present it to our readers , but for a most unfortunate occurrence . mr . pickwick had replaced on the table the glass which , during the last few sentences of the tale , he had retained in his hand ; and had just made up his mind to speak—indeed , we have the authority of mr . snodgrass’s note - book for stating , that he had actually opened his mouth—when the waiter entered the room , and said—‘some gentlemen , sir . ’it has been conjectured that mr . pickwick was on the point of delivering some remarks which would have enlightened the world , if not the thames , when he was thus interrupted ; for he gazed sternly on the waiter’s countenance , and then looked round on the company generally , as if seeking for information relative to the new - comers . ‘oh ! ’ said mr . winkle , rising , ‘some friends of mine—show them in . very pleasant fellows , ’ added mr . winkle , after the waiter had retired—‘officers of the 97th , whose acquaintance i made rather oddly this morning . you will like them very much . ’mr . pickwick’s equanimity was at once restored . the waiter returned , and ushered three gentlemen into the room . ‘lieutenant tappleton , ’ said mr . winkle , ‘lieutenant tappleton , mr . pickwick—doctor payne , mr . pickwick—mr . snodgrass you have seen before , my friend mr . tupman , doctor payne—doctor slammer , mr . pickwick—mr . tupman , doctor slam—’here mr . winkle suddenly paused ; for strong emotion was visible on the countenance both of mr . tupman and the doctor . ‘i have met this gentleman before , ’ said the doctor , with marked emphasis . ‘indeed ! ’ said mr . winkle . ‘and—and that person , too , if i am not mistaken , ’ said the doctor , bestowing a scrutinising glance on the green - coated stranger . ‘i think i gave that person a very pressing invitation last night , which he thought proper to decline . ’ saying which the doctor scowled magnanimously on the stranger , and whispered his friend lieutenant tappleton . ‘you don’t say so , ’ said that gentleman , at the conclusion of the whisper . ‘i do , indeed , ’ replied doctor slammer . ‘you are bound to kick him on the spot , ’ murmured the owner of the camp - stool , with great importance . ‘do be quiet , payne , ’ interposed the lieutenant . ‘will you allow me to ask you , sir , ’ he said , addressing mr . pickwick , who was considerably mystified by this very unpolite by - play—‘will you allow me to ask you , sir , whether that person belongs to your party ? ’‘no , sir , ’ replied mr . pickwick , ‘he is a guest of ours . ’‘he is a member of your club , or i am mistaken ? ’ said the lieutenant inquiringly . ‘certainly not , ’ responded mr . pickwick . ‘and never wears your club - button ? ’ said the lieutenant . ‘no—never ! ’ replied the astonished mr . pickwick . lieutenant tappleton turned round to his friend doctor slammer , with a scarcely perceptible shrug of the shoulder , as if implying some doubt of the accuracy of his recollection . the little doctor looked wrathful , but confounded ; and mr . payne gazed with a ferocious aspect on the beaming countenance of the unconscious pickwick . ‘sir , ’ said the doctor , suddenly addressing mr . tupman , in a tone which made that gentleman start as perceptibly as if a pin had been cunningly inserted in the calf of his leg , ‘you were at the ball here last night ! ’mr . tupman gasped a faint affirmative , looking very hard at mr . pickwick all the while . ‘that person was your companion , ’ said the doctor , pointing to the still unmoved stranger . mr . tupman admitted the fact . ‘now , sir , ’ said the doctor to the stranger , ‘i ask you once again , in the presence of these gentlemen , whether you choose to give me your card , and to receive the treatment of a gentleman ; or whether you impose upon me the necessity of personally chastising you on the spot ? ’‘stay , sir , ’ said mr . pickwick , ‘i really cannot allow this matter to go any further without some explanation . tupman , recount the circumstances . ’mr . tupman , thus solemnly adjured , stated the case in a few words ; touched slightly on the borrowing of the coat ; expatiated largely on its having been done ‘after dinner’ ; wound up with a little penitence on his own account ; and left the stranger to clear himself as best he could . he was apparently about to proceed to do so , when lieutenant tappleton , who had been eyeing him with great curiosity , said with considerable scorn , ‘haven’t i seen you at the theatre , sir ? ’‘certainly , ’ replied the unabashed stranger . ‘he is a strolling actor ! ’ said the lieutenant contemptuously , turning to doctor slammer . —‘he acts in the piece that the officers of the 52nd get up at the rochester theatre to - morrow night . you cannot proceed in this affair , slammer—impossible ! ’‘quite ! ’ said the dignified payne . ‘sorry to have placed you in this disagreeable situation , ’ said lieutenant tappleton , addressing mr . pickwick ; ‘allow me to suggest , that the best way of avoiding a recurrence of such scenes in future will be to be more select in the choice of your companions . good - evening , sir ! ’ and the lieutenant bounced out of the room . ‘and allow me to say , sir , ’ said the irascible doctor payne , ‘that if i had been tappleton , or if i had been slammer , i would have pulled your nose , sir , and the nose of every man in this company . i would , sir—every man . payne is my name , sir—doctor payne of the 43rd . good - evening , sir . ’ having concluded this speech , and uttered the last three words in a loud key , he stalked majestically after his friend , closely followed by doctor slammer , who said nothing , but contented himself by withering the company with a look . rising rage and extreme bewilderment had swelled the noble breast of mr . pickwick , almost to the bursting of his waistcoat , during the delivery of the above defiance . he stood transfixed to the spot , gazing on vacancy . the closing of the door recalled him to himself . he rushed forward with fury in his looks , and fire in his eye . his hand was upon the lock of the door ; in another instant it would have been on the throat of doctor payne of the 43rd , had not mr . snodgrass seized his revered leader by the coat tail , and dragged him backwards . ‘restrain him , ’ cried mr . snodgrass ; ‘winkle , tupman—he must not peril his distinguished life in such a cause as this . ’‘let me go , ’ said mr . pickwick . ‘hold him tight , ’ shouted mr . snodgrass ; and by the united efforts of the whole company , mr . pickwick was forced into an arm - chair . ‘leave him alone , ’ said the green - coated stranger ; ‘brandy - and - water—jolly old gentleman—lots of pluck—swallow this—ah ! —capital stuff . ’ having previously tested the virtues of a bumper , which had been mixed by the dismal man , the stranger applied the glass to mr . pickwick’s mouth ; and the remainder of its contents rapidly disappeared . there was a short pause ; the brandy - and - water had done its work ; the amiable countenance of mr . pickwick was fast recovering its customary expression . ‘they are not worth your notice , ’ said the dismal man . ‘you are right , sir , ’ replied mr . pickwick , ‘they are not . i am ashamed to have been betrayed into this warmth of feeling . draw your chair up to the table , sir . ’the dismal man readily complied ; a circle was again formed round the table , and harmony once more prevailed . some lingering irritability appeared to find a resting - place in mr . winkle’s bosom , occasioned possibly by the temporary abstraction of his coat—though it is scarcely reasonable to suppose that so slight a circumstance can have excited even a passing feeling of anger in a pickwickian’s breast . with this exception , their good - humour was completely restored ; and the evening concluded with the conviviality with which it had begun . ']"
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_dataframe = clean_text()\n",
    "text_dataframe[2:3]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "if token_type == 'word':\n",
    "    tokenizer = Tokenizer(char_level = False, filters = '')\n",
    "else:\n",
    "    tokenizer = Tokenizer(char_level = True, filters = '', lower = False)\n",
    "\n",
    "tokenizer.fit_on_texts(text_dataframe)\n",
    "\n",
    "total_words = len(tokenizer.word_index) + 1\n",
    "\n",
    "token_list = tokenizer.texts_to_sequences(text_dataframe)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "def generate_sequences(token_list, step):\n",
    "    X = []\n",
    "    y = []\n",
    "\n",
    "    for i in range(0, len(token_list) - seq_length, step):\n",
    "        X.append(token_list[i: i + seq_length])\n",
    "        y.append(token_list[i + seq_length])\n",
    "\n",
    "    y = np_utils.to_categorical(y, num_classes = total_words)\n",
    "\n",
    "    num_seq = len(X)\n",
    "    print('Number of sequences:', num_seq, \"\\n\")\n",
    "\n",
    "    return X, y, num_seq"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Learn\n",
    "### Create model\n",
    "\n",
    "Test fit with test dataframes"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-14 14:22:25.844114: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-05-14 14:22:25.844432: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-05-14 14:22:25.844668: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-05-14 14:22:25.845178: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-05-14 14:22:25.845423: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-05-14 14:22:25.845651: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-05-14 14:22:25.845937: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-05-14 14:22:25.846172: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-05-14 14:22:25.846338: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 3318 MB memory:  -> device: 0, name: NVIDIA GeForce GTX 1650, pci bus id: 0000:01:00.0, compute capability: 7.5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, None)]            0         \n",
      "                                                                 \n",
      " embedding (Embedding)       (None, None, 500)         9874000   \n",
      "                                                                 \n",
      " lstm (LSTM)                 (None, None, 1024)        6246400   \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, None, 1024)        0         \n",
      "                                                                 \n",
      " lstm_1 (LSTM)               (None, 1024)              8392704   \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 1024)              0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 19748)             20241700  \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 44,754,804\n",
      "Trainable params: 44,754,804\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "-----------Started learning-----------\n",
      "---0/69-----------\n",
      "Number of sequences: 2149 \n",
      "\n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-14 14:22:30.763168: I tensorflow/stream_executor/cuda/cuda_dnn.cc:368] Loaded cuDNN version 8400\n",
      "Could not load symbol cublasGetSmCountTarget from libcublas.so.11. Error: /usr/local/cuda/targets/x86_64-linux/lib/libcublas.so.11: undefined symbol: cublasGetSmCountTarget\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "33/33 [==============================] - 7s 125ms/step - loss: 7.2958 - mae: 9.9256e-05\n",
      "Epoch 2/50\n",
      "33/33 [==============================] - 5s 128ms/step - loss: 5.7328 - mae: 9.9146e-05\n",
      "Epoch 3/50\n",
      "33/33 [==============================] - 5s 133ms/step - loss: 5.4041 - mae: 9.9045e-05\n",
      "Epoch 4/50\n",
      "33/33 [==============================] - 5s 127ms/step - loss: 5.1754 - mae: 9.8637e-05\n",
      "Epoch 5/50\n",
      "33/33 [==============================] - 5s 127ms/step - loss: 4.9616 - mae: 9.7607e-05\n",
      "Epoch 6/50\n",
      "33/33 [==============================] - 4s 124ms/step - loss: 4.7564 - mae: 9.6165e-05\n",
      "Epoch 7/50\n",
      "33/33 [==============================] - 5s 130ms/step - loss: 4.5674 - mae: 9.5198e-05\n",
      "Epoch 8/50\n",
      "33/33 [==============================] - 5s 130ms/step - loss: 4.3880 - mae: 9.4240e-05\n",
      "Epoch 9/50\n",
      "33/33 [==============================] - 5s 126ms/step - loss: 4.2941 - mae: 9.3847e-05\n",
      "Epoch 10/50\n",
      "33/33 [==============================] - 5s 125ms/step - loss: 4.1185 - mae: 9.2866e-05\n",
      "Epoch 11/50\n",
      "33/33 [==============================] - 4s 125ms/step - loss: 4.0283 - mae: 9.2360e-05\n",
      "Epoch 12/50\n",
      "33/33 [==============================] - 5s 128ms/step - loss: 3.9157 - mae: 9.1413e-05\n",
      "Epoch 13/50\n",
      "33/33 [==============================] - 5s 128ms/step - loss: 3.8210 - mae: 9.1105e-05\n",
      "Epoch 14/50\n",
      "33/33 [==============================] - 5s 130ms/step - loss: 3.7022 - mae: 9.0411e-05\n",
      "Epoch 15/50\n",
      "33/33 [==============================] - 5s 133ms/step - loss: 3.5789 - mae: 8.9813e-05\n",
      "Epoch 16/50\n",
      "33/33 [==============================] - 5s 134ms/step - loss: 3.4631 - mae: 8.9098e-05\n",
      "Epoch 17/50\n",
      "33/33 [==============================] - 5s 133ms/step - loss: 3.4077 - mae: 8.9008e-05\n",
      "Epoch 18/50\n",
      "33/33 [==============================] - 5s 128ms/step - loss: 3.2756 - mae: 8.8089e-05\n",
      "Epoch 19/50\n",
      "33/33 [==============================] - 5s 127ms/step - loss: 3.1724 - mae: 8.7294e-05\n",
      "Epoch 20/50\n",
      "33/33 [==============================] - 5s 127ms/step - loss: 3.0560 - mae: 8.6609e-05\n",
      "Epoch 21/50\n",
      "33/33 [==============================] - 5s 127ms/step - loss: 2.9081 - mae: 8.5579e-05\n",
      "Epoch 22/50\n",
      "33/33 [==============================] - 5s 127ms/step - loss: 2.8063 - mae: 8.4722e-05\n",
      "Epoch 23/50\n",
      "33/33 [==============================] - 5s 127ms/step - loss: 2.6756 - mae: 8.3459e-05\n",
      "Epoch 24/50\n",
      "33/33 [==============================] - 5s 130ms/step - loss: 2.5127 - mae: 8.2162e-05\n",
      "Epoch 25/50\n",
      "33/33 [==============================] - 5s 127ms/step - loss: 2.4218 - mae: 8.0931e-05\n",
      "Epoch 26/50\n",
      "33/33 [==============================] - 5s 127ms/step - loss: 2.3451 - mae: 7.9762e-05\n",
      "Epoch 27/50\n",
      "33/33 [==============================] - 5s 127ms/step - loss: 2.1504 - mae: 7.7534e-05\n",
      "Epoch 28/50\n",
      "33/33 [==============================] - 5s 129ms/step - loss: 2.1158 - mae: 7.6566e-05\n",
      "Epoch 29/50\n",
      "33/33 [==============================] - 5s 132ms/step - loss: 1.9400 - mae: 7.4160e-05\n",
      "Epoch 30/50\n",
      "33/33 [==============================] - 5s 128ms/step - loss: 1.8609 - mae: 7.2692e-05\n",
      "Epoch 31/50\n",
      "33/33 [==============================] - 5s 127ms/step - loss: 1.6545 - mae: 6.9131e-05\n",
      "Epoch 32/50\n",
      "33/33 [==============================] - 5s 129ms/step - loss: 1.6562 - mae: 6.8232e-05\n",
      "Epoch 33/50\n",
      "33/33 [==============================] - 5s 130ms/step - loss: 1.4275 - mae: 6.4304e-05\n",
      "Epoch 34/50\n",
      "33/33 [==============================] - 5s 139ms/step - loss: 1.2965 - mae: 6.0918e-05\n",
      "Epoch 35/50\n",
      "33/33 [==============================] - 5s 127ms/step - loss: 1.2557 - mae: 5.9509e-05\n",
      "Epoch 36/50\n",
      "33/33 [==============================] - 5s 127ms/step - loss: 1.1267 - mae: 5.6259e-05\n",
      "Epoch 37/50\n",
      "33/33 [==============================] - 5s 129ms/step - loss: 1.0668 - mae: 5.3524e-05\n",
      "Epoch 38/50\n",
      "33/33 [==============================] - 5s 128ms/step - loss: 0.9481 - mae: 4.9839e-05\n",
      "Epoch 39/50\n",
      "33/33 [==============================] - 5s 127ms/step - loss: 0.8799 - mae: 4.7695e-05\n",
      "Epoch 40/50\n",
      "33/33 [==============================] - 5s 127ms/step - loss: 0.7921 - mae: 4.4403e-05\n",
      "Epoch 41/50\n",
      "33/33 [==============================] - 5s 127ms/step - loss: 0.6801 - mae: 4.0059e-05\n",
      "Epoch 42/50\n",
      "33/33 [==============================] - 5s 127ms/step - loss: 0.6469 - mae: 3.7884e-05\n",
      "Epoch 43/50\n",
      "33/33 [==============================] - 5s 127ms/step - loss: 0.5625 - mae: 3.4349e-05\n",
      "Epoch 44/50\n",
      "33/33 [==============================] - 5s 128ms/step - loss: 0.4716 - mae: 3.0340e-05\n",
      "Epoch 45/50\n",
      "33/33 [==============================] - 5s 127ms/step - loss: 0.4322 - mae: 2.8073e-05\n",
      "Epoch 46/50\n",
      "33/33 [==============================] - 5s 127ms/step - loss: 0.4178 - mae: 2.6521e-05\n",
      "Epoch 47/50\n",
      "33/33 [==============================] - 5s 127ms/step - loss: 0.3434 - mae: 2.4076e-05\n",
      "Epoch 48/50\n",
      "33/33 [==============================] - 5s 127ms/step - loss: 0.3351 - mae: 2.2441e-05\n",
      "Epoch 49/50\n",
      "33/33 [==============================] - 5s 127ms/step - loss: 0.2923 - mae: 2.0373e-05\n",
      "Epoch 50/50\n",
      "33/33 [==============================] - 5s 127ms/step - loss: 0.2669 - mae: 1.8984e-05\n",
      "-----------------Model /home/sanzharrko/Рабочий стол/Atom/creation_story/models/Multi_LSTM_RNN_Model_2_books.h5 saved.-----------------\n",
      "-----------Started learning-----------\n",
      "---1/69-----------\n",
      "Number of sequences: 11827 \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-14 14:26:28.493163: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 934238384 exceeds 10% of free system memory.\n",
      "2022-05-14 14:26:28.984605: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 934238384 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-14 14:26:29.756018: I tensorflow/stream_executor/cuda/cuda_driver.cc:739] failed to allocate 1.24G (1329623808 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "2022-05-14 14:26:29.756298: I tensorflow/stream_executor/cuda/cuda_driver.cc:739] failed to allocate 1.11G (1196661504 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "2022-05-14 14:26:29.756570: I tensorflow/stream_executor/cuda/cuda_driver.cc:739] failed to allocate 1.00G (1076995328 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "33/33 [==============================] - 13s 387ms/step - loss: 7.3037 - mae: 9.6557e-05\n",
      "Epoch 2/50\n",
      "33/33 [==============================] - 13s 390ms/step - loss: 5.7842 - mae: 9.5134e-05\n",
      "Epoch 3/50\n",
      "33/33 [==============================] - 13s 389ms/step - loss: 5.3811 - mae: 9.3537e-05\n",
      "Epoch 4/50\n",
      "33/33 [==============================] - 13s 388ms/step - loss: 5.0332 - mae: 9.2135e-05\n",
      "Epoch 5/50\n",
      "33/33 [==============================] - 13s 389ms/step - loss: 4.7238 - mae: 9.0714e-05\n",
      "Epoch 6/50\n",
      "33/33 [==============================] - 13s 389ms/step - loss: 4.3916 - mae: 8.9243e-05\n",
      "Epoch 7/50\n",
      "33/33 [==============================] - 13s 389ms/step - loss: 4.0644 - mae: 8.8035e-05\n",
      "Epoch 8/50\n",
      "33/33 [==============================] - 13s 389ms/step - loss: 3.7559 - mae: 8.6444e-05\n",
      "Epoch 9/50\n",
      "33/33 [==============================] - 13s 391ms/step - loss: 3.4291 - mae: 8.4926e-05\n",
      "Epoch 10/50\n",
      "33/33 [==============================] - 13s 391ms/step - loss: 3.1258 - mae: 8.3115e-05\n",
      "Epoch 11/50\n",
      "33/33 [==============================] - 13s 387ms/step - loss: 2.8395 - mae: 8.1266e-05\n",
      "Epoch 12/50\n",
      "33/33 [==============================] - 13s 388ms/step - loss: 2.5506 - mae: 7.8789e-05\n",
      "Epoch 13/50\n",
      "33/33 [==============================] - 13s 389ms/step - loss: 2.2807 - mae: 7.5932e-05\n",
      "Epoch 14/50\n",
      "33/33 [==============================] - 13s 388ms/step - loss: 2.0160 - mae: 7.2536e-05\n",
      "Epoch 15/50\n",
      "33/33 [==============================] - 13s 390ms/step - loss: 1.7843 - mae: 6.8719e-05\n",
      "Epoch 16/50\n",
      "33/33 [==============================] - 13s 389ms/step - loss: 1.5569 - mae: 6.4499e-05\n",
      "Epoch 17/50\n",
      "33/33 [==============================] - 13s 390ms/step - loss: 1.3512 - mae: 5.9615e-05\n",
      "Epoch 18/50\n",
      "33/33 [==============================] - 13s 392ms/step - loss: 1.1514 - mae: 5.4715e-05\n",
      "Epoch 19/50\n",
      "33/33 [==============================] - 13s 395ms/step - loss: 0.9958 - mae: 5.0119e-05\n",
      "Epoch 20/50\n",
      "33/33 [==============================] - 13s 391ms/step - loss: 0.8613 - mae: 4.5435e-05\n",
      "Epoch 21/50\n",
      "33/33 [==============================] - 15s 437ms/step - loss: 0.7238 - mae: 4.0720e-05\n",
      "Epoch 22/50\n",
      "33/33 [==============================] - 14s 404ms/step - loss: 0.5913 - mae: 3.5499e-05\n",
      "Epoch 23/50\n",
      "33/33 [==============================] - 14s 404ms/step - loss: 0.5234 - mae: 3.2348e-05\n",
      "Epoch 24/50\n",
      "33/33 [==============================] - 14s 404ms/step - loss: 0.4128 - mae: 2.7197e-05\n",
      "Epoch 25/50\n",
      "33/33 [==============================] - 14s 404ms/step - loss: 0.3705 - mae: 2.4896e-05\n",
      "Epoch 26/50\n",
      "33/33 [==============================] - 14s 404ms/step - loss: 0.2978 - mae: 2.1126e-05\n",
      "Epoch 27/50\n",
      "33/33 [==============================] - 14s 405ms/step - loss: 0.2295 - mae: 1.7136e-05\n",
      "Epoch 28/50\n",
      "33/33 [==============================] - 14s 404ms/step - loss: 0.2218 - mae: 1.6330e-05\n",
      "Epoch 29/50\n",
      "33/33 [==============================] - 14s 405ms/step - loss: 0.1693 - mae: 1.3071e-05\n",
      "Epoch 30/50\n",
      "33/33 [==============================] - 14s 406ms/step - loss: 0.1373 - mae: 1.0971e-05\n",
      "Epoch 31/50\n",
      "33/33 [==============================] - 14s 405ms/step - loss: 0.1262 - mae: 1.0103e-05\n",
      "Epoch 32/50\n",
      "33/33 [==============================] - 14s 406ms/step - loss: 0.1114 - mae: 9.0035e-06\n",
      "Epoch 33/50\n",
      "33/33 [==============================] - 14s 404ms/step - loss: 0.0902 - mae: 7.5446e-06\n",
      "Epoch 34/50\n",
      "33/33 [==============================] - 14s 406ms/step - loss: 0.0844 - mae: 6.9841e-06\n",
      "Epoch 35/50\n",
      "33/33 [==============================] - 14s 406ms/step - loss: 0.0759 - mae: 6.3815e-06\n",
      "Epoch 36/50\n",
      "33/33 [==============================] - 14s 404ms/step - loss: 0.0702 - mae: 5.9086e-06\n",
      "Epoch 37/50\n",
      "33/33 [==============================] - 14s 407ms/step - loss: 0.0677 - mae: 5.5811e-06\n",
      "Epoch 38/50\n",
      "33/33 [==============================] - 14s 404ms/step - loss: 0.0711 - mae: 5.7201e-06\n",
      "Epoch 39/50\n",
      "33/33 [==============================] - 14s 404ms/step - loss: 0.0760 - mae: 6.0216e-06\n",
      "Epoch 40/50\n",
      "33/33 [==============================] - 14s 406ms/step - loss: 0.0569 - mae: 4.7864e-06\n",
      "Epoch 41/50\n",
      "33/33 [==============================] - 14s 404ms/step - loss: 0.0412 - mae: 3.5752e-06\n",
      "Epoch 42/50\n",
      "33/33 [==============================] - 14s 405ms/step - loss: 0.0440 - mae: 3.6920e-06\n",
      "Epoch 43/50\n",
      "33/33 [==============================] - 14s 410ms/step - loss: 0.0342 - mae: 2.9216e-06\n",
      "Epoch 44/50\n",
      "33/33 [==============================] - 14s 402ms/step - loss: 0.0337 - mae: 2.8982e-06\n",
      "Epoch 45/50\n",
      "33/33 [==============================] - 13s 396ms/step - loss: 0.0387 - mae: 3.1918e-06\n",
      "Epoch 46/50\n",
      "33/33 [==============================] - 14s 397ms/step - loss: 0.0354 - mae: 2.9290e-06\n",
      "Epoch 47/50\n",
      "33/33 [==============================] - 14s 397ms/step - loss: 0.0346 - mae: 2.8556e-06\n",
      "Epoch 48/50\n",
      "33/33 [==============================] - 13s 397ms/step - loss: 0.0255 - mae: 2.2134e-06\n",
      "Epoch 49/50\n",
      "33/33 [==============================] - 13s 397ms/step - loss: 0.0276 - mae: 2.2296e-06\n",
      "Epoch 50/50\n",
      "33/33 [==============================] - 13s 396ms/step - loss: 0.0257 - mae: 2.1868e-06\n",
      "-----------------Model /home/sanzharrko/Рабочий стол/Atom/creation_story/models/Multi_LSTM_RNN_Model_2_books.h5 saved.-----------------\n",
      "-----------Started learning-----------\n",
      "---2/69-----------\n",
      "Number of sequences: 5449 \n",
      "\n",
      "Epoch 1/50\n",
      "33/33 [==============================] - 7s 210ms/step - loss: 7.4634 - mae: 9.5514e-05\n",
      "Epoch 2/50\n",
      "33/33 [==============================] - 7s 209ms/step - loss: 5.4368 - mae: 9.3839e-05\n",
      "Epoch 3/50\n",
      "33/33 [==============================] - 7s 209ms/step - loss: 4.7014 - mae: 9.1127e-05\n",
      "Epoch 4/50\n",
      "33/33 [==============================] - 7s 209ms/step - loss: 4.0100 - mae: 8.7432e-05\n",
      "Epoch 5/50\n",
      "33/33 [==============================] - 7s 210ms/step - loss: 3.2866 - mae: 8.2387e-05\n",
      "Epoch 6/50\n",
      "33/33 [==============================] - 7s 210ms/step - loss: 2.6137 - mae: 7.6510e-05\n",
      "Epoch 7/50\n",
      "33/33 [==============================] - 7s 210ms/step - loss: 2.0019 - mae: 6.8435e-05\n",
      "Epoch 8/50\n",
      "33/33 [==============================] - 7s 210ms/step - loss: 1.4271 - mae: 5.8398e-05\n",
      "Epoch 9/50\n",
      "33/33 [==============================] - 7s 210ms/step - loss: 0.9442 - mae: 4.6697e-05\n",
      "Epoch 10/50\n",
      "33/33 [==============================] - 7s 210ms/step - loss: 0.6655 - mae: 3.7075e-05\n",
      "Epoch 11/50\n",
      "33/33 [==============================] - 7s 210ms/step - loss: 0.4385 - mae: 2.7483e-05\n",
      "Epoch 12/50\n",
      "33/33 [==============================] - 7s 211ms/step - loss: 0.2762 - mae: 1.9570e-05\n",
      "Epoch 13/50\n",
      "33/33 [==============================] - 7s 210ms/step - loss: 0.2010 - mae: 1.4845e-05\n",
      "Epoch 14/50\n",
      "33/33 [==============================] - 7s 210ms/step - loss: 0.1325 - mae: 1.0536e-05\n",
      "Epoch 15/50\n",
      "33/33 [==============================] - 7s 210ms/step - loss: 0.1094 - mae: 8.6003e-06\n",
      "Epoch 16/50\n",
      "33/33 [==============================] - 7s 211ms/step - loss: 0.0779 - mae: 6.3736e-06\n",
      "Epoch 17/50\n",
      "33/33 [==============================] - 7s 211ms/step - loss: 0.0713 - mae: 5.8584e-06\n",
      "Epoch 18/50\n",
      "33/33 [==============================] - 7s 210ms/step - loss: 0.0537 - mae: 4.5061e-06\n",
      "Epoch 19/50\n",
      "33/33 [==============================] - 7s 210ms/step - loss: 0.0461 - mae: 3.9376e-06\n",
      "Epoch 20/50\n",
      "33/33 [==============================] - 7s 210ms/step - loss: 0.0426 - mae: 3.4742e-06\n",
      "Epoch 21/50\n",
      "33/33 [==============================] - 7s 211ms/step - loss: 0.0333 - mae: 2.7924e-06\n",
      "Epoch 22/50\n",
      "33/33 [==============================] - 7s 210ms/step - loss: 0.0351 - mae: 2.8878e-06\n",
      "Epoch 23/50\n",
      "33/33 [==============================] - 7s 210ms/step - loss: 0.0272 - mae: 2.3228e-06\n",
      "Epoch 24/50\n",
      "33/33 [==============================] - 7s 211ms/step - loss: 0.0204 - mae: 1.7865e-06\n",
      "Epoch 25/50\n",
      "33/33 [==============================] - 7s 210ms/step - loss: 0.0205 - mae: 1.7824e-06\n",
      "Epoch 26/50\n",
      "33/33 [==============================] - 7s 210ms/step - loss: 0.0217 - mae: 1.7698e-06\n",
      "Epoch 27/50\n",
      "33/33 [==============================] - 7s 210ms/step - loss: 0.0196 - mae: 1.5704e-06\n",
      "Epoch 28/50\n",
      "33/33 [==============================] - 7s 210ms/step - loss: 0.0179 - mae: 1.5145e-06\n",
      "Epoch 29/50\n",
      "33/33 [==============================] - 7s 211ms/step - loss: 0.0195 - mae: 1.5695e-06\n",
      "Epoch 30/50\n",
      "33/33 [==============================] - 7s 210ms/step - loss: 0.0147 - mae: 1.2733e-06\n",
      "Epoch 31/50\n",
      "33/33 [==============================] - 7s 210ms/step - loss: 0.0135 - mae: 1.1823e-06\n",
      "Epoch 32/50\n",
      "33/33 [==============================] - 7s 211ms/step - loss: 0.0090 - mae: 7.9631e-07\n",
      "Epoch 33/50\n",
      "33/33 [==============================] - 7s 210ms/step - loss: 0.0161 - mae: 1.2720e-06\n",
      "Epoch 34/50\n",
      "33/33 [==============================] - 7s 210ms/step - loss: 0.0119 - mae: 9.7493e-07\n",
      "Epoch 35/50\n",
      "33/33 [==============================] - 7s 211ms/step - loss: 0.0118 - mae: 9.9325e-07\n",
      "Epoch 36/50\n",
      "33/33 [==============================] - 7s 210ms/step - loss: 0.0127 - mae: 1.0258e-06\n",
      "Epoch 37/50\n",
      "33/33 [==============================] - 7s 211ms/step - loss: 0.0122 - mae: 1.0166e-06\n",
      "Epoch 38/50\n",
      "33/33 [==============================] - 7s 211ms/step - loss: 0.0136 - mae: 9.8639e-07\n",
      "Epoch 39/50\n",
      "33/33 [==============================] - 7s 211ms/step - loss: 0.0074 - mae: 6.6611e-07\n",
      "Epoch 40/50\n",
      "33/33 [==============================] - 7s 211ms/step - loss: 0.0079 - mae: 6.8284e-07\n",
      "Epoch 41/50\n",
      "33/33 [==============================] - 7s 211ms/step - loss: 0.0111 - mae: 8.3504e-07\n",
      "Epoch 42/50\n",
      "33/33 [==============================] - 7s 211ms/step - loss: 0.0052 - mae: 4.5239e-07\n",
      "Epoch 43/50\n",
      "33/33 [==============================] - 7s 211ms/step - loss: 0.0108 - mae: 8.1479e-07\n",
      "Epoch 44/50\n",
      "33/33 [==============================] - 7s 211ms/step - loss: 0.0058 - mae: 5.3552e-07\n",
      "Epoch 45/50\n",
      "33/33 [==============================] - 7s 211ms/step - loss: 0.0057 - mae: 4.9506e-07\n",
      "Epoch 46/50\n",
      "33/33 [==============================] - 7s 211ms/step - loss: 0.0055 - mae: 4.4320e-07\n",
      "Epoch 47/50\n",
      "33/33 [==============================] - 7s 211ms/step - loss: 0.0119 - mae: 7.3751e-07\n",
      "Epoch 48/50\n",
      "33/33 [==============================] - 7s 211ms/step - loss: 0.0083 - mae: 6.1207e-07\n",
      "Epoch 49/50\n",
      "33/33 [==============================] - 7s 211ms/step - loss: 0.0107 - mae: 5.3316e-07\n",
      "Epoch 50/50\n",
      "33/33 [==============================] - 7s 211ms/step - loss: 0.0050 - mae: 4.1931e-07\n",
      "-----------------Model /home/sanzharrko/Рабочий стол/Atom/creation_story/models/Multi_LSTM_RNN_Model_2_books.h5 saved.-----------------\n",
      "-----------Started learning-----------\n",
      "---3/69-----------\n",
      "Number of sequences: 5464 \n",
      "\n",
      "Epoch 1/50\n",
      "33/33 [==============================] - 7s 210ms/step - loss: 7.2540 - mae: 9.4027e-05\n",
      "Epoch 2/50\n",
      "33/33 [==============================] - 7s 210ms/step - loss: 5.3007 - mae: 9.1344e-05\n",
      "Epoch 3/50\n",
      "33/33 [==============================] - 7s 211ms/step - loss: 4.3501 - mae: 8.7064e-05\n",
      "Epoch 4/50\n",
      "33/33 [==============================] - 7s 210ms/step - loss: 3.4471 - mae: 8.0759e-05\n",
      "Epoch 5/50\n",
      "33/33 [==============================] - 7s 211ms/step - loss: 2.5774 - mae: 7.2145e-05\n",
      "Epoch 6/50\n",
      "33/33 [==============================] - 7s 211ms/step - loss: 1.8823 - mae: 6.2803e-05\n",
      "Epoch 7/50\n",
      "33/33 [==============================] - 7s 211ms/step - loss: 1.2130 - mae: 5.0001e-05\n",
      "Epoch 8/50\n",
      "33/33 [==============================] - 7s 211ms/step - loss: 0.7788 - mae: 3.8292e-05\n",
      "Epoch 9/50\n",
      "33/33 [==============================] - 7s 211ms/step - loss: 0.5031 - mae: 2.8699e-05\n",
      "Epoch 10/50\n",
      "33/33 [==============================] - 7s 211ms/step - loss: 0.3302 - mae: 2.0588e-05\n",
      "Epoch 11/50\n",
      "33/33 [==============================] - 7s 211ms/step - loss: 0.2191 - mae: 1.5323e-05\n",
      "Epoch 12/50\n",
      "33/33 [==============================] - 7s 211ms/step - loss: 0.1351 - mae: 1.0369e-05\n",
      "Epoch 13/50\n",
      "33/33 [==============================] - 7s 211ms/step - loss: 0.1070 - mae: 8.2682e-06\n",
      "Epoch 14/50\n",
      "33/33 [==============================] - 7s 211ms/step - loss: 0.0878 - mae: 6.8790e-06\n",
      "Epoch 15/50\n",
      "33/33 [==============================] - 7s 211ms/step - loss: 0.0705 - mae: 5.4279e-06\n",
      "Epoch 16/50\n",
      "33/33 [==============================] - 7s 211ms/step - loss: 0.0581 - mae: 4.6773e-06\n",
      "Epoch 17/50\n",
      "33/33 [==============================] - 7s 211ms/step - loss: 0.0423 - mae: 3.5259e-06\n",
      "Epoch 18/50\n",
      "33/33 [==============================] - 7s 211ms/step - loss: 0.0401 - mae: 3.3118e-06\n",
      "Epoch 19/50\n",
      "33/33 [==============================] - 7s 211ms/step - loss: 0.0339 - mae: 2.8523e-06\n",
      "Epoch 20/50\n",
      "33/33 [==============================] - 7s 211ms/step - loss: 0.0307 - mae: 2.5142e-06\n",
      "Epoch 21/50\n",
      "33/33 [==============================] - 7s 211ms/step - loss: 0.0266 - mae: 2.2777e-06\n",
      "Epoch 22/50\n",
      "33/33 [==============================] - 7s 211ms/step - loss: 0.0259 - mae: 1.9862e-06\n",
      "Epoch 23/50\n",
      "33/33 [==============================] - 7s 211ms/step - loss: 0.0210 - mae: 1.7490e-06\n",
      "Epoch 24/50\n",
      "33/33 [==============================] - 7s 211ms/step - loss: 0.0189 - mae: 1.5646e-06\n",
      "Epoch 25/50\n",
      "33/33 [==============================] - 7s 211ms/step - loss: 0.0277 - mae: 2.0157e-06\n",
      "Epoch 26/50\n",
      "33/33 [==============================] - 7s 211ms/step - loss: 0.0178 - mae: 1.4077e-06\n",
      "Epoch 27/50\n",
      "33/33 [==============================] - 7s 211ms/step - loss: 0.0129 - mae: 1.1292e-06\n",
      "Epoch 28/50\n",
      "33/33 [==============================] - 7s 211ms/step - loss: 0.0120 - mae: 1.0420e-06\n",
      "Epoch 29/50\n",
      "33/33 [==============================] - 7s 211ms/step - loss: 0.0193 - mae: 1.4540e-06\n",
      "Epoch 30/50\n",
      "33/33 [==============================] - 7s 211ms/step - loss: 0.0095 - mae: 8.6139e-07\n",
      "Epoch 31/50\n",
      "33/33 [==============================] - 7s 211ms/step - loss: 0.0172 - mae: 1.3658e-06\n",
      "Epoch 32/50\n",
      "33/33 [==============================] - 7s 211ms/step - loss: 0.0109 - mae: 8.9941e-07\n",
      "Epoch 33/50\n",
      "33/33 [==============================] - 7s 210ms/step - loss: 0.0079 - mae: 7.1455e-07\n",
      "Epoch 34/50\n",
      "33/33 [==============================] - 7s 211ms/step - loss: 0.0089 - mae: 7.8317e-07\n",
      "Epoch 35/50\n",
      "33/33 [==============================] - 7s 211ms/step - loss: 0.0100 - mae: 8.5491e-07\n",
      "Epoch 36/50\n",
      "33/33 [==============================] - 7s 211ms/step - loss: 0.0063 - mae: 5.6512e-07\n",
      "Epoch 37/50\n",
      "33/33 [==============================] - 7s 211ms/step - loss: 0.0118 - mae: 9.1663e-07\n",
      "Epoch 38/50\n",
      "33/33 [==============================] - 7s 211ms/step - loss: 0.0080 - mae: 6.2855e-07\n",
      "Epoch 39/50\n",
      "33/33 [==============================] - 7s 211ms/step - loss: 0.0055 - mae: 4.4976e-07\n",
      "Epoch 40/50\n",
      "33/33 [==============================] - 7s 211ms/step - loss: 0.0072 - mae: 5.6281e-07\n",
      "Epoch 41/50\n",
      "33/33 [==============================] - 7s 211ms/step - loss: 0.0101 - mae: 7.3592e-07\n",
      "Epoch 42/50\n",
      "33/33 [==============================] - 7s 211ms/step - loss: 0.0099 - mae: 7.3917e-07\n",
      "Epoch 43/50\n",
      "33/33 [==============================] - 7s 211ms/step - loss: 0.0083 - mae: 6.6526e-07\n",
      "Epoch 44/50\n",
      "33/33 [==============================] - 7s 211ms/step - loss: 0.0041 - mae: 3.5934e-07\n",
      "Epoch 45/50\n",
      "33/33 [==============================] - 7s 211ms/step - loss: 0.0044 - mae: 3.7555e-07\n",
      "Epoch 46/50\n",
      "33/33 [==============================] - 7s 211ms/step - loss: 0.0067 - mae: 5.5157e-07\n",
      "Epoch 47/50\n",
      "33/33 [==============================] - 7s 211ms/step - loss: 0.0068 - mae: 5.8952e-07\n",
      "Epoch 48/50\n",
      "33/33 [==============================] - 7s 211ms/step - loss: 0.0087 - mae: 5.7999e-07\n",
      "Epoch 49/50\n",
      "33/33 [==============================] - 7s 211ms/step - loss: 0.0064 - mae: 4.7583e-07\n",
      "Epoch 50/50\n",
      "33/33 [==============================] - 7s 211ms/step - loss: 0.0049 - mae: 3.7367e-07\n",
      "-----------------Model /home/sanzharrko/Рабочий стол/Atom/creation_story/models/Multi_LSTM_RNN_Model_2_books.h5 saved.-----------------\n",
      "-----------Started learning-----------\n",
      "---4/69-----------\n",
      "Number of sequences: 4553 \n",
      "\n",
      "Epoch 1/50\n",
      "33/33 [==============================] - 7s 197ms/step - loss: 7.1851 - mae: 9.2122e-05\n",
      "Epoch 2/50\n",
      "33/33 [==============================] - 7s 197ms/step - loss: 4.9726 - mae: 8.7622e-05\n",
      "Epoch 3/50\n",
      "33/33 [==============================] - 7s 196ms/step - loss: 3.6996 - mae: 7.9841e-05\n",
      "Epoch 4/50\n",
      "33/33 [==============================] - 7s 197ms/step - loss: 2.5448 - mae: 6.8883e-05\n",
      "Epoch 5/50\n",
      "33/33 [==============================] - 7s 197ms/step - loss: 1.6155 - mae: 5.5709e-05\n",
      "Epoch 6/50\n",
      "33/33 [==============================] - 7s 197ms/step - loss: 0.9638 - mae: 4.2219e-05\n",
      "Epoch 7/50\n",
      "33/33 [==============================] - 7s 197ms/step - loss: 0.5425 - mae: 2.9617e-05\n",
      "Epoch 8/50\n",
      "33/33 [==============================] - 7s 197ms/step - loss: 0.3265 - mae: 2.0633e-05\n",
      "Epoch 9/50\n",
      "33/33 [==============================] - 7s 197ms/step - loss: 0.1896 - mae: 1.3542e-05\n",
      "Epoch 10/50\n",
      "33/33 [==============================] - 7s 197ms/step - loss: 0.1283 - mae: 9.7014e-06\n",
      "Epoch 11/50\n",
      "33/33 [==============================] - 7s 197ms/step - loss: 0.0996 - mae: 7.6393e-06\n",
      "Epoch 12/50\n",
      "33/33 [==============================] - 7s 197ms/step - loss: 0.0811 - mae: 6.2165e-06\n",
      "Epoch 13/50\n",
      "33/33 [==============================] - 7s 197ms/step - loss: 0.0629 - mae: 4.8570e-06\n",
      "Epoch 14/50\n",
      "33/33 [==============================] - 7s 197ms/step - loss: 0.0500 - mae: 4.0042e-06\n",
      "Epoch 15/50\n",
      "33/33 [==============================] - 7s 197ms/step - loss: 0.0474 - mae: 3.7265e-06\n",
      "Epoch 16/50\n",
      "33/33 [==============================] - 7s 197ms/step - loss: 0.0295 - mae: 2.4800e-06\n",
      "Epoch 17/50\n",
      "33/33 [==============================] - 7s 197ms/step - loss: 0.0396 - mae: 2.8909e-06\n",
      "Epoch 18/50\n",
      "33/33 [==============================] - 7s 197ms/step - loss: 0.0243 - mae: 2.0644e-06\n",
      "Epoch 19/50\n",
      "33/33 [==============================] - 7s 197ms/step - loss: 0.0269 - mae: 2.1355e-06\n",
      "Epoch 20/50\n",
      "33/33 [==============================] - 7s 197ms/step - loss: 0.0206 - mae: 1.6923e-06\n",
      "Epoch 21/50\n",
      "33/33 [==============================] - 7s 197ms/step - loss: 0.0164 - mae: 1.4139e-06\n",
      "Epoch 22/50\n",
      "33/33 [==============================] - 7s 197ms/step - loss: 0.0236 - mae: 1.8132e-06\n",
      "Epoch 23/50\n",
      "33/33 [==============================] - 7s 197ms/step - loss: 0.0144 - mae: 1.2325e-06\n",
      "Epoch 24/50\n",
      "33/33 [==============================] - 7s 197ms/step - loss: 0.0133 - mae: 1.1019e-06\n",
      "Epoch 25/50\n",
      "33/33 [==============================] - 7s 197ms/step - loss: 0.0216 - mae: 1.4646e-06\n",
      "Epoch 26/50\n",
      "33/33 [==============================] - 7s 197ms/step - loss: 0.0116 - mae: 9.9880e-07\n",
      "Epoch 27/50\n",
      "33/33 [==============================] - 7s 197ms/step - loss: 0.0158 - mae: 1.1431e-06\n",
      "Epoch 28/50\n",
      "33/33 [==============================] - 7s 197ms/step - loss: 0.0140 - mae: 1.0295e-06\n",
      "Epoch 29/50\n",
      "33/33 [==============================] - 7s 197ms/step - loss: 0.0096 - mae: 7.9292e-07\n",
      "Epoch 30/50\n",
      "33/33 [==============================] - 7s 197ms/step - loss: 0.0074 - mae: 6.3712e-07\n",
      "Epoch 31/50\n",
      "33/33 [==============================] - 7s 197ms/step - loss: 0.0091 - mae: 7.2201e-07\n",
      "Epoch 32/50\n",
      "33/33 [==============================] - 7s 197ms/step - loss: 0.0065 - mae: 5.4084e-07\n",
      "Epoch 33/50\n",
      "33/33 [==============================] - 7s 197ms/step - loss: 0.0080 - mae: 6.6052e-07\n",
      "Epoch 34/50\n",
      "33/33 [==============================] - 7s 197ms/step - loss: 0.0108 - mae: 8.2827e-07\n",
      "Epoch 35/50\n",
      "33/33 [==============================] - 7s 198ms/step - loss: 0.0057 - mae: 4.6024e-07\n",
      "Epoch 36/50\n",
      "33/33 [==============================] - 7s 198ms/step - loss: 0.0114 - mae: 7.1121e-07\n",
      "Epoch 37/50\n",
      "33/33 [==============================] - 7s 198ms/step - loss: 0.0068 - mae: 5.3559e-07\n",
      "Epoch 38/50\n",
      "33/33 [==============================] - 7s 197ms/step - loss: 0.0095 - mae: 6.2721e-07\n",
      "Epoch 39/50\n",
      "33/33 [==============================] - 7s 197ms/step - loss: 0.0089 - mae: 5.6732e-07\n",
      "Epoch 40/50\n",
      "33/33 [==============================] - 7s 197ms/step - loss: 0.0065 - mae: 4.9933e-07\n",
      "Epoch 41/50\n",
      "33/33 [==============================] - 7s 197ms/step - loss: 0.0065 - mae: 5.7126e-07\n",
      "Epoch 42/50\n",
      "33/33 [==============================] - 7s 197ms/step - loss: 0.0082 - mae: 5.8303e-07\n",
      "Epoch 43/50\n",
      "33/33 [==============================] - 7s 197ms/step - loss: 0.0044 - mae: 3.3874e-07\n",
      "Epoch 44/50\n",
      "33/33 [==============================] - 7s 197ms/step - loss: 0.0039 - mae: 3.4337e-07\n",
      "Epoch 45/50\n",
      "33/33 [==============================] - 7s 197ms/step - loss: 0.0085 - mae: 5.6279e-07\n",
      "Epoch 46/50\n",
      "33/33 [==============================] - 7s 197ms/step - loss: 0.0031 - mae: 2.4165e-07\n",
      "Epoch 47/50\n",
      "33/33 [==============================] - 7s 197ms/step - loss: 0.0084 - mae: 5.0742e-07\n",
      "Epoch 48/50\n",
      "33/33 [==============================] - 7s 197ms/step - loss: 0.0065 - mae: 4.8279e-07\n",
      "Epoch 49/50\n",
      "33/33 [==============================] - 7s 197ms/step - loss: 0.0087 - mae: 5.6115e-07\n",
      "Epoch 50/50\n",
      "33/33 [==============================] - 7s 197ms/step - loss: 0.0025 - mae: 2.3940e-07\n",
      "-----------------Model /home/sanzharrko/Рабочий стол/Atom/creation_story/models/Multi_LSTM_RNN_Model_2_books.h5 saved.-----------------\n",
      "-----------Started learning-----------\n",
      "---5/69-----------\n",
      "Number of sequences: 6961 \n",
      "\n",
      "Epoch 1/50\n",
      "33/33 [==============================] - 10s 275ms/step - loss: 7.2430 - mae: 9.5442e-05\n",
      "Epoch 2/50\n",
      "33/33 [==============================] - 10s 275ms/step - loss: 5.4655 - mae: 9.3465e-05\n",
      "Epoch 3/50\n",
      "33/33 [==============================] - 9s 275ms/step - loss: 4.5178 - mae: 8.8744e-05\n",
      "Epoch 4/50\n",
      "33/33 [==============================] - 9s 275ms/step - loss: 3.6343 - mae: 8.2406e-05\n",
      "Epoch 5/50\n",
      "33/33 [==============================] - 9s 275ms/step - loss: 2.8361 - mae: 7.4565e-05\n",
      "Epoch 6/50\n",
      "33/33 [==============================] - 9s 275ms/step - loss: 2.1155 - mae: 6.5678e-05\n",
      "Epoch 7/50\n",
      "33/33 [==============================] - 10s 276ms/step - loss: 1.5315 - mae: 5.5390e-05\n",
      "Epoch 8/50\n",
      "33/33 [==============================] - 9s 274ms/step - loss: 1.0241 - mae: 4.4032e-05\n",
      "Epoch 9/50\n",
      "33/33 [==============================] - 10s 276ms/step - loss: 0.6851 - mae: 3.4126e-05\n",
      "Epoch 10/50\n",
      "33/33 [==============================] - 9s 275ms/step - loss: 0.4341 - mae: 2.5014e-05\n",
      "Epoch 11/50\n",
      "33/33 [==============================] - 9s 274ms/step - loss: 0.2796 - mae: 1.8246e-05\n",
      "Epoch 12/50\n",
      "33/33 [==============================] - 10s 275ms/step - loss: 0.1819 - mae: 1.2940e-05\n",
      "Epoch 13/50\n",
      "33/33 [==============================] - 9s 275ms/step - loss: 0.1426 - mae: 1.0408e-05\n",
      "Epoch 14/50\n",
      "33/33 [==============================] - 10s 275ms/step - loss: 0.1123 - mae: 8.3157e-06\n",
      "Epoch 15/50\n",
      "33/33 [==============================] - 9s 275ms/step - loss: 0.0880 - mae: 6.6251e-06\n",
      "Epoch 16/50\n",
      "33/33 [==============================] - 9s 275ms/step - loss: 0.0824 - mae: 5.9730e-06\n",
      "Epoch 17/50\n",
      "33/33 [==============================] - 10s 276ms/step - loss: 0.0609 - mae: 4.6958e-06\n",
      "Epoch 18/50\n",
      "33/33 [==============================] - 10s 276ms/step - loss: 0.0479 - mae: 3.8448e-06\n",
      "Epoch 19/50\n",
      "33/33 [==============================] - 10s 275ms/step - loss: 0.0390 - mae: 3.1774e-06\n",
      "Epoch 20/50\n",
      "33/33 [==============================] - 9s 274ms/step - loss: 0.0339 - mae: 2.8423e-06\n",
      "Epoch 21/50\n",
      "33/33 [==============================] - 9s 275ms/step - loss: 0.0346 - mae: 2.7720e-06\n",
      "Epoch 22/50\n",
      "33/33 [==============================] - 9s 276ms/step - loss: 0.0322 - mae: 2.5078e-06\n",
      "Epoch 23/50\n",
      "33/33 [==============================] - 9s 276ms/step - loss: 0.0294 - mae: 2.3877e-06\n",
      "Epoch 24/50\n",
      "33/33 [==============================] - 9s 276ms/step - loss: 0.0257 - mae: 2.1343e-06\n",
      "Epoch 25/50\n",
      "33/33 [==============================] - 9s 276ms/step - loss: 0.0246 - mae: 1.9561e-06\n",
      "Epoch 26/50\n",
      "33/33 [==============================] - 10s 276ms/step - loss: 0.0219 - mae: 1.7299e-06\n",
      "Epoch 27/50\n",
      "33/33 [==============================] - 10s 276ms/step - loss: 0.0213 - mae: 1.7003e-06\n",
      "Epoch 28/50\n",
      "33/33 [==============================] - 9s 275ms/step - loss: 0.0184 - mae: 1.4797e-06\n",
      "Epoch 29/50\n",
      "33/33 [==============================] - 9s 275ms/step - loss: 0.0158 - mae: 1.3144e-06\n",
      "Epoch 30/50\n",
      "33/33 [==============================] - 9s 275ms/step - loss: 0.0131 - mae: 1.1138e-06\n",
      "Epoch 31/50\n",
      "33/33 [==============================] - 10s 275ms/step - loss: 0.0147 - mae: 1.2521e-06\n",
      "Epoch 32/50\n",
      "33/33 [==============================] - 9s 274ms/step - loss: 0.0162 - mae: 1.2956e-06\n",
      "Epoch 33/50\n",
      "33/33 [==============================] - 10s 276ms/step - loss: 0.0152 - mae: 1.1548e-06\n",
      "Epoch 34/50\n",
      "33/33 [==============================] - 10s 275ms/step - loss: 0.0149 - mae: 1.1547e-06\n",
      "Epoch 35/50\n",
      "33/33 [==============================] - 10s 276ms/step - loss: 0.0119 - mae: 9.7989e-07\n",
      "Epoch 36/50\n",
      "33/33 [==============================] - 10s 275ms/step - loss: 0.0092 - mae: 7.7763e-07\n",
      "Epoch 37/50\n",
      "33/33 [==============================] - 10s 276ms/step - loss: 0.0078 - mae: 6.8671e-07\n",
      "Epoch 38/50\n",
      "33/33 [==============================] - 10s 275ms/step - loss: 0.0105 - mae: 8.1470e-07\n",
      "Epoch 39/50\n",
      "33/33 [==============================] - 10s 275ms/step - loss: 0.0138 - mae: 1.0544e-06\n",
      "Epoch 40/50\n",
      "33/33 [==============================] - 9s 275ms/step - loss: 0.0124 - mae: 8.4256e-07\n",
      "Epoch 41/50\n",
      "33/33 [==============================] - 9s 275ms/step - loss: 0.0138 - mae: 1.0577e-06\n",
      "Epoch 42/50\n",
      "33/33 [==============================] - 10s 277ms/step - loss: 0.0093 - mae: 7.1355e-07\n",
      "Epoch 43/50\n",
      "33/33 [==============================] - 10s 277ms/step - loss: 0.0081 - mae: 6.8155e-07\n",
      "Epoch 44/50\n",
      "33/33 [==============================] - 9s 275ms/step - loss: 0.0096 - mae: 7.1680e-07\n",
      "Epoch 45/50\n",
      "33/33 [==============================] - 9s 275ms/step - loss: 0.0087 - mae: 7.0841e-07\n",
      "Epoch 46/50\n",
      "33/33 [==============================] - 10s 275ms/step - loss: 0.0070 - mae: 5.6421e-07\n",
      "Epoch 47/50\n",
      "33/33 [==============================] - 10s 276ms/step - loss: 0.0074 - mae: 6.1406e-07\n",
      "Epoch 48/50\n",
      "33/33 [==============================] - 9s 275ms/step - loss: 0.0056 - mae: 4.7567e-07\n",
      "Epoch 49/50\n",
      "33/33 [==============================] - 10s 275ms/step - loss: 0.0085 - mae: 5.8564e-07\n",
      "Epoch 50/50\n",
      "33/33 [==============================] - 9s 275ms/step - loss: 0.0065 - mae: 5.5811e-07\n",
      "-----------------Model /home/sanzharrko/Рабочий стол/Atom/creation_story/models/Multi_LSTM_RNN_Model_2_books.h5 saved.-----------------\n",
      "-----------Started learning-----------\n",
      "---6/69-----------\n",
      "Number of sequences: 6330 \n",
      "\n",
      "Epoch 1/50\n",
      "33/33 [==============================] - 9s 252ms/step - loss: 7.4793 - mae: 9.4044e-05\n",
      "Epoch 2/50\n",
      "33/33 [==============================] - 9s 252ms/step - loss: 5.4689 - mae: 9.0678e-05\n",
      "Epoch 3/50\n",
      "33/33 [==============================] - 9s 253ms/step - loss: 4.2800 - mae: 8.3952e-05\n",
      "Epoch 4/50\n",
      "33/33 [==============================] - 9s 252ms/step - loss: 3.2271 - mae: 7.5225e-05\n",
      "Epoch 5/50\n",
      "33/33 [==============================] - 9s 253ms/step - loss: 2.2757 - mae: 6.4276e-05\n",
      "Epoch 6/50\n",
      "33/33 [==============================] - 9s 253ms/step - loss: 1.5206 - mae: 5.2995e-05\n",
      "Epoch 7/50\n",
      "33/33 [==============================] - 9s 253ms/step - loss: 1.0004 - mae: 4.1932e-05\n",
      "Epoch 8/50\n",
      "33/33 [==============================] - 9s 253ms/step - loss: 0.6006 - mae: 3.0313e-05\n",
      "Epoch 9/50\n",
      "33/33 [==============================] - 9s 253ms/step - loss: 0.3804 - mae: 2.1865e-05\n",
      "Epoch 10/50\n",
      "33/33 [==============================] - 9s 253ms/step - loss: 0.2469 - mae: 1.5741e-05\n",
      "Epoch 11/50\n",
      "33/33 [==============================] - 9s 253ms/step - loss: 0.1489 - mae: 1.0627e-05\n",
      "Epoch 12/50\n",
      "33/33 [==============================] - 9s 253ms/step - loss: 0.1259 - mae: 9.0490e-06\n",
      "Epoch 13/50\n",
      "33/33 [==============================] - 9s 253ms/step - loss: 0.0956 - mae: 7.0434e-06\n",
      "Epoch 14/50\n",
      "33/33 [==============================] - 9s 253ms/step - loss: 0.0707 - mae: 5.5103e-06\n",
      "Epoch 15/50\n",
      "33/33 [==============================] - 9s 253ms/step - loss: 0.0667 - mae: 5.0154e-06\n",
      "Epoch 16/50\n",
      "33/33 [==============================] - 9s 253ms/step - loss: 0.0537 - mae: 4.1646e-06\n",
      "Epoch 17/50\n",
      "33/33 [==============================] - 9s 253ms/step - loss: 0.0432 - mae: 3.4031e-06\n",
      "Epoch 18/50\n",
      "33/33 [==============================] - 9s 253ms/step - loss: 0.0445 - mae: 3.3607e-06\n",
      "Epoch 19/50\n",
      "33/33 [==============================] - 9s 271ms/step - loss: 0.0383 - mae: 2.9732e-06\n",
      "Epoch 20/50\n",
      "33/33 [==============================] - 9s 263ms/step - loss: 0.0292 - mae: 2.3617e-06\n",
      "Epoch 21/50\n",
      "33/33 [==============================] - 9s 263ms/step - loss: 0.0278 - mae: 2.2528e-06\n",
      "Epoch 22/50\n",
      "33/33 [==============================] - 9s 263ms/step - loss: 0.0275 - mae: 2.0876e-06\n",
      "Epoch 23/50\n",
      "33/33 [==============================] - 9s 263ms/step - loss: 0.0235 - mae: 1.8558e-06\n",
      "Epoch 24/50\n",
      "33/33 [==============================] - 9s 263ms/step - loss: 0.0280 - mae: 2.0089e-06\n",
      "Epoch 25/50\n",
      "33/33 [==============================] - 9s 264ms/step - loss: 0.0230 - mae: 1.8169e-06\n",
      "Epoch 26/50\n",
      "33/33 [==============================] - 9s 264ms/step - loss: 0.0207 - mae: 1.6341e-06\n",
      "Epoch 27/50\n",
      "33/33 [==============================] - 9s 263ms/step - loss: 0.0158 - mae: 1.2844e-06\n",
      "Epoch 28/50\n",
      "33/33 [==============================] - 9s 263ms/step - loss: 0.0192 - mae: 1.5291e-06\n",
      "Epoch 29/50\n",
      "33/33 [==============================] - 9s 263ms/step - loss: 0.0143 - mae: 1.1522e-06\n",
      "Epoch 30/50\n",
      "33/33 [==============================] - 9s 263ms/step - loss: 0.0145 - mae: 1.1487e-06\n",
      "Epoch 31/50\n",
      "33/33 [==============================] - 9s 263ms/step - loss: 0.0170 - mae: 1.2859e-06\n",
      "Epoch 32/50\n",
      "33/33 [==============================] - 9s 263ms/step - loss: 0.0165 - mae: 1.2457e-06\n",
      "Epoch 33/50\n",
      "33/33 [==============================] - 9s 263ms/step - loss: 0.0139 - mae: 1.0695e-06\n",
      "Epoch 34/50\n",
      "33/33 [==============================] - 9s 263ms/step - loss: 0.0130 - mae: 1.0301e-06\n",
      "Epoch 35/50\n",
      "33/33 [==============================] - 9s 263ms/step - loss: 0.0140 - mae: 1.1120e-06\n",
      "Epoch 36/50\n",
      "33/33 [==============================] - 9s 263ms/step - loss: 0.0102 - mae: 8.3884e-07\n",
      "Epoch 37/50\n",
      "33/33 [==============================] - 10s 292ms/step - loss: 0.0130 - mae: 9.9948e-07\n",
      "Epoch 38/50\n",
      "33/33 [==============================] - 10s 286ms/step - loss: 0.0096 - mae: 8.0675e-07\n",
      "Epoch 39/50\n",
      "33/33 [==============================] - 9s 270ms/step - loss: 0.0124 - mae: 9.0374e-07\n",
      "Epoch 40/50\n",
      "33/33 [==============================] - 9s 274ms/step - loss: 0.0087 - mae: 7.1612e-07\n",
      "Epoch 41/50\n",
      "33/33 [==============================] - 9s 269ms/step - loss: 0.0124 - mae: 8.5714e-07\n",
      "Epoch 42/50\n",
      "33/33 [==============================] - 9s 272ms/step - loss: 0.0091 - mae: 6.3933e-07\n",
      "Epoch 43/50\n",
      "33/33 [==============================] - 9s 266ms/step - loss: 0.0118 - mae: 8.6536e-07\n",
      "Epoch 44/50\n",
      "33/33 [==============================] - 9s 266ms/step - loss: 0.0106 - mae: 7.4360e-07\n",
      "Epoch 45/50\n",
      "33/33 [==============================] - 9s 267ms/step - loss: 0.0076 - mae: 6.2669e-07\n",
      "Epoch 46/50\n",
      "33/33 [==============================] - 9s 267ms/step - loss: 0.0101 - mae: 7.2962e-07\n",
      "Epoch 47/50\n",
      "33/33 [==============================] - 9s 266ms/step - loss: 0.0086 - mae: 6.6363e-07\n",
      "Epoch 48/50\n",
      "33/33 [==============================] - 9s 266ms/step - loss: 0.0055 - mae: 4.5501e-07\n",
      "Epoch 49/50\n",
      "33/33 [==============================] - 9s 267ms/step - loss: 0.0066 - mae: 4.7594e-07\n",
      "Epoch 50/50\n",
      "33/33 [==============================] - 9s 267ms/step - loss: 0.0096 - mae: 6.5711e-07\n",
      "-----------------Model /home/sanzharrko/Рабочий стол/Atom/creation_story/models/Multi_LSTM_RNN_Model_2_books.h5 saved.-----------------\n",
      "-----------Started learning-----------\n",
      "---7/69-----------\n",
      "Number of sequences: 5522 \n",
      "\n",
      "Epoch 1/50\n",
      "33/33 [==============================] - 8s 221ms/step - loss: 7.2110 - mae: 9.3752e-05\n",
      "Epoch 2/50\n",
      "33/33 [==============================] - 8s 220ms/step - loss: 5.2912 - mae: 8.9736e-05\n",
      "Epoch 3/50\n",
      "33/33 [==============================] - 8s 221ms/step - loss: 4.1258 - mae: 8.2597e-05\n",
      "Epoch 4/50\n",
      "33/33 [==============================] - 8s 221ms/step - loss: 3.0340 - mae: 7.3354e-05\n",
      "Epoch 5/50\n",
      "33/33 [==============================] - 8s 220ms/step - loss: 2.1164 - mae: 6.2429e-05\n",
      "Epoch 6/50\n",
      "33/33 [==============================] - 8s 220ms/step - loss: 1.3769 - mae: 5.0388e-05\n",
      "Epoch 7/50\n",
      "33/33 [==============================] - 8s 221ms/step - loss: 0.8746 - mae: 3.8964e-05\n",
      "Epoch 8/50\n",
      "33/33 [==============================] - 8s 221ms/step - loss: 0.5190 - mae: 2.7503e-05\n",
      "Epoch 9/50\n",
      "33/33 [==============================] - 8s 220ms/step - loss: 0.3210 - mae: 1.9486e-05\n",
      "Epoch 10/50\n",
      "33/33 [==============================] - 8s 221ms/step - loss: 0.1922 - mae: 1.3195e-05\n",
      "Epoch 11/50\n",
      "33/33 [==============================] - 8s 220ms/step - loss: 0.1442 - mae: 9.9822e-06\n",
      "Epoch 12/50\n",
      "33/33 [==============================] - 8s 221ms/step - loss: 0.1062 - mae: 7.7449e-06\n",
      "Epoch 13/50\n",
      "33/33 [==============================] - 8s 221ms/step - loss: 0.0897 - mae: 6.5722e-06\n",
      "Epoch 14/50\n",
      "33/33 [==============================] - 8s 220ms/step - loss: 0.0646 - mae: 4.8803e-06\n",
      "Epoch 15/50\n",
      "33/33 [==============================] - 8s 220ms/step - loss: 0.0512 - mae: 4.0752e-06\n",
      "Epoch 16/50\n",
      "33/33 [==============================] - 8s 221ms/step - loss: 0.0435 - mae: 3.4331e-06\n",
      "Epoch 17/50\n",
      "33/33 [==============================] - 8s 221ms/step - loss: 0.0352 - mae: 2.8190e-06\n",
      "Epoch 18/50\n",
      "33/33 [==============================] - 8s 221ms/step - loss: 0.0397 - mae: 3.0359e-06\n",
      "Epoch 19/50\n",
      "33/33 [==============================] - 8s 220ms/step - loss: 0.0377 - mae: 2.7305e-06\n",
      "Epoch 20/50\n",
      "33/33 [==============================] - 8s 221ms/step - loss: 0.0313 - mae: 2.3871e-06\n",
      "Epoch 21/50\n",
      "33/33 [==============================] - 8s 220ms/step - loss: 0.0291 - mae: 2.2232e-06\n",
      "Epoch 22/50\n",
      "33/33 [==============================] - 8s 222ms/step - loss: 0.0247 - mae: 1.9513e-06\n",
      "Epoch 23/50\n",
      "33/33 [==============================] - 8s 221ms/step - loss: 0.0238 - mae: 1.9015e-06\n",
      "Epoch 24/50\n",
      "33/33 [==============================] - 8s 221ms/step - loss: 0.0274 - mae: 1.9824e-06\n",
      "Epoch 25/50\n",
      "33/33 [==============================] - 8s 221ms/step - loss: 0.0253 - mae: 1.8665e-06\n",
      "Epoch 26/50\n",
      "33/33 [==============================] - 8s 221ms/step - loss: 0.0216 - mae: 1.6085e-06\n",
      "Epoch 27/50\n",
      "33/33 [==============================] - 8s 221ms/step - loss: 0.0144 - mae: 1.1477e-06\n",
      "Epoch 28/50\n",
      "33/33 [==============================] - 8s 221ms/step - loss: 0.0175 - mae: 1.1827e-06\n",
      "Epoch 29/50\n",
      "33/33 [==============================] - 8s 235ms/step - loss: 0.0179 - mae: 1.2583e-06\n",
      "Epoch 30/50\n",
      "33/33 [==============================] - 7s 214ms/step - loss: 0.0133 - mae: 1.1167e-06\n",
      "Epoch 31/50\n",
      "33/33 [==============================] - 7s 211ms/step - loss: 0.0111 - mae: 8.8403e-07\n",
      "Epoch 32/50\n",
      "33/33 [==============================] - 7s 212ms/step - loss: 0.0165 - mae: 1.1243e-06\n",
      "Epoch 33/50\n",
      "33/33 [==============================] - 7s 211ms/step - loss: 0.0131 - mae: 1.0474e-06\n",
      "Epoch 34/50\n",
      "33/33 [==============================] - 7s 211ms/step - loss: 0.0138 - mae: 1.0247e-06\n",
      "Epoch 35/50\n",
      "33/33 [==============================] - 7s 211ms/step - loss: 0.0123 - mae: 9.3960e-07\n",
      "Epoch 36/50\n",
      "33/33 [==============================] - 7s 212ms/step - loss: 0.0087 - mae: 7.3345e-07\n",
      "Epoch 37/50\n",
      "33/33 [==============================] - 7s 211ms/step - loss: 0.0084 - mae: 6.5704e-07\n",
      "Epoch 38/50\n",
      "33/33 [==============================] - 7s 211ms/step - loss: 0.0086 - mae: 6.7680e-07\n",
      "Epoch 39/50\n",
      "33/33 [==============================] - 7s 212ms/step - loss: 0.0082 - mae: 6.5402e-07\n",
      "Epoch 40/50\n",
      "33/33 [==============================] - 7s 211ms/step - loss: 0.0104 - mae: 7.7932e-07\n",
      "Epoch 41/50\n",
      "33/33 [==============================] - 7s 212ms/step - loss: 0.0107 - mae: 7.3901e-07\n",
      "Epoch 42/50\n",
      "33/33 [==============================] - 7s 211ms/step - loss: 0.0078 - mae: 6.2632e-07\n",
      "Epoch 43/50\n",
      "33/33 [==============================] - 7s 211ms/step - loss: 0.0107 - mae: 6.9081e-07\n",
      "Epoch 44/50\n",
      "33/33 [==============================] - 7s 211ms/step - loss: 0.0101 - mae: 7.2574e-07\n",
      "Epoch 45/50\n",
      "33/33 [==============================] - 7s 212ms/step - loss: 0.0044 - mae: 3.9472e-07\n",
      "Epoch 46/50\n",
      "33/33 [==============================] - 7s 211ms/step - loss: 0.0066 - mae: 5.6397e-07\n",
      "Epoch 47/50\n",
      "33/33 [==============================] - 7s 211ms/step - loss: 0.0059 - mae: 4.8982e-07\n",
      "Epoch 48/50\n",
      "33/33 [==============================] - 7s 211ms/step - loss: 0.0067 - mae: 5.6026e-07\n",
      "Epoch 49/50\n",
      "33/33 [==============================] - 7s 211ms/step - loss: 0.0069 - mae: 5.0928e-07\n",
      "Epoch 50/50\n",
      "33/33 [==============================] - 7s 212ms/step - loss: 0.0078 - mae: 5.8740e-07\n",
      "-----------------Model /home/sanzharrko/Рабочий стол/Atom/creation_story/models/Multi_LSTM_RNN_Model_2_books.h5 saved.-----------------\n",
      "-----------Started learning-----------\n",
      "---8/69-----------\n",
      "Number of sequences: 4018 \n",
      "\n",
      "Epoch 1/50\n",
      "33/33 [==============================] - 6s 174ms/step - loss: 7.4378 - mae: 9.3331e-05\n",
      "Epoch 2/50\n",
      "33/33 [==============================] - 6s 174ms/step - loss: 5.0588 - mae: 8.6756e-05\n",
      "Epoch 3/50\n",
      "33/33 [==============================] - 6s 174ms/step - loss: 3.6143 - mae: 7.6359e-05\n",
      "Epoch 4/50\n",
      "33/33 [==============================] - 6s 174ms/step - loss: 2.4377 - mae: 6.4158e-05\n",
      "Epoch 5/50\n",
      "33/33 [==============================] - 6s 174ms/step - loss: 1.5418 - mae: 5.1659e-05\n",
      "Epoch 6/50\n",
      "33/33 [==============================] - 6s 175ms/step - loss: 0.8882 - mae: 3.8077e-05\n",
      "Epoch 7/50\n",
      "33/33 [==============================] - 6s 174ms/step - loss: 0.5212 - mae: 2.7310e-05\n",
      "Epoch 8/50\n",
      "33/33 [==============================] - 6s 174ms/step - loss: 0.3044 - mae: 1.8555e-05\n",
      "Epoch 9/50\n",
      "33/33 [==============================] - 6s 174ms/step - loss: 0.1973 - mae: 1.3224e-05\n",
      "Epoch 10/50\n",
      "33/33 [==============================] - 6s 174ms/step - loss: 0.1261 - mae: 9.0818e-06\n",
      "Epoch 11/50\n",
      "33/33 [==============================] - 6s 174ms/step - loss: 0.0977 - mae: 6.9626e-06\n",
      "Epoch 12/50\n",
      "33/33 [==============================] - 6s 174ms/step - loss: 0.0797 - mae: 5.7076e-06\n",
      "Epoch 13/50\n",
      "33/33 [==============================] - 6s 174ms/step - loss: 0.0633 - mae: 4.6823e-06\n",
      "Epoch 14/50\n",
      "33/33 [==============================] - 6s 174ms/step - loss: 0.0571 - mae: 4.2467e-06\n",
      "Epoch 15/50\n",
      "33/33 [==============================] - 6s 174ms/step - loss: 0.0468 - mae: 3.4283e-06\n",
      "Epoch 16/50\n",
      "33/33 [==============================] - 6s 174ms/step - loss: 0.0381 - mae: 2.8203e-06\n",
      "Epoch 17/50\n",
      "33/33 [==============================] - 6s 174ms/step - loss: 0.0369 - mae: 2.7356e-06\n",
      "Epoch 18/50\n",
      "33/33 [==============================] - 6s 174ms/step - loss: 0.0359 - mae: 2.5820e-06\n",
      "Epoch 19/50\n",
      "33/33 [==============================] - 6s 174ms/step - loss: 0.0312 - mae: 2.1730e-06\n",
      "Epoch 20/50\n",
      "33/33 [==============================] - 6s 174ms/step - loss: 0.0360 - mae: 2.2283e-06\n",
      "Epoch 21/50\n",
      "33/33 [==============================] - 6s 174ms/step - loss: 0.0255 - mae: 1.7304e-06\n",
      "Epoch 22/50\n",
      "33/33 [==============================] - 6s 174ms/step - loss: 0.0268 - mae: 1.9369e-06\n",
      "Epoch 23/50\n",
      "33/33 [==============================] - 6s 174ms/step - loss: 0.0268 - mae: 1.7840e-06\n",
      "Epoch 24/50\n",
      "33/33 [==============================] - 6s 174ms/step - loss: 0.0254 - mae: 1.7285e-06\n",
      "Epoch 25/50\n",
      "33/33 [==============================] - 6s 174ms/step - loss: 0.0189 - mae: 1.3247e-06\n",
      "Epoch 26/50\n",
      "33/33 [==============================] - 6s 175ms/step - loss: 0.0212 - mae: 1.3910e-06\n",
      "Epoch 27/50\n",
      "33/33 [==============================] - 6s 175ms/step - loss: 0.0156 - mae: 1.1983e-06\n",
      "Epoch 28/50\n",
      "33/33 [==============================] - 6s 174ms/step - loss: 0.0138 - mae: 1.1309e-06\n",
      "Epoch 29/50\n",
      "33/33 [==============================] - 6s 175ms/step - loss: 0.0129 - mae: 9.5761e-07\n",
      "Epoch 30/50\n",
      "33/33 [==============================] - 6s 174ms/step - loss: 0.0199 - mae: 1.3096e-06\n",
      "Epoch 31/50\n",
      "33/33 [==============================] - 6s 174ms/step - loss: 0.0117 - mae: 8.2231e-07\n",
      "Epoch 32/50\n",
      "33/33 [==============================] - 6s 174ms/step - loss: 0.0061 - mae: 5.5557e-07\n",
      "Epoch 33/50\n",
      "33/33 [==============================] - 6s 175ms/step - loss: 0.0094 - mae: 7.2000e-07\n",
      "Epoch 34/50\n",
      "33/33 [==============================] - 6s 174ms/step - loss: 0.0153 - mae: 1.0357e-06\n",
      "Epoch 35/50\n",
      "33/33 [==============================] - 6s 175ms/step - loss: 0.0072 - mae: 6.0568e-07\n",
      "Epoch 36/50\n",
      "33/33 [==============================] - 6s 174ms/step - loss: 0.0082 - mae: 6.5680e-07\n",
      "Epoch 37/50\n",
      "33/33 [==============================] - 6s 174ms/step - loss: 0.0055 - mae: 4.7303e-07\n",
      "Epoch 38/50\n",
      "33/33 [==============================] - 6s 174ms/step - loss: 0.0063 - mae: 5.0437e-07\n",
      "Epoch 39/50\n",
      "33/33 [==============================] - 6s 174ms/step - loss: 0.0092 - mae: 6.6740e-07\n",
      "Epoch 40/50\n",
      "33/33 [==============================] - 6s 174ms/step - loss: 0.0103 - mae: 7.3408e-07\n",
      "Epoch 41/50\n",
      "33/33 [==============================] - 6s 174ms/step - loss: 0.0099 - mae: 6.8230e-07\n",
      "Epoch 42/50\n",
      "33/33 [==============================] - 6s 175ms/step - loss: 0.0052 - mae: 3.9628e-07\n",
      "Epoch 43/50\n",
      "33/33 [==============================] - 6s 174ms/step - loss: 0.0049 - mae: 4.2984e-07\n",
      "Epoch 44/50\n",
      "33/33 [==============================] - 6s 175ms/step - loss: 0.0056 - mae: 4.3262e-07\n",
      "Epoch 45/50\n",
      "33/33 [==============================] - 6s 174ms/step - loss: 0.0052 - mae: 4.6329e-07\n",
      "Epoch 46/50\n",
      "33/33 [==============================] - 6s 174ms/step - loss: 0.0119 - mae: 6.2950e-07\n",
      "Epoch 47/50\n",
      "33/33 [==============================] - 6s 176ms/step - loss: 0.0059 - mae: 4.4181e-07\n",
      "Epoch 48/50\n",
      "33/33 [==============================] - 8s 217ms/step - loss: 0.0081 - mae: 5.4311e-07\n",
      "Epoch 49/50\n",
      "33/33 [==============================] - 7s 192ms/step - loss: 0.0050 - mae: 4.3932e-07\n",
      "Epoch 50/50\n",
      "33/33 [==============================] - 6s 179ms/step - loss: 0.0053 - mae: 3.8328e-07\n",
      "-----------------Model /home/sanzharrko/Рабочий стол/Atom/creation_story/models/Multi_LSTM_RNN_Model_2_books.h5 saved.-----------------\n",
      "-----------Started learning-----------\n",
      "---9/69-----------\n",
      "Number of sequences: 6468 \n",
      "\n",
      "Epoch 1/50\n",
      "33/33 [==============================] - 9s 270ms/step - loss: 7.3287 - mae: 9.4556e-05\n",
      "Epoch 2/50\n",
      "33/33 [==============================] - 9s 270ms/step - loss: 5.4363 - mae: 9.0214e-05\n",
      "Epoch 3/50\n",
      "33/33 [==============================] - 9s 270ms/step - loss: 4.3239 - mae: 8.3739e-05\n",
      "Epoch 4/50\n",
      "33/33 [==============================] - 9s 270ms/step - loss: 3.3473 - mae: 7.5967e-05\n",
      "Epoch 5/50\n",
      "33/33 [==============================] - 9s 270ms/step - loss: 2.4947 - mae: 6.7250e-05\n",
      "Epoch 6/50\n",
      "33/33 [==============================] - 9s 270ms/step - loss: 1.7592 - mae: 5.7232e-05\n",
      "Epoch 7/50\n",
      "33/33 [==============================] - 9s 270ms/step - loss: 1.1592 - mae: 4.5895e-05\n",
      "Epoch 8/50\n",
      "33/33 [==============================] - 9s 269ms/step - loss: 0.7538 - mae: 3.5846e-05\n",
      "Epoch 9/50\n",
      "33/33 [==============================] - 9s 270ms/step - loss: 0.4615 - mae: 2.5816e-05\n",
      "Epoch 10/50\n",
      "33/33 [==============================] - 9s 270ms/step - loss: 0.2806 - mae: 1.7687e-05\n",
      "Epoch 11/50\n",
      "33/33 [==============================] - 9s 269ms/step - loss: 0.1977 - mae: 1.3407e-05\n",
      "Epoch 12/50\n",
      "33/33 [==============================] - 9s 270ms/step - loss: 0.1461 - mae: 1.0192e-05\n",
      "Epoch 13/50\n",
      "33/33 [==============================] - 9s 269ms/step - loss: 0.1128 - mae: 8.0874e-06\n",
      "Epoch 14/50\n",
      "33/33 [==============================] - 9s 270ms/step - loss: 0.0817 - mae: 6.1361e-06\n",
      "Epoch 15/50\n",
      "33/33 [==============================] - 9s 269ms/step - loss: 0.0724 - mae: 5.4285e-06\n",
      "Epoch 16/50\n",
      "33/33 [==============================] - 9s 270ms/step - loss: 0.0636 - mae: 4.8562e-06\n",
      "Epoch 17/50\n",
      "33/33 [==============================] - 9s 270ms/step - loss: 0.0501 - mae: 3.7800e-06\n",
      "Epoch 18/50\n",
      "33/33 [==============================] - 9s 270ms/step - loss: 0.0450 - mae: 3.4070e-06\n",
      "Epoch 19/50\n",
      "33/33 [==============================] - 9s 270ms/step - loss: 0.0409 - mae: 3.1094e-06\n",
      "Epoch 20/50\n",
      "33/33 [==============================] - 9s 270ms/step - loss: 0.0364 - mae: 2.8765e-06\n",
      "Epoch 21/50\n",
      "33/33 [==============================] - 9s 270ms/step - loss: 0.0361 - mae: 2.8038e-06\n",
      "Epoch 22/50\n",
      "33/33 [==============================] - 9s 269ms/step - loss: 0.0289 - mae: 2.2598e-06\n",
      "Epoch 23/50\n",
      "33/33 [==============================] - 9s 270ms/step - loss: 0.0316 - mae: 2.3049e-06\n",
      "Epoch 24/50\n",
      "33/33 [==============================] - 9s 269ms/step - loss: 0.0299 - mae: 2.2631e-06\n",
      "Epoch 25/50\n",
      "33/33 [==============================] - 9s 270ms/step - loss: 0.0239 - mae: 1.8230e-06\n",
      "Epoch 26/50\n",
      "33/33 [==============================] - 9s 270ms/step - loss: 0.0208 - mae: 1.5120e-06\n",
      "Epoch 27/50\n",
      "33/33 [==============================] - 9s 270ms/step - loss: 0.0224 - mae: 1.7095e-06\n",
      "Epoch 28/50\n",
      "33/33 [==============================] - 9s 269ms/step - loss: 0.0227 - mae: 1.5819e-06\n",
      "Epoch 29/50\n",
      "33/33 [==============================] - 9s 269ms/step - loss: 0.0257 - mae: 1.7710e-06\n",
      "Epoch 30/50\n",
      "33/33 [==============================] - 9s 270ms/step - loss: 0.0212 - mae: 1.4977e-06\n",
      "Epoch 31/50\n",
      "33/33 [==============================] - 9s 273ms/step - loss: 0.0199 - mae: 1.4183e-06\n",
      "Epoch 32/50\n",
      "33/33 [==============================] - 9s 268ms/step - loss: 0.0187 - mae: 1.3304e-06\n",
      "Epoch 33/50\n",
      "33/33 [==============================] - 9s 263ms/step - loss: 0.0176 - mae: 1.2967e-06\n",
      "Epoch 34/50\n",
      "33/33 [==============================] - 9s 263ms/step - loss: 0.0157 - mae: 1.1394e-06\n",
      "Epoch 35/50\n",
      "33/33 [==============================] - 9s 263ms/step - loss: 0.0146 - mae: 1.1352e-06\n",
      "Epoch 36/50\n",
      "33/33 [==============================] - 9s 263ms/step - loss: 0.0131 - mae: 1.0391e-06\n",
      "Epoch 37/50\n",
      "33/33 [==============================] - 9s 263ms/step - loss: 0.0098 - mae: 8.3090e-07\n",
      "Epoch 38/50\n",
      "33/33 [==============================] - 9s 263ms/step - loss: 0.0108 - mae: 8.4687e-07\n",
      "Epoch 39/50\n",
      "33/33 [==============================] - 9s 263ms/step - loss: 0.0153 - mae: 1.1205e-06\n",
      "Epoch 40/50\n",
      "33/33 [==============================] - 9s 263ms/step - loss: 0.0084 - mae: 7.2306e-07\n",
      "Epoch 41/50\n",
      "33/33 [==============================] - 9s 264ms/step - loss: 0.0104 - mae: 8.4761e-07\n",
      "Epoch 42/50\n",
      "33/33 [==============================] - 9s 263ms/step - loss: 0.0112 - mae: 8.7641e-07\n",
      "Epoch 43/50\n",
      "33/33 [==============================] - 9s 264ms/step - loss: 0.0090 - mae: 6.8604e-07\n",
      "Epoch 44/50\n",
      "33/33 [==============================] - 9s 263ms/step - loss: 0.0112 - mae: 7.9202e-07\n",
      "Epoch 45/50\n",
      "33/33 [==============================] - 9s 264ms/step - loss: 0.0096 - mae: 7.2614e-07\n",
      "Epoch 46/50\n",
      "33/33 [==============================] - 9s 263ms/step - loss: 0.0094 - mae: 7.3851e-07\n",
      "Epoch 47/50\n",
      "33/33 [==============================] - 9s 263ms/step - loss: 0.0120 - mae: 8.7762e-07\n",
      "Epoch 48/50\n",
      "33/33 [==============================] - 9s 263ms/step - loss: 0.0112 - mae: 8.4795e-07\n",
      "Epoch 49/50\n",
      "33/33 [==============================] - 9s 263ms/step - loss: 0.0105 - mae: 7.5383e-07\n",
      "Epoch 50/50\n",
      "33/33 [==============================] - 9s 263ms/step - loss: 0.0102 - mae: 7.4769e-07\n",
      "-----------------Model /home/sanzharrko/Рабочий стол/Atom/creation_story/models/Multi_LSTM_RNN_Model_2_books.h5 saved.-----------------\n",
      "-----------Started learning-----------\n",
      "---10/69-----------\n",
      "Number of sequences: 8295 \n",
      "\n",
      "Epoch 1/50\n",
      "33/33 [==============================] - 11s 321ms/step - loss: 7.3046 - mae: 9.5703e-05\n",
      "Epoch 2/50\n",
      "33/33 [==============================] - 11s 321ms/step - loss: 5.6164 - mae: 9.2849e-05\n",
      "Epoch 3/50\n",
      "33/33 [==============================] - 11s 322ms/step - loss: 4.6579 - mae: 8.7956e-05\n",
      "Epoch 4/50\n",
      "33/33 [==============================] - 11s 321ms/step - loss: 3.7023 - mae: 8.0497e-05\n",
      "Epoch 5/50\n",
      "33/33 [==============================] - 11s 320ms/step - loss: 2.8636 - mae: 7.2074e-05\n",
      "Epoch 6/50\n",
      "33/33 [==============================] - 11s 320ms/step - loss: 2.1231 - mae: 6.3257e-05\n",
      "Epoch 7/50\n",
      "33/33 [==============================] - 11s 320ms/step - loss: 1.4978 - mae: 5.2738e-05\n",
      "Epoch 8/50\n",
      "33/33 [==============================] - 11s 321ms/step - loss: 1.0242 - mae: 4.2628e-05\n",
      "Epoch 9/50\n",
      "33/33 [==============================] - 11s 321ms/step - loss: 0.6632 - mae: 3.2523e-05\n",
      "Epoch 10/50\n",
      "33/33 [==============================] - 11s 321ms/step - loss: 0.4600 - mae: 2.4990e-05\n",
      "Epoch 11/50\n",
      "33/33 [==============================] - 11s 321ms/step - loss: 0.2960 - mae: 1.7965e-05\n",
      "Epoch 12/50\n",
      "33/33 [==============================] - 11s 322ms/step - loss: 0.1952 - mae: 1.3136e-05\n",
      "Epoch 13/50\n",
      "33/33 [==============================] - 11s 320ms/step - loss: 0.1525 - mae: 1.0499e-05\n",
      "Epoch 14/50\n",
      "33/33 [==============================] - 11s 320ms/step - loss: 0.1104 - mae: 8.0929e-06\n",
      "Epoch 15/50\n",
      "33/33 [==============================] - 11s 322ms/step - loss: 0.0993 - mae: 7.2149e-06\n",
      "Epoch 16/50\n",
      "33/33 [==============================] - 11s 322ms/step - loss: 0.0753 - mae: 5.6157e-06\n",
      "Epoch 17/50\n",
      "33/33 [==============================] - 11s 319ms/step - loss: 0.0729 - mae: 5.3262e-06\n",
      "Epoch 18/50\n",
      "33/33 [==============================] - 11s 321ms/step - loss: 0.0626 - mae: 4.6004e-06\n",
      "Epoch 19/50\n",
      "33/33 [==============================] - 11s 321ms/step - loss: 0.0485 - mae: 3.7788e-06\n",
      "Epoch 20/50\n",
      "33/33 [==============================] - 11s 320ms/step - loss: 0.0470 - mae: 3.4521e-06\n",
      "Epoch 21/50\n",
      "33/33 [==============================] - 11s 320ms/step - loss: 0.0414 - mae: 3.2086e-06\n",
      "Epoch 22/50\n",
      "33/33 [==============================] - 11s 322ms/step - loss: 0.0402 - mae: 3.0398e-06\n",
      "Epoch 23/50\n",
      "33/33 [==============================] - 11s 321ms/step - loss: 0.0373 - mae: 2.8259e-06\n",
      "Epoch 24/50\n",
      "33/33 [==============================] - 11s 321ms/step - loss: 0.0325 - mae: 2.4872e-06\n",
      "Epoch 25/50\n",
      "33/33 [==============================] - 11s 322ms/step - loss: 0.0269 - mae: 2.0739e-06\n",
      "Epoch 26/50\n",
      "33/33 [==============================] - 11s 321ms/step - loss: 0.0274 - mae: 2.1437e-06\n",
      "Epoch 27/50\n",
      "33/33 [==============================] - 11s 320ms/step - loss: 0.0313 - mae: 2.2321e-06\n",
      "Epoch 28/50\n",
      "33/33 [==============================] - 11s 321ms/step - loss: 0.0242 - mae: 1.8021e-06\n",
      "Epoch 29/50\n",
      "33/33 [==============================] - 11s 321ms/step - loss: 0.0217 - mae: 1.7433e-06\n",
      "Epoch 30/50\n",
      "33/33 [==============================] - 11s 320ms/step - loss: 0.0223 - mae: 1.6919e-06\n",
      "Epoch 31/50\n",
      "33/33 [==============================] - 11s 321ms/step - loss: 0.0265 - mae: 1.9717e-06\n",
      "Epoch 32/50\n",
      "33/33 [==============================] - 11s 320ms/step - loss: 0.0233 - mae: 1.7874e-06\n",
      "Epoch 33/50\n",
      "33/33 [==============================] - 11s 321ms/step - loss: 0.0211 - mae: 1.5524e-06\n",
      "Epoch 34/50\n",
      "33/33 [==============================] - 11s 321ms/step - loss: 0.0176 - mae: 1.3500e-06\n",
      "Epoch 35/50\n",
      "33/33 [==============================] - 11s 321ms/step - loss: 0.0202 - mae: 1.5135e-06\n",
      "Epoch 36/50\n",
      "33/33 [==============================] - 11s 321ms/step - loss: 0.0212 - mae: 1.5113e-06\n",
      "Epoch 37/50\n",
      "33/33 [==============================] - 11s 321ms/step - loss: 0.0179 - mae: 1.3571e-06\n",
      "Epoch 38/50\n",
      "33/33 [==============================] - 11s 323ms/step - loss: 0.0175 - mae: 1.3148e-06\n",
      "Epoch 39/50\n",
      "33/33 [==============================] - 11s 323ms/step - loss: 0.0153 - mae: 1.1912e-06\n",
      "Epoch 40/50\n",
      "33/33 [==============================] - 11s 321ms/step - loss: 0.0164 - mae: 1.2186e-06\n",
      "Epoch 41/50\n",
      "33/33 [==============================] - 11s 321ms/step - loss: 0.0162 - mae: 1.1479e-06\n",
      "Epoch 42/50\n",
      "33/33 [==============================] - 11s 322ms/step - loss: 0.0127 - mae: 9.2717e-07\n",
      "Epoch 43/50\n",
      "33/33 [==============================] - 11s 322ms/step - loss: 0.0147 - mae: 1.0522e-06\n",
      "Epoch 44/50\n",
      "33/33 [==============================] - 11s 322ms/step - loss: 0.0161 - mae: 1.1626e-06\n",
      "Epoch 45/50\n",
      "33/33 [==============================] - 11s 320ms/step - loss: 0.0151 - mae: 1.0759e-06\n",
      "Epoch 46/50\n",
      "33/33 [==============================] - 11s 321ms/step - loss: 0.0111 - mae: 8.7154e-07\n",
      "Epoch 47/50\n",
      "33/33 [==============================] - 11s 321ms/step - loss: 0.0139 - mae: 1.0588e-06\n",
      "Epoch 48/50\n",
      "33/33 [==============================] - 11s 322ms/step - loss: 0.0119 - mae: 9.2261e-07\n",
      "Epoch 49/50\n",
      "33/33 [==============================] - 11s 321ms/step - loss: 0.0102 - mae: 8.4903e-07\n",
      "Epoch 50/50\n",
      "33/33 [==============================] - 11s 322ms/step - loss: 0.0129 - mae: 9.0647e-07\n",
      "-----------------Model /home/sanzharrko/Рабочий стол/Atom/creation_story/models/Multi_LSTM_RNN_Model_2_books.h5 saved.-----------------\n",
      "-----------Started learning-----------\n",
      "---11/69-----------\n",
      "Number of sequences: 2749 \n",
      "\n",
      "Epoch 1/50\n",
      "33/33 [==============================] - 5s 134ms/step - loss: 7.3826 - mae: 9.1345e-05\n",
      "Epoch 2/50\n",
      "33/33 [==============================] - 5s 134ms/step - loss: 4.8265 - mae: 8.2927e-05\n",
      "Epoch 3/50\n",
      "33/33 [==============================] - 5s 134ms/step - loss: 3.2262 - mae: 6.9953e-05\n",
      "Epoch 4/50\n",
      "33/33 [==============================] - 5s 134ms/step - loss: 1.9982 - mae: 5.5739e-05\n",
      "Epoch 5/50\n",
      "33/33 [==============================] - 5s 134ms/step - loss: 1.1816 - mae: 4.2201e-05\n",
      "Epoch 6/50\n",
      "33/33 [==============================] - 5s 134ms/step - loss: 0.6561 - mae: 2.9503e-05\n",
      "Epoch 7/50\n",
      "33/33 [==============================] - 5s 134ms/step - loss: 0.3544 - mae: 1.9498e-05\n",
      "Epoch 8/50\n",
      "33/33 [==============================] - 5s 134ms/step - loss: 0.2160 - mae: 1.3362e-05\n",
      "Epoch 9/50\n",
      "33/33 [==============================] - 5s 134ms/step - loss: 0.1549 - mae: 1.0005e-05\n",
      "Epoch 10/50\n",
      "33/33 [==============================] - 5s 134ms/step - loss: 0.1038 - mae: 7.1715e-06\n",
      "Epoch 11/50\n",
      "33/33 [==============================] - 5s 134ms/step - loss: 0.0688 - mae: 4.9201e-06\n",
      "Epoch 12/50\n",
      "33/33 [==============================] - 5s 134ms/step - loss: 0.0647 - mae: 4.5325e-06\n",
      "Epoch 13/50\n",
      "33/33 [==============================] - 5s 134ms/step - loss: 0.0534 - mae: 3.9077e-06\n",
      "Epoch 14/50\n",
      "33/33 [==============================] - 5s 134ms/step - loss: 0.0373 - mae: 2.8387e-06\n",
      "Epoch 15/50\n",
      "33/33 [==============================] - 5s 134ms/step - loss: 0.0522 - mae: 3.2126e-06\n",
      "Epoch 16/50\n",
      "33/33 [==============================] - 5s 134ms/step - loss: 0.0377 - mae: 2.7416e-06\n",
      "Epoch 17/50\n",
      "33/33 [==============================] - 5s 134ms/step - loss: 0.0303 - mae: 2.1564e-06\n",
      "Epoch 18/50\n",
      "33/33 [==============================] - 5s 134ms/step - loss: 0.0374 - mae: 2.4609e-06\n",
      "Epoch 19/50\n",
      "33/33 [==============================] - 5s 134ms/step - loss: 0.0251 - mae: 1.7424e-06\n",
      "Epoch 20/50\n",
      "33/33 [==============================] - 5s 134ms/step - loss: 0.0246 - mae: 1.7017e-06\n",
      "Epoch 21/50\n",
      "33/33 [==============================] - 5s 134ms/step - loss: 0.0283 - mae: 1.8966e-06\n",
      "Epoch 22/50\n",
      "33/33 [==============================] - 5s 134ms/step - loss: 0.0272 - mae: 1.5938e-06\n",
      "Epoch 23/50\n",
      "33/33 [==============================] - 5s 134ms/step - loss: 0.0252 - mae: 1.6352e-06\n",
      "Epoch 24/50\n",
      "33/33 [==============================] - 5s 134ms/step - loss: 0.0222 - mae: 1.6017e-06\n",
      "Epoch 25/50\n",
      "33/33 [==============================] - 5s 134ms/step - loss: 0.0166 - mae: 1.2027e-06\n",
      "Epoch 26/50\n",
      "33/33 [==============================] - 5s 134ms/step - loss: 0.0170 - mae: 1.1758e-06\n",
      "Epoch 27/50\n",
      "33/33 [==============================] - 5s 134ms/step - loss: 0.0153 - mae: 1.0381e-06\n",
      "Epoch 28/50\n",
      "33/33 [==============================] - 5s 134ms/step - loss: 0.0131 - mae: 1.0176e-06\n",
      "Epoch 29/50\n",
      "33/33 [==============================] - 5s 134ms/step - loss: 0.0121 - mae: 9.1199e-07\n",
      "Epoch 30/50\n",
      "33/33 [==============================] - 5s 134ms/step - loss: 0.0126 - mae: 9.2777e-07\n",
      "Epoch 31/50\n",
      "33/33 [==============================] - 5s 134ms/step - loss: 0.0129 - mae: 8.8693e-07\n",
      "Epoch 32/50\n",
      "33/33 [==============================] - 5s 134ms/step - loss: 0.0156 - mae: 9.6322e-07\n",
      "Epoch 33/50\n",
      "33/33 [==============================] - 5s 134ms/step - loss: 0.0140 - mae: 8.5867e-07\n",
      "Epoch 34/50\n",
      "33/33 [==============================] - 5s 134ms/step - loss: 0.0199 - mae: 1.2575e-06\n",
      "Epoch 35/50\n",
      "33/33 [==============================] - 5s 134ms/step - loss: 0.0090 - mae: 6.6713e-07\n",
      "Epoch 36/50\n",
      "33/33 [==============================] - 5s 134ms/step - loss: 0.0135 - mae: 8.9078e-07\n",
      "Epoch 37/50\n",
      "33/33 [==============================] - 5s 134ms/step - loss: 0.0061 - mae: 4.7855e-07\n",
      "Epoch 38/50\n",
      "33/33 [==============================] - 5s 134ms/step - loss: 0.0086 - mae: 6.5528e-07\n",
      "Epoch 39/50\n",
      "33/33 [==============================] - 5s 134ms/step - loss: 0.0062 - mae: 4.9644e-07\n",
      "Epoch 40/50\n",
      "33/33 [==============================] - 5s 134ms/step - loss: 0.0037 - mae: 2.9705e-07\n",
      "Epoch 41/50\n",
      "33/33 [==============================] - 5s 134ms/step - loss: 0.0084 - mae: 5.9340e-07\n",
      "Epoch 42/50\n",
      "33/33 [==============================] - 5s 134ms/step - loss: 0.0064 - mae: 4.6605e-07\n",
      "Epoch 43/50\n",
      "33/33 [==============================] - 5s 134ms/step - loss: 0.0180 - mae: 9.2504e-07\n",
      "Epoch 44/50\n",
      "33/33 [==============================] - 5s 134ms/step - loss: 0.0084 - mae: 6.4045e-07\n",
      "Epoch 45/50\n",
      "33/33 [==============================] - 5s 134ms/step - loss: 0.0107 - mae: 7.2924e-07\n",
      "Epoch 46/50\n",
      "33/33 [==============================] - 5s 134ms/step - loss: 0.0051 - mae: 4.0692e-07\n",
      "Epoch 47/50\n",
      "33/33 [==============================] - 5s 134ms/step - loss: 0.0101 - mae: 4.5369e-07\n",
      "Epoch 48/50\n",
      "33/33 [==============================] - 5s 134ms/step - loss: 0.0130 - mae: 7.4486e-07\n",
      "Epoch 49/50\n",
      "33/33 [==============================] - 5s 134ms/step - loss: 0.0047 - mae: 3.8002e-07\n",
      "Epoch 50/50\n",
      "33/33 [==============================] - 5s 134ms/step - loss: 0.0124 - mae: 5.3207e-07\n",
      "-----------------Model /home/sanzharrko/Рабочий стол/Atom/creation_story/models/Multi_LSTM_RNN_Model_2_books.h5 saved.-----------------\n",
      "-----------Started learning-----------\n",
      "---12/69-----------\n",
      "Number of sequences: 8479 \n",
      "\n",
      "Epoch 1/50\n",
      "33/33 [==============================] - 11s 323ms/step - loss: 7.2662 - mae: 9.4464e-05\n",
      "Epoch 2/50\n",
      "33/33 [==============================] - 11s 324ms/step - loss: 5.4926 - mae: 9.0768e-05\n",
      "Epoch 3/50\n",
      "33/33 [==============================] - 11s 325ms/step - loss: 4.5438 - mae: 8.5603e-05\n",
      "Epoch 4/50\n",
      "33/33 [==============================] - 11s 324ms/step - loss: 3.6784 - mae: 7.8958e-05\n",
      "Epoch 5/50\n",
      "33/33 [==============================] - 11s 324ms/step - loss: 2.9279 - mae: 7.1538e-05\n",
      "Epoch 6/50\n",
      "33/33 [==============================] - 11s 324ms/step - loss: 2.2137 - mae: 6.3216e-05\n",
      "Epoch 7/50\n",
      "33/33 [==============================] - 11s 324ms/step - loss: 1.6110 - mae: 5.4111e-05\n",
      "Epoch 8/50\n",
      "33/33 [==============================] - 11s 324ms/step - loss: 1.1342 - mae: 4.4882e-05\n",
      "Epoch 9/50\n",
      "33/33 [==============================] - 11s 325ms/step - loss: 0.7732 - mae: 3.5582e-05\n",
      "Epoch 10/50\n",
      "33/33 [==============================] - 11s 325ms/step - loss: 0.5294 - mae: 2.7578e-05\n",
      "Epoch 11/50\n",
      "33/33 [==============================] - 11s 325ms/step - loss: 0.3527 - mae: 2.0457e-05\n",
      "Epoch 12/50\n",
      "33/33 [==============================] - 11s 325ms/step - loss: 0.2517 - mae: 1.6017e-05\n",
      "Epoch 13/50\n",
      "33/33 [==============================] - 11s 325ms/step - loss: 0.1963 - mae: 1.2853e-05\n",
      "Epoch 14/50\n",
      "33/33 [==============================] - 11s 324ms/step - loss: 0.1478 - mae: 1.0129e-05\n",
      "Epoch 15/50\n",
      "33/33 [==============================] - 11s 324ms/step - loss: 0.1163 - mae: 8.2842e-06\n",
      "Epoch 16/50\n",
      "33/33 [==============================] - 11s 325ms/step - loss: 0.1056 - mae: 7.4684e-06\n",
      "Epoch 17/50\n",
      "33/33 [==============================] - 11s 325ms/step - loss: 0.0755 - mae: 5.6498e-06\n",
      "Epoch 18/50\n",
      "33/33 [==============================] - 11s 325ms/step - loss: 0.0754 - mae: 5.3795e-06\n",
      "Epoch 19/50\n",
      "33/33 [==============================] - 11s 326ms/step - loss: 0.0642 - mae: 4.6372e-06\n",
      "Epoch 20/50\n",
      "33/33 [==============================] - 11s 325ms/step - loss: 0.0578 - mae: 4.2134e-06\n",
      "Epoch 21/50\n",
      "33/33 [==============================] - 11s 325ms/step - loss: 0.0536 - mae: 3.9037e-06\n",
      "Epoch 22/50\n",
      "33/33 [==============================] - 11s 325ms/step - loss: 0.0478 - mae: 3.4308e-06\n",
      "Epoch 23/50\n",
      "33/33 [==============================] - 11s 325ms/step - loss: 0.0359 - mae: 2.7617e-06\n",
      "Epoch 24/50\n",
      "33/33 [==============================] - 11s 326ms/step - loss: 0.0407 - mae: 2.9643e-06\n",
      "Epoch 25/50\n",
      "33/33 [==============================] - 11s 325ms/step - loss: 0.0419 - mae: 3.0332e-06\n",
      "Epoch 26/50\n",
      "33/33 [==============================] - 11s 325ms/step - loss: 0.0434 - mae: 2.9029e-06\n",
      "Epoch 27/50\n",
      "33/33 [==============================] - 11s 326ms/step - loss: 0.0308 - mae: 2.3102e-06\n",
      "Epoch 28/50\n",
      "33/33 [==============================] - 11s 325ms/step - loss: 0.0257 - mae: 1.9300e-06\n",
      "Epoch 29/50\n",
      "33/33 [==============================] - 11s 325ms/step - loss: 0.0303 - mae: 2.1504e-06\n",
      "Epoch 30/50\n",
      "33/33 [==============================] - 11s 326ms/step - loss: 0.0250 - mae: 1.8823e-06\n",
      "Epoch 31/50\n",
      "33/33 [==============================] - 11s 326ms/step - loss: 0.0258 - mae: 1.9149e-06\n",
      "Epoch 32/50\n",
      "33/33 [==============================] - 11s 325ms/step - loss: 0.0209 - mae: 1.5756e-06\n",
      "Epoch 33/50\n",
      "33/33 [==============================] - 11s 326ms/step - loss: 0.0231 - mae: 1.6975e-06\n",
      "Epoch 34/50\n",
      "33/33 [==============================] - 11s 325ms/step - loss: 0.0241 - mae: 1.7416e-06\n",
      "Epoch 35/50\n",
      "33/33 [==============================] - 11s 326ms/step - loss: 0.0244 - mae: 1.6924e-06\n",
      "Epoch 36/50\n",
      "33/33 [==============================] - 11s 325ms/step - loss: 0.0189 - mae: 1.4637e-06\n",
      "Epoch 37/50\n",
      "33/33 [==============================] - 11s 325ms/step - loss: 0.0164 - mae: 1.2895e-06\n",
      "Epoch 38/50\n",
      "33/33 [==============================] - 11s 325ms/step - loss: 0.0174 - mae: 1.3314e-06\n",
      "Epoch 39/50\n",
      "33/33 [==============================] - 11s 325ms/step - loss: 0.0187 - mae: 1.4068e-06\n",
      "Epoch 40/50\n",
      "33/33 [==============================] - 11s 325ms/step - loss: 0.0141 - mae: 1.1342e-06\n",
      "Epoch 41/50\n",
      "33/33 [==============================] - 11s 325ms/step - loss: 0.0178 - mae: 1.2517e-06\n",
      "Epoch 42/50\n",
      "33/33 [==============================] - 11s 324ms/step - loss: 0.0179 - mae: 1.2159e-06\n",
      "Epoch 43/50\n",
      "33/33 [==============================] - 11s 325ms/step - loss: 0.0193 - mae: 1.3095e-06\n",
      "Epoch 44/50\n",
      "33/33 [==============================] - 11s 325ms/step - loss: 0.0180 - mae: 1.2652e-06\n",
      "Epoch 45/50\n",
      "33/33 [==============================] - 11s 326ms/step - loss: 0.0128 - mae: 9.8703e-07\n",
      "Epoch 46/50\n",
      "33/33 [==============================] - 11s 325ms/step - loss: 0.0177 - mae: 1.2315e-06\n",
      "Epoch 47/50\n",
      "33/33 [==============================] - 11s 325ms/step - loss: 0.0153 - mae: 1.1142e-06\n",
      "Epoch 48/50\n",
      "33/33 [==============================] - 11s 325ms/step - loss: 0.0140 - mae: 1.0689e-06\n",
      "Epoch 49/50\n",
      "33/33 [==============================] - 11s 324ms/step - loss: 0.0096 - mae: 7.7543e-07\n",
      "Epoch 50/50\n",
      "33/33 [==============================] - 11s 325ms/step - loss: 0.0122 - mae: 9.1765e-07\n",
      "-----------------Model /home/sanzharrko/Рабочий стол/Atom/creation_story/models/Multi_LSTM_RNN_Model_2_books.h5 saved.-----------------\n",
      "-----------Started learning-----------\n",
      "---13/69-----------\n",
      "Number of sequences: 8148 \n",
      "\n",
      "Epoch 1/50\n",
      "33/33 [==============================] - 11s 311ms/step - loss: 7.3290 - mae: 9.6403e-05\n",
      "Epoch 2/50\n",
      "33/33 [==============================] - 11s 310ms/step - loss: 5.5737 - mae: 9.2500e-05\n",
      "Epoch 3/50\n",
      "33/33 [==============================] - 11s 310ms/step - loss: 4.5677 - mae: 8.6892e-05\n",
      "Epoch 4/50\n",
      "33/33 [==============================] - 11s 312ms/step - loss: 3.6782 - mae: 7.9858e-05\n",
      "Epoch 5/50\n",
      "33/33 [==============================] - 11s 311ms/step - loss: 2.8539 - mae: 7.1377e-05\n",
      "Epoch 6/50\n",
      "33/33 [==============================] - 11s 311ms/step - loss: 2.1393 - mae: 6.2897e-05\n",
      "Epoch 7/50\n",
      "33/33 [==============================] - 11s 311ms/step - loss: 1.5355 - mae: 5.3258e-05\n",
      "Epoch 8/50\n",
      "33/33 [==============================] - 11s 311ms/step - loss: 1.0371 - mae: 4.2759e-05\n",
      "Epoch 9/50\n",
      "33/33 [==============================] - 11s 311ms/step - loss: 0.7043 - mae: 3.3539e-05\n",
      "Epoch 10/50\n",
      "33/33 [==============================] - 11s 311ms/step - loss: 0.4675 - mae: 2.5351e-05\n",
      "Epoch 11/50\n",
      "33/33 [==============================] - 11s 311ms/step - loss: 0.3080 - mae: 1.8619e-05\n",
      "Epoch 12/50\n",
      "33/33 [==============================] - 11s 312ms/step - loss: 0.2223 - mae: 1.4240e-05\n",
      "Epoch 13/50\n",
      "33/33 [==============================] - 11s 311ms/step - loss: 0.1766 - mae: 1.1759e-05\n",
      "Epoch 14/50\n",
      "33/33 [==============================] - 11s 311ms/step - loss: 0.1385 - mae: 9.5085e-06\n",
      "Epoch 15/50\n",
      "33/33 [==============================] - 11s 312ms/step - loss: 0.1154 - mae: 7.9603e-06\n",
      "Epoch 16/50\n",
      "33/33 [==============================] - 11s 311ms/step - loss: 0.0868 - mae: 6.3185e-06\n",
      "Epoch 17/50\n",
      "33/33 [==============================] - 11s 311ms/step - loss: 0.0857 - mae: 6.0186e-06\n",
      "Epoch 18/50\n",
      "33/33 [==============================] - 11s 311ms/step - loss: 0.0701 - mae: 5.0720e-06\n",
      "Epoch 19/50\n",
      "33/33 [==============================] - 11s 312ms/step - loss: 0.0606 - mae: 4.4612e-06\n",
      "Epoch 20/50\n",
      "33/33 [==============================] - 11s 311ms/step - loss: 0.0583 - mae: 4.1257e-06\n",
      "Epoch 21/50\n",
      "33/33 [==============================] - 11s 311ms/step - loss: 0.0594 - mae: 4.0757e-06\n",
      "Epoch 22/50\n",
      "33/33 [==============================] - 11s 311ms/step - loss: 0.0530 - mae: 3.6820e-06\n",
      "Epoch 23/50\n",
      "33/33 [==============================] - 11s 312ms/step - loss: 0.0421 - mae: 3.1073e-06\n",
      "Epoch 24/50\n",
      "33/33 [==============================] - 11s 312ms/step - loss: 0.0420 - mae: 3.0189e-06\n",
      "Epoch 25/50\n",
      "33/33 [==============================] - 11s 311ms/step - loss: 0.0334 - mae: 2.5124e-06\n",
      "Epoch 26/50\n",
      "33/33 [==============================] - 11s 311ms/step - loss: 0.0402 - mae: 2.7783e-06\n",
      "Epoch 27/50\n",
      "33/33 [==============================] - 11s 311ms/step - loss: 0.0394 - mae: 2.7189e-06\n",
      "Epoch 28/50\n",
      "33/33 [==============================] - 11s 312ms/step - loss: 0.0297 - mae: 2.2000e-06\n",
      "Epoch 29/50\n",
      "33/33 [==============================] - 11s 311ms/step - loss: 0.0312 - mae: 2.2243e-06\n",
      "Epoch 30/50\n",
      "33/33 [==============================] - 11s 311ms/step - loss: 0.0284 - mae: 2.0361e-06\n",
      "Epoch 31/50\n",
      "33/33 [==============================] - 11s 311ms/step - loss: 0.0258 - mae: 1.8338e-06\n",
      "Epoch 32/50\n",
      "33/33 [==============================] - 11s 311ms/step - loss: 0.0258 - mae: 1.8780e-06\n",
      "Epoch 33/50\n",
      "33/33 [==============================] - 11s 312ms/step - loss: 0.0266 - mae: 1.9270e-06\n",
      "Epoch 34/50\n",
      "33/33 [==============================] - 11s 312ms/step - loss: 0.0247 - mae: 1.8176e-06\n",
      "Epoch 35/50\n",
      "33/33 [==============================] - 11s 311ms/step - loss: 0.0228 - mae: 1.5946e-06\n",
      "Epoch 36/50\n",
      "33/33 [==============================] - 11s 311ms/step - loss: 0.0224 - mae: 1.6233e-06\n",
      "Epoch 37/50\n",
      "33/33 [==============================] - 11s 311ms/step - loss: 0.0214 - mae: 1.6289e-06\n",
      "Epoch 38/50\n",
      "33/33 [==============================] - 11s 311ms/step - loss: 0.0197 - mae: 1.4381e-06\n",
      "Epoch 39/50\n",
      "33/33 [==============================] - 11s 311ms/step - loss: 0.0151 - mae: 1.2165e-06\n",
      "Epoch 40/50\n",
      "33/33 [==============================] - 11s 311ms/step - loss: 0.0199 - mae: 1.3949e-06\n",
      "Epoch 41/50\n",
      "33/33 [==============================] - 11s 311ms/step - loss: 0.0216 - mae: 1.5486e-06\n",
      "Epoch 42/50\n",
      "33/33 [==============================] - 11s 311ms/step - loss: 0.0208 - mae: 1.4881e-06\n",
      "Epoch 43/50\n",
      "33/33 [==============================] - 11s 312ms/step - loss: 0.0228 - mae: 1.5111e-06\n",
      "Epoch 44/50\n",
      "33/33 [==============================] - 11s 311ms/step - loss: 0.0169 - mae: 1.2231e-06\n",
      "Epoch 45/50\n",
      "33/33 [==============================] - 11s 311ms/step - loss: 0.0167 - mae: 1.2209e-06\n",
      "Epoch 46/50\n",
      "33/33 [==============================] - 11s 310ms/step - loss: 0.0168 - mae: 1.1822e-06\n",
      "Epoch 47/50\n",
      "33/33 [==============================] - 11s 311ms/step - loss: 0.0151 - mae: 1.0848e-06\n",
      "Epoch 48/50\n",
      "33/33 [==============================] - 11s 311ms/step - loss: 0.0218 - mae: 1.3692e-06\n",
      "Epoch 49/50\n",
      "33/33 [==============================] - 11s 311ms/step - loss: 0.0170 - mae: 1.1931e-06\n",
      "Epoch 50/50\n",
      "33/33 [==============================] - 11s 310ms/step - loss: 0.0145 - mae: 1.0205e-06\n",
      "-----------------Model /home/sanzharrko/Рабочий стол/Atom/creation_story/models/Multi_LSTM_RNN_Model_2_books.h5 saved.-----------------\n",
      "-----------Started learning-----------\n",
      "---14/69-----------\n",
      "Number of sequences: 6336 \n",
      "\n",
      "Epoch 1/50\n",
      "32/32 [==============================] - 10s 267ms/step - loss: 7.2230 - mae: 9.2724e-05\n",
      "Epoch 2/50\n",
      "32/32 [==============================] - 9s 267ms/step - loss: 5.3637 - mae: 8.7734e-05\n",
      "Epoch 3/50\n",
      "32/32 [==============================] - 9s 266ms/step - loss: 4.2460 - mae: 8.0959e-05\n",
      "Epoch 4/50\n",
      "32/32 [==============================] - 9s 267ms/step - loss: 3.1878 - mae: 7.1795e-05\n",
      "Epoch 5/50\n",
      "32/32 [==============================] - 9s 268ms/step - loss: 2.3222 - mae: 6.1964e-05\n",
      "Epoch 6/50\n",
      "32/32 [==============================] - 9s 267ms/step - loss: 1.6377 - mae: 5.1936e-05\n",
      "Epoch 7/50\n",
      "32/32 [==============================] - 9s 268ms/step - loss: 1.0810 - mae: 4.1941e-05\n",
      "Epoch 8/50\n",
      "32/32 [==============================] - 9s 267ms/step - loss: 0.6983 - mae: 3.1933e-05\n",
      "Epoch 9/50\n",
      "32/32 [==============================] - 9s 266ms/step - loss: 0.4553 - mae: 2.4172e-05\n",
      "Epoch 10/50\n",
      "32/32 [==============================] - 9s 268ms/step - loss: 0.2940 - mae: 1.7710e-05\n",
      "Epoch 11/50\n",
      "32/32 [==============================] - 9s 268ms/step - loss: 0.2037 - mae: 1.2890e-05\n",
      "Epoch 12/50\n",
      "32/32 [==============================] - 9s 267ms/step - loss: 0.1555 - mae: 1.0242e-05\n",
      "Epoch 13/50\n",
      "32/32 [==============================] - 9s 266ms/step - loss: 0.1137 - mae: 7.9640e-06\n",
      "Epoch 14/50\n",
      "32/32 [==============================] - 9s 267ms/step - loss: 0.1037 - mae: 7.0044e-06\n",
      "Epoch 15/50\n",
      "32/32 [==============================] - 9s 266ms/step - loss: 0.0873 - mae: 5.9567e-06\n",
      "Epoch 16/50\n",
      "32/32 [==============================] - 9s 267ms/step - loss: 0.0852 - mae: 5.6571e-06\n",
      "Epoch 17/50\n",
      "32/32 [==============================] - 9s 267ms/step - loss: 0.0615 - mae: 4.3536e-06\n",
      "Epoch 18/50\n",
      "32/32 [==============================] - 9s 268ms/step - loss: 0.0650 - mae: 4.2974e-06\n",
      "Epoch 19/50\n",
      "32/32 [==============================] - 9s 267ms/step - loss: 0.0550 - mae: 3.7085e-06\n",
      "Epoch 20/50\n",
      "32/32 [==============================] - 9s 266ms/step - loss: 0.0477 - mae: 3.2953e-06\n",
      "Epoch 21/50\n",
      "32/32 [==============================] - 9s 267ms/step - loss: 0.0466 - mae: 3.2663e-06\n",
      "Epoch 22/50\n",
      "32/32 [==============================] - 9s 267ms/step - loss: 0.0501 - mae: 3.3301e-06\n",
      "Epoch 23/50\n",
      "32/32 [==============================] - 9s 267ms/step - loss: 0.0342 - mae: 2.5128e-06\n",
      "Epoch 24/50\n",
      "32/32 [==============================] - 9s 267ms/step - loss: 0.0327 - mae: 2.4178e-06\n",
      "Epoch 25/50\n",
      "32/32 [==============================] - 9s 267ms/step - loss: 0.0347 - mae: 2.3872e-06\n",
      "Epoch 26/50\n",
      "32/32 [==============================] - 9s 266ms/step - loss: 0.0306 - mae: 2.2730e-06\n",
      "Epoch 27/50\n",
      "32/32 [==============================] - 9s 267ms/step - loss: 0.0222 - mae: 1.7639e-06\n",
      "Epoch 28/50\n",
      "32/32 [==============================] - 9s 266ms/step - loss: 0.0236 - mae: 1.7934e-06\n",
      "Epoch 29/50\n",
      "32/32 [==============================] - 9s 267ms/step - loss: 0.0262 - mae: 1.8428e-06\n",
      "Epoch 30/50\n",
      "32/32 [==============================] - 9s 266ms/step - loss: 0.0245 - mae: 1.7117e-06\n",
      "Epoch 31/50\n",
      "32/32 [==============================] - 9s 267ms/step - loss: 0.0275 - mae: 1.8153e-06\n",
      "Epoch 32/50\n",
      "32/32 [==============================] - 9s 265ms/step - loss: 0.0257 - mae: 1.7088e-06\n",
      "Epoch 33/50\n",
      "32/32 [==============================] - 9s 266ms/step - loss: 0.0248 - mae: 1.6064e-06\n",
      "Epoch 34/50\n",
      "32/32 [==============================] - 9s 266ms/step - loss: 0.0230 - mae: 1.5874e-06\n",
      "Epoch 35/50\n",
      "32/32 [==============================] - 9s 267ms/step - loss: 0.0211 - mae: 1.4839e-06\n",
      "Epoch 36/50\n",
      "32/32 [==============================] - 9s 267ms/step - loss: 0.0243 - mae: 1.6227e-06\n",
      "Epoch 37/50\n",
      "32/32 [==============================] - 9s 267ms/step - loss: 0.0195 - mae: 1.3562e-06\n",
      "Epoch 38/50\n",
      "32/32 [==============================] - 9s 267ms/step - loss: 0.0218 - mae: 1.4235e-06\n",
      "Epoch 39/50\n",
      "32/32 [==============================] - 9s 268ms/step - loss: 0.0173 - mae: 1.1396e-06\n",
      "Epoch 40/50\n",
      "32/32 [==============================] - 9s 266ms/step - loss: 0.0214 - mae: 1.3890e-06\n",
      "Epoch 41/50\n",
      "32/32 [==============================] - 9s 267ms/step - loss: 0.0186 - mae: 1.2978e-06\n",
      "Epoch 42/50\n",
      "32/32 [==============================] - 9s 267ms/step - loss: 0.0178 - mae: 1.1611e-06\n",
      "Epoch 43/50\n",
      "32/32 [==============================] - 9s 267ms/step - loss: 0.0182 - mae: 1.2431e-06\n",
      "Epoch 44/50\n",
      "32/32 [==============================] - 9s 266ms/step - loss: 0.0156 - mae: 1.0761e-06\n",
      "Epoch 45/50\n",
      "32/32 [==============================] - 9s 267ms/step - loss: 0.0161 - mae: 1.0840e-06\n",
      "Epoch 46/50\n",
      "32/32 [==============================] - 9s 267ms/step - loss: 0.0148 - mae: 1.0798e-06\n",
      "Epoch 47/50\n",
      "32/32 [==============================] - 9s 267ms/step - loss: 0.0115 - mae: 8.9936e-07\n",
      "Epoch 48/50\n",
      "32/32 [==============================] - 9s 267ms/step - loss: 0.0119 - mae: 8.9564e-07\n",
      "Epoch 49/50\n",
      "32/32 [==============================] - 9s 266ms/step - loss: 0.0126 - mae: 8.6335e-07\n",
      "Epoch 50/50\n",
      "32/32 [==============================] - 9s 266ms/step - loss: 0.0185 - mae: 1.1547e-06\n",
      "-----------------Model /home/sanzharrko/Рабочий стол/Atom/creation_story/models/Multi_LSTM_RNN_Model_2_books.h5 saved.-----------------\n",
      "-----------Started learning-----------\n",
      "---15/69-----------\n",
      "Number of sequences: 8863 \n",
      "\n",
      "Epoch 1/50\n",
      "33/33 [==============================] - 12s 341ms/step - loss: 7.0028 - mae: 9.3374e-05\n",
      "Epoch 2/50\n",
      "33/33 [==============================] - 12s 342ms/step - loss: 5.3137 - mae: 8.9116e-05\n",
      "Epoch 3/50\n",
      "33/33 [==============================] - 12s 343ms/step - loss: 4.4241 - mae: 8.3694e-05\n",
      "Epoch 4/50\n",
      "33/33 [==============================] - 12s 343ms/step - loss: 3.5932 - mae: 7.6896e-05\n",
      "Epoch 5/50\n",
      "33/33 [==============================] - 12s 343ms/step - loss: 2.8470 - mae: 6.9489e-05\n",
      "Epoch 6/50\n",
      "33/33 [==============================] - 12s 343ms/step - loss: 2.1506 - mae: 6.1125e-05\n",
      "Epoch 7/50\n",
      "33/33 [==============================] - 12s 343ms/step - loss: 1.5721 - mae: 5.2202e-05\n",
      "Epoch 8/50\n",
      "33/33 [==============================] - 12s 343ms/step - loss: 1.1051 - mae: 4.2793e-05\n",
      "Epoch 9/50\n",
      "33/33 [==============================] - 12s 344ms/step - loss: 0.7465 - mae: 3.4016e-05\n",
      "Epoch 10/50\n",
      "33/33 [==============================] - 12s 344ms/step - loss: 0.4969 - mae: 2.5914e-05\n",
      "Epoch 11/50\n",
      "33/33 [==============================] - 12s 343ms/step - loss: 0.3306 - mae: 1.9503e-05\n",
      "Epoch 12/50\n",
      "33/33 [==============================] - 12s 344ms/step - loss: 0.2450 - mae: 1.5322e-05\n",
      "Epoch 13/50\n",
      "33/33 [==============================] - 12s 344ms/step - loss: 0.1773 - mae: 1.1653e-05\n",
      "Epoch 14/50\n",
      "33/33 [==============================] - 12s 344ms/step - loss: 0.1484 - mae: 9.9478e-06\n",
      "Epoch 15/50\n",
      "33/33 [==============================] - 12s 344ms/step - loss: 0.1168 - mae: 8.0882e-06\n",
      "Epoch 16/50\n",
      "33/33 [==============================] - 12s 344ms/step - loss: 0.0963 - mae: 6.7153e-06\n",
      "Epoch 17/50\n",
      "33/33 [==============================] - 12s 344ms/step - loss: 0.0810 - mae: 5.7689e-06\n",
      "Epoch 18/50\n",
      "33/33 [==============================] - 12s 344ms/step - loss: 0.0760 - mae: 5.2606e-06\n",
      "Epoch 19/50\n",
      "33/33 [==============================] - 12s 343ms/step - loss: 0.0696 - mae: 4.9478e-06\n",
      "Epoch 20/50\n",
      "33/33 [==============================] - 12s 344ms/step - loss: 0.0583 - mae: 4.2277e-06\n",
      "Epoch 21/50\n",
      "33/33 [==============================] - 12s 344ms/step - loss: 0.0600 - mae: 4.1685e-06\n",
      "Epoch 22/50\n",
      "33/33 [==============================] - 12s 343ms/step - loss: 0.0521 - mae: 3.6549e-06\n",
      "Epoch 23/50\n",
      "33/33 [==============================] - 12s 344ms/step - loss: 0.0491 - mae: 3.4468e-06\n",
      "Epoch 24/50\n",
      "33/33 [==============================] - 12s 344ms/step - loss: 0.0436 - mae: 3.1607e-06\n",
      "Epoch 25/50\n",
      "33/33 [==============================] - 12s 344ms/step - loss: 0.0398 - mae: 2.8359e-06\n",
      "Epoch 26/50\n",
      "33/33 [==============================] - 12s 343ms/step - loss: 0.0369 - mae: 2.6804e-06\n",
      "Epoch 27/50\n",
      "33/33 [==============================] - 12s 344ms/step - loss: 0.0421 - mae: 2.8655e-06\n",
      "Epoch 28/50\n",
      "33/33 [==============================] - 12s 344ms/step - loss: 0.0380 - mae: 2.6333e-06\n",
      "Epoch 29/50\n",
      "33/33 [==============================] - 12s 343ms/step - loss: 0.0375 - mae: 2.5611e-06\n",
      "Epoch 30/50\n",
      "33/33 [==============================] - 12s 344ms/step - loss: 0.0339 - mae: 2.4349e-06\n",
      "Epoch 31/50\n",
      "33/33 [==============================] - 12s 343ms/step - loss: 0.0366 - mae: 2.3920e-06\n",
      "Epoch 32/50\n",
      "33/33 [==============================] - 12s 344ms/step - loss: 0.0285 - mae: 2.0559e-06\n",
      "Epoch 33/50\n",
      "33/33 [==============================] - 12s 344ms/step - loss: 0.0282 - mae: 2.0066e-06\n",
      "Epoch 34/50\n",
      "33/33 [==============================] - 12s 343ms/step - loss: 0.0271 - mae: 1.8837e-06\n",
      "Epoch 35/50\n",
      "33/33 [==============================] - 12s 343ms/step - loss: 0.0303 - mae: 2.0589e-06\n",
      "Epoch 36/50\n",
      "33/33 [==============================] - 12s 344ms/step - loss: 0.0255 - mae: 1.8373e-06\n",
      "Epoch 37/50\n",
      "33/33 [==============================] - 12s 344ms/step - loss: 0.0256 - mae: 1.8873e-06\n",
      "Epoch 38/50\n",
      "33/33 [==============================] - 12s 343ms/step - loss: 0.0239 - mae: 1.6771e-06\n",
      "Epoch 39/50\n",
      "33/33 [==============================] - 12s 343ms/step - loss: 0.0225 - mae: 1.5906e-06\n",
      "Epoch 40/50\n",
      "33/33 [==============================] - 12s 344ms/step - loss: 0.0205 - mae: 1.4666e-06\n",
      "Epoch 41/50\n",
      "33/33 [==============================] - 12s 344ms/step - loss: 0.0218 - mae: 1.5286e-06\n",
      "Epoch 42/50\n",
      "33/33 [==============================] - 12s 344ms/step - loss: 0.0224 - mae: 1.5696e-06\n",
      "Epoch 43/50\n",
      "33/33 [==============================] - 12s 343ms/step - loss: 0.0243 - mae: 1.6690e-06\n",
      "Epoch 44/50\n",
      "33/33 [==============================] - 12s 344ms/step - loss: 0.0167 - mae: 1.2611e-06\n",
      "Epoch 45/50\n",
      "33/33 [==============================] - 12s 344ms/step - loss: 0.0208 - mae: 1.4538e-06\n",
      "Epoch 46/50\n",
      "33/33 [==============================] - 12s 343ms/step - loss: 0.0210 - mae: 1.4505e-06\n",
      "Epoch 47/50\n",
      "33/33 [==============================] - 12s 344ms/step - loss: 0.0170 - mae: 1.2349e-06\n",
      "Epoch 48/50\n",
      "33/33 [==============================] - 12s 344ms/step - loss: 0.0211 - mae: 1.3620e-06\n",
      "Epoch 49/50\n",
      "33/33 [==============================] - 12s 344ms/step - loss: 0.0171 - mae: 1.1703e-06\n",
      "Epoch 50/50\n",
      "33/33 [==============================] - 12s 344ms/step - loss: 0.0210 - mae: 1.3127e-06\n",
      "-----------------Model /home/sanzharrko/Рабочий стол/Atom/creation_story/models/Multi_LSTM_RNN_Model_2_books.h5 saved.-----------------\n",
      "-----------Started learning-----------\n",
      "---16/69-----------\n",
      "Number of sequences: 4100 \n",
      "\n",
      "Epoch 1/50\n",
      "33/33 [==============================] - 6s 173ms/step - loss: 7.5969 - mae: 9.7189e-05\n",
      "Epoch 2/50\n",
      "33/33 [==============================] - 6s 173ms/step - loss: 5.5473 - mae: 9.2405e-05\n",
      "Epoch 3/50\n",
      "33/33 [==============================] - 6s 172ms/step - loss: 4.2302 - mae: 8.3827e-05\n",
      "Epoch 4/50\n",
      "33/33 [==============================] - 6s 173ms/step - loss: 3.1222 - mae: 7.3832e-05\n",
      "Epoch 5/50\n",
      "33/33 [==============================] - 6s 173ms/step - loss: 2.2451 - mae: 6.2961e-05\n",
      "Epoch 6/50\n",
      "33/33 [==============================] - 6s 173ms/step - loss: 1.5281 - mae: 5.0692e-05\n",
      "Epoch 7/50\n",
      "33/33 [==============================] - 6s 173ms/step - loss: 0.9930 - mae: 4.0281e-05\n",
      "Epoch 8/50\n",
      "33/33 [==============================] - 6s 173ms/step - loss: 0.6321 - mae: 3.0391e-05\n",
      "Epoch 9/50\n",
      "33/33 [==============================] - 6s 173ms/step - loss: 0.4312 - mae: 2.3184e-05\n",
      "Epoch 10/50\n",
      "33/33 [==============================] - 6s 173ms/step - loss: 0.2625 - mae: 1.6251e-05\n",
      "Epoch 11/50\n",
      "33/33 [==============================] - 6s 173ms/step - loss: 0.2008 - mae: 1.2924e-05\n",
      "Epoch 12/50\n",
      "33/33 [==============================] - 6s 173ms/step - loss: 0.1321 - mae: 9.2557e-06\n",
      "Epoch 13/50\n",
      "33/33 [==============================] - 6s 173ms/step - loss: 0.1127 - mae: 7.7384e-06\n",
      "Epoch 14/50\n",
      "33/33 [==============================] - 6s 173ms/step - loss: 0.0846 - mae: 6.1669e-06\n",
      "Epoch 15/50\n",
      "33/33 [==============================] - 6s 173ms/step - loss: 0.0732 - mae: 5.1720e-06\n",
      "Epoch 16/50\n",
      "33/33 [==============================] - 6s 173ms/step - loss: 0.0752 - mae: 4.9658e-06\n",
      "Epoch 17/50\n",
      "33/33 [==============================] - 6s 173ms/step - loss: 0.0579 - mae: 4.0981e-06\n",
      "Epoch 18/50\n",
      "33/33 [==============================] - 6s 173ms/step - loss: 0.0517 - mae: 3.6488e-06\n",
      "Epoch 19/50\n",
      "33/33 [==============================] - 6s 173ms/step - loss: 0.0545 - mae: 3.6134e-06\n",
      "Epoch 20/50\n",
      "33/33 [==============================] - 6s 173ms/step - loss: 0.0390 - mae: 2.8755e-06\n",
      "Epoch 21/50\n",
      "33/33 [==============================] - 6s 173ms/step - loss: 0.0369 - mae: 2.7625e-06\n",
      "Epoch 22/50\n",
      "33/33 [==============================] - 6s 173ms/step - loss: 0.0334 - mae: 2.4099e-06\n",
      "Epoch 23/50\n",
      "33/33 [==============================] - 6s 173ms/step - loss: 0.0471 - mae: 2.7535e-06\n",
      "Epoch 24/50\n",
      "33/33 [==============================] - 6s 174ms/step - loss: 0.0310 - mae: 2.2667e-06\n",
      "Epoch 25/50\n",
      "33/33 [==============================] - 6s 173ms/step - loss: 0.0240 - mae: 1.8341e-06\n",
      "Epoch 26/50\n",
      "33/33 [==============================] - 6s 173ms/step - loss: 0.0227 - mae: 1.5069e-06\n",
      "Epoch 27/50\n",
      "33/33 [==============================] - 6s 173ms/step - loss: 0.0292 - mae: 1.8316e-06\n",
      "Epoch 28/50\n",
      "33/33 [==============================] - 6s 173ms/step - loss: 0.0311 - mae: 1.9153e-06\n",
      "Epoch 29/50\n",
      "33/33 [==============================] - 6s 173ms/step - loss: 0.0264 - mae: 1.6910e-06\n",
      "Epoch 30/50\n",
      "33/33 [==============================] - 6s 173ms/step - loss: 0.0177 - mae: 1.3953e-06\n",
      "Epoch 31/50\n",
      "33/33 [==============================] - 6s 173ms/step - loss: 0.0245 - mae: 1.6401e-06\n",
      "Epoch 32/50\n",
      "33/33 [==============================] - 6s 173ms/step - loss: 0.0190 - mae: 1.3860e-06\n",
      "Epoch 33/50\n",
      "33/33 [==============================] - 6s 173ms/step - loss: 0.0239 - mae: 1.6101e-06\n",
      "Epoch 34/50\n",
      "33/33 [==============================] - 6s 174ms/step - loss: 0.0194 - mae: 1.2414e-06\n",
      "Epoch 35/50\n",
      "33/33 [==============================] - 6s 173ms/step - loss: 0.0215 - mae: 1.4162e-06\n",
      "Epoch 36/50\n",
      "33/33 [==============================] - 6s 173ms/step - loss: 0.0121 - mae: 9.4677e-07\n",
      "Epoch 37/50\n",
      "33/33 [==============================] - 6s 173ms/step - loss: 0.0126 - mae: 9.3711e-07\n",
      "Epoch 38/50\n",
      "33/33 [==============================] - 6s 173ms/step - loss: 0.0201 - mae: 1.1616e-06\n",
      "Epoch 39/50\n",
      "33/33 [==============================] - 6s 173ms/step - loss: 0.0103 - mae: 7.2846e-07\n",
      "Epoch 40/50\n",
      "33/33 [==============================] - 6s 173ms/step - loss: 0.0130 - mae: 9.6000e-07\n",
      "Epoch 41/50\n",
      "33/33 [==============================] - 6s 173ms/step - loss: 0.0138 - mae: 9.9428e-07\n",
      "Epoch 42/50\n",
      "33/33 [==============================] - 6s 173ms/step - loss: 0.0142 - mae: 1.0324e-06\n",
      "Epoch 43/50\n",
      "33/33 [==============================] - 6s 173ms/step - loss: 0.0160 - mae: 1.0554e-06\n",
      "Epoch 44/50\n",
      "33/33 [==============================] - 6s 173ms/step - loss: 0.0187 - mae: 9.9476e-07\n",
      "Epoch 45/50\n",
      "33/33 [==============================] - 6s 173ms/step - loss: 0.0105 - mae: 8.0913e-07\n",
      "Epoch 46/50\n",
      "33/33 [==============================] - 6s 173ms/step - loss: 0.0094 - mae: 7.0472e-07\n",
      "Epoch 47/50\n",
      "33/33 [==============================] - 6s 173ms/step - loss: 0.0160 - mae: 1.0069e-06\n",
      "Epoch 48/50\n",
      "33/33 [==============================] - 6s 174ms/step - loss: 0.0125 - mae: 8.4561e-07\n",
      "Epoch 49/50\n",
      "33/33 [==============================] - 6s 173ms/step - loss: 0.0106 - mae: 7.2094e-07\n",
      "Epoch 50/50\n",
      "33/33 [==============================] - 6s 173ms/step - loss: 0.0076 - mae: 5.2442e-07\n",
      "-----------------Model /home/sanzharrko/Рабочий стол/Atom/creation_story/models/Multi_LSTM_RNN_Model_2_books.h5 saved.-----------------\n",
      "-----------Started learning-----------\n",
      "---17/69-----------\n",
      "Number of sequences: 4722 \n",
      "\n",
      "Epoch 1/50\n",
      "33/33 [==============================] - 7s 206ms/step - loss: 7.3898 - mae: 9.3950e-05\n",
      "Epoch 2/50\n",
      "33/33 [==============================] - 7s 206ms/step - loss: 5.2672 - mae: 8.8265e-05\n",
      "Epoch 3/50\n",
      "33/33 [==============================] - 7s 206ms/step - loss: 4.1043 - mae: 8.0280e-05\n",
      "Epoch 4/50\n",
      "33/33 [==============================] - 7s 206ms/step - loss: 3.0390 - mae: 6.9744e-05\n",
      "Epoch 5/50\n",
      "33/33 [==============================] - 7s 206ms/step - loss: 2.1911 - mae: 5.9877e-05\n",
      "Epoch 6/50\n",
      "33/33 [==============================] - 7s 206ms/step - loss: 1.4720 - mae: 4.8820e-05\n",
      "Epoch 7/50\n",
      "33/33 [==============================] - 7s 206ms/step - loss: 0.9683 - mae: 3.8988e-05\n",
      "Epoch 8/50\n",
      "33/33 [==============================] - 7s 206ms/step - loss: 0.5714 - mae: 2.7591e-05\n",
      "Epoch 9/50\n",
      "33/33 [==============================] - 7s 206ms/step - loss: 0.3756 - mae: 2.0861e-05\n",
      "Epoch 10/50\n",
      "33/33 [==============================] - 7s 206ms/step - loss: 0.2491 - mae: 1.4820e-05\n",
      "Epoch 11/50\n",
      "33/33 [==============================] - 7s 207ms/step - loss: 0.1839 - mae: 1.1810e-05\n",
      "Epoch 12/50\n",
      "33/33 [==============================] - 7s 206ms/step - loss: 0.1359 - mae: 8.9264e-06\n",
      "Epoch 13/50\n",
      "33/33 [==============================] - 7s 206ms/step - loss: 0.1081 - mae: 7.2889e-06\n",
      "Epoch 14/50\n",
      "33/33 [==============================] - 7s 206ms/step - loss: 0.0959 - mae: 6.4866e-06\n",
      "Epoch 15/50\n",
      "33/33 [==============================] - 7s 206ms/step - loss: 0.0757 - mae: 5.0317e-06\n",
      "Epoch 16/50\n",
      "33/33 [==============================] - 7s 207ms/step - loss: 0.0744 - mae: 4.8660e-06\n",
      "Epoch 17/50\n",
      "33/33 [==============================] - 7s 206ms/step - loss: 0.0534 - mae: 3.7788e-06\n",
      "Epoch 18/50\n",
      "33/33 [==============================] - 7s 207ms/step - loss: 0.0607 - mae: 4.0720e-06\n",
      "Epoch 19/50\n",
      "33/33 [==============================] - 7s 207ms/step - loss: 0.0531 - mae: 3.5822e-06\n",
      "Epoch 20/50\n",
      "33/33 [==============================] - 7s 206ms/step - loss: 0.0515 - mae: 3.4986e-06\n",
      "Epoch 21/50\n",
      "33/33 [==============================] - 7s 206ms/step - loss: 0.0440 - mae: 3.0845e-06\n",
      "Epoch 22/50\n",
      "33/33 [==============================] - 7s 206ms/step - loss: 0.0416 - mae: 2.8682e-06\n",
      "Epoch 23/50\n",
      "33/33 [==============================] - 7s 206ms/step - loss: 0.0385 - mae: 2.5183e-06\n",
      "Epoch 24/50\n",
      "33/33 [==============================] - 7s 206ms/step - loss: 0.0375 - mae: 2.4299e-06\n",
      "Epoch 25/50\n",
      "33/33 [==============================] - 7s 206ms/step - loss: 0.0327 - mae: 2.0775e-06\n",
      "Epoch 26/50\n",
      "33/33 [==============================] - 7s 207ms/step - loss: 0.0275 - mae: 1.9823e-06\n",
      "Epoch 27/50\n",
      "33/33 [==============================] - 7s 207ms/step - loss: 0.0280 - mae: 2.0515e-06\n",
      "Epoch 28/50\n",
      "33/33 [==============================] - 7s 207ms/step - loss: 0.0235 - mae: 1.7696e-06\n",
      "Epoch 29/50\n",
      "33/33 [==============================] - 7s 207ms/step - loss: 0.0237 - mae: 1.6404e-06\n",
      "Epoch 30/50\n",
      "33/33 [==============================] - 7s 207ms/step - loss: 0.0237 - mae: 1.7195e-06\n",
      "Epoch 31/50\n",
      "33/33 [==============================] - 7s 207ms/step - loss: 0.0270 - mae: 1.8780e-06\n",
      "Epoch 32/50\n",
      "33/33 [==============================] - 7s 206ms/step - loss: 0.0212 - mae: 1.5377e-06\n",
      "Epoch 33/50\n",
      "33/33 [==============================] - 7s 206ms/step - loss: 0.0268 - mae: 1.7568e-06\n",
      "Epoch 34/50\n",
      "33/33 [==============================] - 7s 206ms/step - loss: 0.0195 - mae: 1.3298e-06\n",
      "Epoch 35/50\n",
      "33/33 [==============================] - 7s 206ms/step - loss: 0.0204 - mae: 1.4248e-06\n",
      "Epoch 36/50\n",
      "33/33 [==============================] - 7s 206ms/step - loss: 0.0197 - mae: 1.2597e-06\n",
      "Epoch 37/50\n",
      "33/33 [==============================] - 7s 206ms/step - loss: 0.0263 - mae: 1.6188e-06\n",
      "Epoch 38/50\n",
      "33/33 [==============================] - 7s 207ms/step - loss: 0.0190 - mae: 1.3322e-06\n",
      "Epoch 39/50\n",
      "33/33 [==============================] - 7s 207ms/step - loss: 0.0204 - mae: 1.3090e-06\n",
      "Epoch 40/50\n",
      "33/33 [==============================] - 7s 206ms/step - loss: 0.0160 - mae: 1.1085e-06\n",
      "Epoch 41/50\n",
      "33/33 [==============================] - 7s 206ms/step - loss: 0.0193 - mae: 1.1667e-06\n",
      "Epoch 42/50\n",
      "33/33 [==============================] - 7s 207ms/step - loss: 0.0218 - mae: 1.3309e-06\n",
      "Epoch 43/50\n",
      "33/33 [==============================] - 7s 206ms/step - loss: 0.0200 - mae: 1.1801e-06\n",
      "Epoch 44/50\n",
      "33/33 [==============================] - 7s 207ms/step - loss: 0.0175 - mae: 1.1487e-06\n",
      "Epoch 45/50\n",
      "33/33 [==============================] - 7s 207ms/step - loss: 0.0174 - mae: 1.2106e-06\n",
      "Epoch 46/50\n",
      "33/33 [==============================] - 7s 207ms/step - loss: 0.0199 - mae: 1.2838e-06\n",
      "Epoch 47/50\n",
      "33/33 [==============================] - 7s 206ms/step - loss: 0.0200 - mae: 1.1828e-06\n",
      "Epoch 48/50\n",
      "33/33 [==============================] - 7s 206ms/step - loss: 0.0140 - mae: 9.4871e-07\n",
      "Epoch 49/50\n",
      "33/33 [==============================] - 7s 206ms/step - loss: 0.0193 - mae: 1.0950e-06\n",
      "Epoch 50/50\n",
      "33/33 [==============================] - 7s 206ms/step - loss: 0.0229 - mae: 1.2660e-06\n",
      "-----------------Model /home/sanzharrko/Рабочий стол/Atom/creation_story/models/Multi_LSTM_RNN_Model_2_books.h5 saved.-----------------\n",
      "-----------Started learning-----------\n",
      "---18/69-----------\n",
      "Number of sequences: 6541 \n",
      "\n",
      "Epoch 1/50\n",
      "33/33 [==============================] - 9s 261ms/step - loss: 7.2934 - mae: 9.3957e-05\n",
      "Epoch 2/50\n",
      "33/33 [==============================] - 9s 261ms/step - loss: 5.3745 - mae: 8.9154e-05\n",
      "Epoch 3/50\n",
      "33/33 [==============================] - 9s 262ms/step - loss: 4.3412 - mae: 8.2754e-05\n",
      "Epoch 4/50\n",
      "33/33 [==============================] - 9s 262ms/step - loss: 3.4192 - mae: 7.4828e-05\n",
      "Epoch 5/50\n",
      "33/33 [==============================] - 9s 262ms/step - loss: 2.6262 - mae: 6.5905e-05\n",
      "Epoch 6/50\n",
      "33/33 [==============================] - 9s 262ms/step - loss: 1.9285 - mae: 5.6748e-05\n",
      "Epoch 7/50\n",
      "33/33 [==============================] - 9s 262ms/step - loss: 1.3606 - mae: 4.7656e-05\n",
      "Epoch 8/50\n",
      "33/33 [==============================] - 9s 261ms/step - loss: 0.9279 - mae: 3.8297e-05\n",
      "Epoch 9/50\n",
      "33/33 [==============================] - 9s 262ms/step - loss: 0.6190 - mae: 2.9876e-05\n",
      "Epoch 10/50\n",
      "33/33 [==============================] - 9s 262ms/step - loss: 0.4064 - mae: 2.2065e-05\n",
      "Epoch 11/50\n",
      "33/33 [==============================] - 9s 262ms/step - loss: 0.2783 - mae: 1.6485e-05\n",
      "Epoch 12/50\n",
      "33/33 [==============================] - 9s 262ms/step - loss: 0.2128 - mae: 1.3113e-05\n",
      "Epoch 13/50\n",
      "33/33 [==============================] - 9s 262ms/step - loss: 0.1501 - mae: 1.0076e-05\n",
      "Epoch 14/50\n",
      "33/33 [==============================] - 9s 262ms/step - loss: 0.1258 - mae: 8.3592e-06\n",
      "Epoch 15/50\n",
      "33/33 [==============================] - 9s 261ms/step - loss: 0.1125 - mae: 7.5464e-06\n",
      "Epoch 16/50\n",
      "33/33 [==============================] - 9s 262ms/step - loss: 0.0896 - mae: 6.0344e-06\n",
      "Epoch 17/50\n",
      "33/33 [==============================] - 9s 262ms/step - loss: 0.0696 - mae: 4.9301e-06\n",
      "Epoch 18/50\n",
      "33/33 [==============================] - 9s 262ms/step - loss: 0.0629 - mae: 4.4596e-06\n",
      "Epoch 19/50\n",
      "33/33 [==============================] - 9s 262ms/step - loss: 0.0647 - mae: 4.3704e-06\n",
      "Epoch 20/50\n",
      "33/33 [==============================] - 9s 262ms/step - loss: 0.0615 - mae: 4.1702e-06\n",
      "Epoch 21/50\n",
      "33/33 [==============================] - 9s 262ms/step - loss: 0.0652 - mae: 4.2904e-06\n",
      "Epoch 22/50\n",
      "33/33 [==============================] - 9s 262ms/step - loss: 0.0522 - mae: 3.4942e-06\n",
      "Epoch 23/50\n",
      "33/33 [==============================] - 9s 262ms/step - loss: 0.0404 - mae: 2.9327e-06\n",
      "Epoch 24/50\n",
      "33/33 [==============================] - 9s 262ms/step - loss: 0.0474 - mae: 3.2397e-06\n",
      "Epoch 25/50\n",
      "33/33 [==============================] - 9s 262ms/step - loss: 0.0421 - mae: 3.0110e-06\n",
      "Epoch 26/50\n",
      "33/33 [==============================] - 9s 262ms/step - loss: 0.0393 - mae: 2.7365e-06\n",
      "Epoch 27/50\n",
      "33/33 [==============================] - 9s 262ms/step - loss: 0.0398 - mae: 2.6211e-06\n",
      "Epoch 28/50\n",
      "33/33 [==============================] - 9s 262ms/step - loss: 0.0358 - mae: 2.3955e-06\n",
      "Epoch 29/50\n",
      "33/33 [==============================] - 9s 262ms/step - loss: 0.0383 - mae: 2.5093e-06\n",
      "Epoch 30/50\n",
      "33/33 [==============================] - 9s 262ms/step - loss: 0.0318 - mae: 2.1278e-06\n",
      "Epoch 31/50\n",
      "33/33 [==============================] - 9s 262ms/step - loss: 0.0350 - mae: 2.2817e-06\n",
      "Epoch 32/50\n",
      "33/33 [==============================] - 9s 261ms/step - loss: 0.0335 - mae: 2.1686e-06\n",
      "Epoch 33/50\n",
      "33/33 [==============================] - 9s 262ms/step - loss: 0.0252 - mae: 1.7898e-06\n",
      "Epoch 34/50\n",
      "33/33 [==============================] - 9s 262ms/step - loss: 0.0286 - mae: 1.9096e-06\n",
      "Epoch 35/50\n",
      "33/33 [==============================] - 9s 261ms/step - loss: 0.0329 - mae: 2.1395e-06\n",
      "Epoch 36/50\n",
      "33/33 [==============================] - 9s 262ms/step - loss: 0.0274 - mae: 1.8992e-06\n",
      "Epoch 37/50\n",
      "33/33 [==============================] - 9s 262ms/step - loss: 0.0252 - mae: 1.6808e-06\n",
      "Epoch 38/50\n",
      "33/33 [==============================] - 9s 262ms/step - loss: 0.0210 - mae: 1.5882e-06\n",
      "Epoch 39/50\n",
      "33/33 [==============================] - 9s 262ms/step - loss: 0.0240 - mae: 1.5934e-06\n",
      "Epoch 40/50\n",
      "33/33 [==============================] - 9s 262ms/step - loss: 0.0242 - mae: 1.5824e-06\n",
      "Epoch 41/50\n",
      "33/33 [==============================] - 9s 262ms/step - loss: 0.0238 - mae: 1.5398e-06\n",
      "Epoch 42/50\n",
      "33/33 [==============================] - 9s 262ms/step - loss: 0.0219 - mae: 1.4081e-06\n",
      "Epoch 43/50\n",
      "33/33 [==============================] - 9s 262ms/step - loss: 0.0179 - mae: 1.3268e-06\n",
      "Epoch 44/50\n",
      "33/33 [==============================] - 9s 262ms/step - loss: 0.0231 - mae: 1.5051e-06\n",
      "Epoch 45/50\n",
      "33/33 [==============================] - 9s 262ms/step - loss: 0.0259 - mae: 1.5431e-06\n",
      "Epoch 46/50\n",
      "33/33 [==============================] - 9s 262ms/step - loss: 0.0236 - mae: 1.3583e-06\n",
      "Epoch 47/50\n",
      "33/33 [==============================] - 9s 262ms/step - loss: 0.0188 - mae: 1.2148e-06\n",
      "Epoch 48/50\n",
      "33/33 [==============================] - 9s 262ms/step - loss: 0.0179 - mae: 1.2011e-06\n",
      "Epoch 49/50\n",
      "33/33 [==============================] - 9s 262ms/step - loss: 0.0136 - mae: 1.0470e-06\n",
      "Epoch 50/50\n",
      "33/33 [==============================] - 9s 262ms/step - loss: 0.0188 - mae: 1.2323e-06\n",
      "-----------------Model /home/sanzharrko/Рабочий стол/Atom/creation_story/models/Multi_LSTM_RNN_Model_2_books.h5 saved.-----------------\n",
      "-----------Started learning-----------\n",
      "---19/69-----------\n",
      "Number of sequences: 7999 \n",
      "\n",
      "Epoch 1/50\n",
      "33/33 [==============================] - 11s 308ms/step - loss: 7.0353 - mae: 9.2759e-05\n",
      "Epoch 2/50\n",
      "33/33 [==============================] - 11s 308ms/step - loss: 5.2803 - mae: 8.8450e-05\n",
      "Epoch 3/50\n",
      "33/33 [==============================] - 11s 309ms/step - loss: 4.3557 - mae: 8.2387e-05\n",
      "Epoch 4/50\n",
      "33/33 [==============================] - 11s 308ms/step - loss: 3.4930 - mae: 7.5214e-05\n",
      "Epoch 5/50\n",
      "33/33 [==============================] - 11s 309ms/step - loss: 2.7313 - mae: 6.6940e-05\n",
      "Epoch 6/50\n",
      "33/33 [==============================] - 11s 308ms/step - loss: 2.0537 - mae: 5.8711e-05\n",
      "Epoch 7/50\n",
      "33/33 [==============================] - 11s 309ms/step - loss: 1.5108 - mae: 5.0011e-05\n",
      "Epoch 8/50\n",
      "33/33 [==============================] - 11s 309ms/step - loss: 1.0582 - mae: 4.1316e-05\n",
      "Epoch 9/50\n",
      "33/33 [==============================] - 11s 309ms/step - loss: 0.7430 - mae: 3.3312e-05\n",
      "Epoch 10/50\n",
      "33/33 [==============================] - 11s 308ms/step - loss: 0.5175 - mae: 2.5854e-05\n",
      "Epoch 11/50\n",
      "33/33 [==============================] - 11s 309ms/step - loss: 0.3544 - mae: 1.9890e-05\n",
      "Epoch 12/50\n",
      "33/33 [==============================] - 11s 309ms/step - loss: 0.2701 - mae: 1.5927e-05\n",
      "Epoch 13/50\n",
      "33/33 [==============================] - 11s 309ms/step - loss: 0.2076 - mae: 1.2744e-05\n",
      "Epoch 14/50\n",
      "33/33 [==============================] - 11s 308ms/step - loss: 0.1668 - mae: 1.0536e-05\n",
      "Epoch 15/50\n",
      "33/33 [==============================] - 11s 308ms/step - loss: 0.1250 - mae: 8.4483e-06\n",
      "Epoch 16/50\n",
      "33/33 [==============================] - 11s 308ms/step - loss: 0.1246 - mae: 8.0583e-06\n",
      "Epoch 17/50\n",
      "33/33 [==============================] - 11s 308ms/step - loss: 0.0926 - mae: 6.3350e-06\n",
      "Epoch 18/50\n",
      "33/33 [==============================] - 11s 309ms/step - loss: 0.0831 - mae: 5.6413e-06\n",
      "Epoch 19/50\n",
      "33/33 [==============================] - 11s 308ms/step - loss: 0.0822 - mae: 5.4203e-06\n",
      "Epoch 20/50\n",
      "33/33 [==============================] - 11s 308ms/step - loss: 0.0766 - mae: 5.0433e-06\n",
      "Epoch 21/50\n",
      "33/33 [==============================] - 11s 308ms/step - loss: 0.0663 - mae: 4.4296e-06\n",
      "Epoch 22/50\n",
      "33/33 [==============================] - 11s 308ms/step - loss: 0.0607 - mae: 4.1665e-06\n",
      "Epoch 23/50\n",
      "33/33 [==============================] - 11s 308ms/step - loss: 0.0564 - mae: 3.7798e-06\n",
      "Epoch 24/50\n",
      "33/33 [==============================] - 11s 308ms/step - loss: 0.0562 - mae: 3.7423e-06\n",
      "Epoch 25/50\n",
      "33/33 [==============================] - 11s 308ms/step - loss: 0.0478 - mae: 3.2987e-06\n",
      "Epoch 26/50\n",
      "33/33 [==============================] - 11s 308ms/step - loss: 0.0472 - mae: 3.1487e-06\n",
      "Epoch 27/50\n",
      "33/33 [==============================] - 11s 309ms/step - loss: 0.0441 - mae: 2.9619e-06\n",
      "Epoch 28/50\n",
      "33/33 [==============================] - 11s 308ms/step - loss: 0.0454 - mae: 3.0136e-06\n",
      "Epoch 29/50\n",
      "33/33 [==============================] - 11s 309ms/step - loss: 0.0404 - mae: 2.7765e-06\n",
      "Epoch 30/50\n",
      "33/33 [==============================] - 11s 308ms/step - loss: 0.0398 - mae: 2.6757e-06\n",
      "Epoch 31/50\n",
      "33/33 [==============================] - 11s 309ms/step - loss: 0.0412 - mae: 2.6183e-06\n",
      "Epoch 32/50\n",
      "33/33 [==============================] - 11s 309ms/step - loss: 0.0368 - mae: 2.4731e-06\n",
      "Epoch 33/50\n",
      "33/33 [==============================] - 11s 308ms/step - loss: 0.0405 - mae: 2.6154e-06\n",
      "Epoch 34/50\n",
      "33/33 [==============================] - 11s 307ms/step - loss: 0.0325 - mae: 2.2066e-06\n",
      "Epoch 35/50\n",
      "33/33 [==============================] - 11s 309ms/step - loss: 0.0373 - mae: 2.4341e-06\n",
      "Epoch 36/50\n",
      "33/33 [==============================] - 11s 309ms/step - loss: 0.0370 - mae: 2.3451e-06\n",
      "Epoch 37/50\n",
      "33/33 [==============================] - 11s 308ms/step - loss: 0.0264 - mae: 1.8305e-06\n",
      "Epoch 38/50\n",
      "33/33 [==============================] - 11s 309ms/step - loss: 0.0278 - mae: 1.8990e-06\n",
      "Epoch 39/50\n",
      "33/33 [==============================] - 11s 309ms/step - loss: 0.0284 - mae: 1.9189e-06\n",
      "Epoch 40/50\n",
      "33/33 [==============================] - 11s 309ms/step - loss: 0.0284 - mae: 1.8794e-06\n",
      "Epoch 41/50\n",
      "33/33 [==============================] - 11s 309ms/step - loss: 0.0275 - mae: 1.8601e-06\n",
      "Epoch 42/50\n",
      "33/33 [==============================] - 11s 309ms/step - loss: 0.0228 - mae: 1.6128e-06\n",
      "Epoch 43/50\n",
      "33/33 [==============================] - 11s 308ms/step - loss: 0.0250 - mae: 1.7504e-06\n",
      "Epoch 44/50\n",
      "33/33 [==============================] - 11s 309ms/step - loss: 0.0261 - mae: 1.7341e-06\n",
      "Epoch 45/50\n",
      "33/33 [==============================] - 11s 309ms/step - loss: 0.0215 - mae: 1.4448e-06\n",
      "Epoch 46/50\n",
      "33/33 [==============================] - 11s 308ms/step - loss: 0.0232 - mae: 1.5878e-06\n",
      "Epoch 47/50\n",
      "33/33 [==============================] - 11s 309ms/step - loss: 0.0225 - mae: 1.5066e-06\n",
      "Epoch 48/50\n",
      "33/33 [==============================] - 11s 309ms/step - loss: 0.0252 - mae: 1.5222e-06\n",
      "Epoch 49/50\n",
      "33/33 [==============================] - 11s 308ms/step - loss: 0.0258 - mae: 1.5869e-06\n",
      "Epoch 50/50\n",
      "33/33 [==============================] - 11s 308ms/step - loss: 0.0245 - mae: 1.4960e-06\n",
      "-----------------Model /home/sanzharrko/Рабочий стол/Atom/creation_story/models/Multi_LSTM_RNN_Model_2_books.h5 saved.-----------------\n",
      "-----------Started learning-----------\n",
      "---20/69-----------\n",
      "Number of sequences: 8554 \n",
      "\n",
      "Epoch 1/50\n",
      "33/33 [==============================] - 12s 338ms/step - loss: 7.5204 - mae: 9.7009e-05\n",
      "Epoch 2/50\n",
      "33/33 [==============================] - 12s 339ms/step - loss: 5.7583 - mae: 9.3510e-05\n",
      "Epoch 3/50\n",
      "33/33 [==============================] - 12s 339ms/step - loss: 4.8622 - mae: 8.8462e-05\n",
      "Epoch 4/50\n",
      "33/33 [==============================] - 12s 339ms/step - loss: 4.0212 - mae: 8.2099e-05\n",
      "Epoch 5/50\n",
      "33/33 [==============================] - 12s 339ms/step - loss: 3.2197 - mae: 7.4392e-05\n",
      "Epoch 6/50\n",
      "33/33 [==============================] - 12s 339ms/step - loss: 2.5084 - mae: 6.6783e-05\n",
      "Epoch 7/50\n",
      "33/33 [==============================] - 12s 339ms/step - loss: 1.8717 - mae: 5.7585e-05\n",
      "Epoch 8/50\n",
      "33/33 [==============================] - 12s 339ms/step - loss: 1.3594 - mae: 4.8473e-05\n",
      "Epoch 9/50\n",
      "33/33 [==============================] - 12s 339ms/step - loss: 0.9534 - mae: 3.9045e-05\n",
      "Epoch 10/50\n",
      "33/33 [==============================] - 12s 339ms/step - loss: 0.6694 - mae: 3.0920e-05\n",
      "Epoch 11/50\n",
      "33/33 [==============================] - 12s 339ms/step - loss: 0.4701 - mae: 2.4398e-05\n",
      "Epoch 12/50\n",
      "33/33 [==============================] - 12s 339ms/step - loss: 0.3373 - mae: 1.8930e-05\n",
      "Epoch 13/50\n",
      "33/33 [==============================] - 12s 339ms/step - loss: 0.2489 - mae: 1.4946e-05\n",
      "Epoch 14/50\n",
      "33/33 [==============================] - 12s 339ms/step - loss: 0.2079 - mae: 1.2646e-05\n",
      "Epoch 15/50\n",
      "33/33 [==============================] - 12s 339ms/step - loss: 0.1575 - mae: 1.0195e-05\n",
      "Epoch 16/50\n",
      "33/33 [==============================] - 12s 340ms/step - loss: 0.1457 - mae: 9.2271e-06\n",
      "Epoch 17/50\n",
      "33/33 [==============================] - 12s 339ms/step - loss: 0.1109 - mae: 7.4370e-06\n",
      "Epoch 18/50\n",
      "33/33 [==============================] - 12s 340ms/step - loss: 0.1021 - mae: 6.7938e-06\n",
      "Epoch 19/50\n",
      "33/33 [==============================] - 12s 339ms/step - loss: 0.0959 - mae: 6.2795e-06\n",
      "Epoch 20/50\n",
      "33/33 [==============================] - 12s 340ms/step - loss: 0.0850 - mae: 5.5716e-06\n",
      "Epoch 21/50\n",
      "33/33 [==============================] - 12s 339ms/step - loss: 0.0832 - mae: 5.4618e-06\n",
      "Epoch 22/50\n",
      "33/33 [==============================] - 12s 340ms/step - loss: 0.0691 - mae: 4.5268e-06\n",
      "Epoch 23/50\n",
      "33/33 [==============================] - 12s 339ms/step - loss: 0.0745 - mae: 4.6973e-06\n",
      "Epoch 24/50\n",
      "33/33 [==============================] - 12s 340ms/step - loss: 0.0692 - mae: 4.4620e-06\n",
      "Epoch 25/50\n",
      "33/33 [==============================] - 12s 339ms/step - loss: 0.0622 - mae: 4.0032e-06\n",
      "Epoch 26/50\n",
      "33/33 [==============================] - 12s 338ms/step - loss: 0.0508 - mae: 3.5125e-06\n",
      "Epoch 27/50\n",
      "33/33 [==============================] - 12s 339ms/step - loss: 0.0525 - mae: 3.5320e-06\n",
      "Epoch 28/50\n",
      "33/33 [==============================] - 12s 339ms/step - loss: 0.0538 - mae: 3.2517e-06\n",
      "Epoch 29/50\n",
      "33/33 [==============================] - 12s 338ms/step - loss: 0.0467 - mae: 3.2660e-06\n",
      "Epoch 30/50\n",
      "33/33 [==============================] - 12s 339ms/step - loss: 0.0455 - mae: 2.9838e-06\n",
      "Epoch 31/50\n",
      "33/33 [==============================] - 12s 339ms/step - loss: 0.0467 - mae: 3.0864e-06\n",
      "Epoch 32/50\n",
      "33/33 [==============================] - 12s 339ms/step - loss: 0.0403 - mae: 2.6007e-06\n",
      "Epoch 33/50\n",
      "33/33 [==============================] - 12s 338ms/step - loss: 0.0383 - mae: 2.5311e-06\n",
      "Epoch 34/50\n",
      "33/33 [==============================] - 12s 340ms/step - loss: 0.0361 - mae: 2.4866e-06\n",
      "Epoch 35/50\n",
      "33/33 [==============================] - 12s 339ms/step - loss: 0.0438 - mae: 2.6903e-06\n",
      "Epoch 36/50\n",
      "33/33 [==============================] - 12s 339ms/step - loss: 0.0386 - mae: 2.6074e-06\n",
      "Epoch 37/50\n",
      "33/33 [==============================] - 12s 340ms/step - loss: 0.0375 - mae: 2.4796e-06\n",
      "Epoch 38/50\n",
      "33/33 [==============================] - 12s 338ms/step - loss: 0.0322 - mae: 2.2288e-06\n",
      "Epoch 39/50\n",
      "33/33 [==============================] - 12s 339ms/step - loss: 0.0355 - mae: 2.3835e-06\n",
      "Epoch 40/50\n",
      "33/33 [==============================] - 12s 340ms/step - loss: 0.0334 - mae: 2.1975e-06\n",
      "Epoch 41/50\n",
      "33/33 [==============================] - 12s 340ms/step - loss: 0.0310 - mae: 2.0483e-06\n",
      "Epoch 42/50\n",
      "33/33 [==============================] - 12s 339ms/step - loss: 0.0375 - mae: 2.1479e-06\n",
      "Epoch 43/50\n",
      "33/33 [==============================] - 12s 339ms/step - loss: 0.0369 - mae: 2.2015e-06\n",
      "Epoch 44/50\n",
      "33/33 [==============================] - 12s 338ms/step - loss: 0.0267 - mae: 1.7628e-06\n",
      "Epoch 45/50\n",
      "33/33 [==============================] - 12s 339ms/step - loss: 0.0370 - mae: 2.2778e-06\n",
      "Epoch 46/50\n",
      "33/33 [==============================] - 12s 339ms/step - loss: 0.0286 - mae: 1.9027e-06\n",
      "Epoch 47/50\n",
      "33/33 [==============================] - 12s 340ms/step - loss: 0.0274 - mae: 1.7655e-06\n",
      "Epoch 48/50\n",
      "33/33 [==============================] - 12s 339ms/step - loss: 0.0256 - mae: 1.6482e-06\n",
      "Epoch 49/50\n",
      "33/33 [==============================] - 12s 339ms/step - loss: 0.0261 - mae: 1.7782e-06\n",
      "Epoch 50/50\n",
      "33/33 [==============================] - 12s 340ms/step - loss: 0.0275 - mae: 1.7350e-06\n",
      "-----------------Model /home/sanzharrko/Рабочий стол/Atom/creation_story/models/Multi_LSTM_RNN_Model_2_books.h5 saved.-----------------\n",
      "-----------Started learning-----------\n",
      "---21/69-----------\n",
      "Number of sequences: 7750 \n",
      "\n",
      "Epoch 1/50\n",
      "33/33 [==============================] - 10s 287ms/step - loss: 7.2034 - mae: 9.3307e-05\n",
      "Epoch 2/50\n",
      "33/33 [==============================] - 10s 288ms/step - loss: 5.3484 - mae: 8.9152e-05\n",
      "Epoch 3/50\n",
      "33/33 [==============================] - 10s 288ms/step - loss: 4.4008 - mae: 8.3193e-05\n",
      "Epoch 4/50\n",
      "33/33 [==============================] - 10s 288ms/step - loss: 3.5225 - mae: 7.5770e-05\n",
      "Epoch 5/50\n",
      "33/33 [==============================] - 10s 288ms/step - loss: 2.7899 - mae: 6.8029e-05\n",
      "Epoch 6/50\n",
      "33/33 [==============================] - 10s 289ms/step - loss: 2.1094 - mae: 5.9074e-05\n",
      "Epoch 7/50\n",
      "33/33 [==============================] - 10s 289ms/step - loss: 1.5799 - mae: 5.1044e-05\n",
      "Epoch 8/50\n",
      "33/33 [==============================] - 10s 288ms/step - loss: 1.1104 - mae: 4.2062e-05\n",
      "Epoch 9/50\n",
      "33/33 [==============================] - 10s 289ms/step - loss: 0.7770 - mae: 3.3608e-05\n",
      "Epoch 10/50\n",
      "33/33 [==============================] - 10s 288ms/step - loss: 0.5634 - mae: 2.6888e-05\n",
      "Epoch 11/50\n",
      "33/33 [==============================] - 10s 288ms/step - loss: 0.4003 - mae: 2.0906e-05\n",
      "Epoch 12/50\n",
      "33/33 [==============================] - 10s 289ms/step - loss: 0.2893 - mae: 1.6473e-05\n",
      "Epoch 13/50\n",
      "33/33 [==============================] - 10s 288ms/step - loss: 0.2117 - mae: 1.2980e-05\n",
      "Epoch 14/50\n",
      "33/33 [==============================] - 10s 288ms/step - loss: 0.1812 - mae: 1.1056e-05\n",
      "Epoch 15/50\n",
      "33/33 [==============================] - 10s 289ms/step - loss: 0.1551 - mae: 9.5660e-06\n",
      "Epoch 16/50\n",
      "33/33 [==============================] - 10s 288ms/step - loss: 0.1426 - mae: 8.7540e-06\n",
      "Epoch 17/50\n",
      "33/33 [==============================] - 10s 289ms/step - loss: 0.1174 - mae: 7.5524e-06\n",
      "Epoch 18/50\n",
      "33/33 [==============================] - 10s 288ms/step - loss: 0.0991 - mae: 6.4711e-06\n",
      "Epoch 19/50\n",
      "33/33 [==============================] - 10s 289ms/step - loss: 0.0946 - mae: 6.0740e-06\n",
      "Epoch 20/50\n",
      "33/33 [==============================] - 10s 288ms/step - loss: 0.0964 - mae: 5.8472e-06\n",
      "Epoch 21/50\n",
      "33/33 [==============================] - 10s 289ms/step - loss: 0.0855 - mae: 5.2933e-06\n",
      "Epoch 22/50\n",
      "33/33 [==============================] - 10s 289ms/step - loss: 0.0678 - mae: 4.4578e-06\n",
      "Epoch 23/50\n",
      "33/33 [==============================] - 10s 288ms/step - loss: 0.0685 - mae: 4.3061e-06\n",
      "Epoch 24/50\n",
      "33/33 [==============================] - 10s 289ms/step - loss: 0.0648 - mae: 4.1109e-06\n",
      "Epoch 25/50\n",
      "33/33 [==============================] - 10s 288ms/step - loss: 0.0563 - mae: 3.7136e-06\n",
      "Epoch 26/50\n",
      "33/33 [==============================] - 10s 289ms/step - loss: 0.0622 - mae: 3.9686e-06\n",
      "Epoch 27/50\n",
      "33/33 [==============================] - 10s 288ms/step - loss: 0.0598 - mae: 3.7637e-06\n",
      "Epoch 28/50\n",
      "33/33 [==============================] - 10s 289ms/step - loss: 0.0537 - mae: 3.4157e-06\n",
      "Epoch 29/50\n",
      "33/33 [==============================] - 10s 288ms/step - loss: 0.0522 - mae: 3.2250e-06\n",
      "Epoch 30/50\n",
      "33/33 [==============================] - 10s 288ms/step - loss: 0.0477 - mae: 3.0151e-06\n",
      "Epoch 31/50\n",
      "33/33 [==============================] - 10s 288ms/step - loss: 0.0408 - mae: 2.8624e-06\n",
      "Epoch 32/50\n",
      "33/33 [==============================] - 10s 289ms/step - loss: 0.0525 - mae: 3.1743e-06\n",
      "Epoch 33/50\n",
      "33/33 [==============================] - 10s 289ms/step - loss: 0.0441 - mae: 2.7310e-06\n",
      "Epoch 34/50\n",
      "33/33 [==============================] - 10s 288ms/step - loss: 0.0464 - mae: 2.8222e-06\n",
      "Epoch 35/50\n",
      "33/33 [==============================] - 10s 288ms/step - loss: 0.0387 - mae: 2.4900e-06\n",
      "Epoch 36/50\n",
      "33/33 [==============================] - 10s 288ms/step - loss: 0.0341 - mae: 2.2521e-06\n",
      "Epoch 37/50\n",
      "33/33 [==============================] - 10s 288ms/step - loss: 0.0333 - mae: 2.2927e-06\n",
      "Epoch 38/50\n",
      "33/33 [==============================] - 10s 289ms/step - loss: 0.0421 - mae: 2.5427e-06\n",
      "Epoch 39/50\n",
      "33/33 [==============================] - 10s 288ms/step - loss: 0.0337 - mae: 2.2500e-06\n",
      "Epoch 40/50\n",
      "33/33 [==============================] - 10s 288ms/step - loss: 0.0362 - mae: 2.2158e-06\n",
      "Epoch 41/50\n",
      "33/33 [==============================] - 10s 288ms/step - loss: 0.0334 - mae: 2.1700e-06\n",
      "Epoch 42/50\n",
      "33/33 [==============================] - 10s 288ms/step - loss: 0.0273 - mae: 1.8345e-06\n",
      "Epoch 43/50\n",
      "33/33 [==============================] - 10s 289ms/step - loss: 0.0301 - mae: 1.9119e-06\n",
      "Epoch 44/50\n",
      "33/33 [==============================] - 10s 289ms/step - loss: 0.0261 - mae: 1.6730e-06\n",
      "Epoch 45/50\n",
      "33/33 [==============================] - 10s 289ms/step - loss: 0.0321 - mae: 1.9323e-06\n",
      "Epoch 46/50\n",
      "33/33 [==============================] - 10s 289ms/step - loss: 0.0329 - mae: 2.0615e-06\n",
      "Epoch 47/50\n",
      "33/33 [==============================] - 10s 288ms/step - loss: 0.0301 - mae: 1.8728e-06\n",
      "Epoch 48/50\n",
      "33/33 [==============================] - 10s 288ms/step - loss: 0.0291 - mae: 1.8112e-06\n",
      "Epoch 49/50\n",
      "33/33 [==============================] - 10s 289ms/step - loss: 0.0260 - mae: 1.6869e-06\n",
      "Epoch 50/50\n",
      "33/33 [==============================] - 10s 288ms/step - loss: 0.0221 - mae: 1.4805e-06\n",
      "-----------------Model /home/sanzharrko/Рабочий стол/Atom/creation_story/models/Multi_LSTM_RNN_Model_2_books.h5 saved.-----------------\n",
      "-----------Started learning-----------\n",
      "---22/69-----------\n",
      "Number of sequences: 4060 \n",
      "\n",
      "Epoch 1/50\n",
      "33/33 [==============================] - 6s 175ms/step - loss: 7.4559 - mae: 9.3677e-05\n",
      "Epoch 2/50\n",
      "33/33 [==============================] - 6s 175ms/step - loss: 5.2769 - mae: 8.7782e-05\n",
      "Epoch 3/50\n",
      "33/33 [==============================] - 6s 175ms/step - loss: 4.0920 - mae: 7.9476e-05\n",
      "Epoch 4/50\n",
      "33/33 [==============================] - 6s 175ms/step - loss: 3.0356 - mae: 6.9012e-05\n",
      "Epoch 5/50\n",
      "33/33 [==============================] - 6s 175ms/step - loss: 2.1812 - mae: 5.8692e-05\n",
      "Epoch 6/50\n",
      "33/33 [==============================] - 6s 175ms/step - loss: 1.4896 - mae: 4.8062e-05\n",
      "Epoch 7/50\n",
      "33/33 [==============================] - 6s 175ms/step - loss: 1.0120 - mae: 3.7882e-05\n",
      "Epoch 8/50\n",
      "33/33 [==============================] - 6s 176ms/step - loss: 0.6724 - mae: 2.9818e-05\n",
      "Epoch 9/50\n",
      "33/33 [==============================] - 6s 176ms/step - loss: 0.4433 - mae: 2.2508e-05\n",
      "Epoch 10/50\n",
      "33/33 [==============================] - 6s 176ms/step - loss: 0.2998 - mae: 1.6658e-05\n",
      "Epoch 11/50\n",
      "33/33 [==============================] - 6s 175ms/step - loss: 0.2230 - mae: 1.3033e-05\n",
      "Epoch 12/50\n",
      "33/33 [==============================] - 6s 175ms/step - loss: 0.1751 - mae: 1.0754e-05\n",
      "Epoch 13/50\n",
      "33/33 [==============================] - 6s 175ms/step - loss: 0.1344 - mae: 8.4714e-06\n",
      "Epoch 14/50\n",
      "33/33 [==============================] - 6s 176ms/step - loss: 0.1118 - mae: 7.2560e-06\n",
      "Epoch 15/50\n",
      "33/33 [==============================] - 6s 175ms/step - loss: 0.0976 - mae: 6.3591e-06\n",
      "Epoch 16/50\n",
      "33/33 [==============================] - 6s 175ms/step - loss: 0.0898 - mae: 5.7327e-06\n",
      "Epoch 17/50\n",
      "33/33 [==============================] - 6s 175ms/step - loss: 0.0758 - mae: 4.8061e-06\n",
      "Epoch 18/50\n",
      "33/33 [==============================] - 6s 175ms/step - loss: 0.0832 - mae: 4.6769e-06\n",
      "Epoch 19/50\n",
      "33/33 [==============================] - 6s 175ms/step - loss: 0.0769 - mae: 4.6724e-06\n",
      "Epoch 20/50\n",
      "33/33 [==============================] - 6s 175ms/step - loss: 0.0607 - mae: 3.9271e-06\n",
      "Epoch 21/50\n",
      "33/33 [==============================] - 6s 175ms/step - loss: 0.0506 - mae: 3.2660e-06\n",
      "Epoch 22/50\n",
      "33/33 [==============================] - 6s 175ms/step - loss: 0.0524 - mae: 3.4301e-06\n",
      "Epoch 23/50\n",
      "33/33 [==============================] - 6s 176ms/step - loss: 0.0606 - mae: 3.4760e-06\n",
      "Epoch 24/50\n",
      "33/33 [==============================] - 6s 175ms/step - loss: 0.0588 - mae: 3.3187e-06\n",
      "Epoch 25/50\n",
      "33/33 [==============================] - 6s 176ms/step - loss: 0.0540 - mae: 3.1814e-06\n",
      "Epoch 26/50\n",
      "33/33 [==============================] - 6s 175ms/step - loss: 0.0422 - mae: 2.8000e-06\n",
      "Epoch 27/50\n",
      "33/33 [==============================] - 6s 175ms/step - loss: 0.0395 - mae: 2.5999e-06\n",
      "Epoch 28/50\n",
      "33/33 [==============================] - 6s 175ms/step - loss: 0.0434 - mae: 2.7376e-06\n",
      "Epoch 29/50\n",
      "33/33 [==============================] - 6s 175ms/step - loss: 0.0339 - mae: 2.3365e-06\n",
      "Epoch 30/50\n",
      "33/33 [==============================] - 6s 175ms/step - loss: 0.0434 - mae: 2.5021e-06\n",
      "Epoch 31/50\n",
      "33/33 [==============================] - 6s 175ms/step - loss: 0.0311 - mae: 2.1575e-06\n",
      "Epoch 32/50\n",
      "33/33 [==============================] - 6s 175ms/step - loss: 0.0371 - mae: 2.3799e-06\n",
      "Epoch 33/50\n",
      "33/33 [==============================] - 6s 176ms/step - loss: 0.0378 - mae: 2.2246e-06\n",
      "Epoch 34/50\n",
      "33/33 [==============================] - 6s 175ms/step - loss: 0.0332 - mae: 2.1345e-06\n",
      "Epoch 35/50\n",
      "33/33 [==============================] - 6s 176ms/step - loss: 0.0349 - mae: 2.2011e-06\n",
      "Epoch 36/50\n",
      "33/33 [==============================] - 6s 176ms/step - loss: 0.0377 - mae: 2.1029e-06\n",
      "Epoch 37/50\n",
      "33/33 [==============================] - 6s 176ms/step - loss: 0.0296 - mae: 1.7830e-06\n",
      "Epoch 38/50\n",
      "33/33 [==============================] - 6s 176ms/step - loss: 0.0257 - mae: 1.5723e-06\n",
      "Epoch 39/50\n",
      "33/33 [==============================] - 6s 176ms/step - loss: 0.0357 - mae: 2.0616e-06\n",
      "Epoch 40/50\n",
      "33/33 [==============================] - 6s 175ms/step - loss: 0.0312 - mae: 1.8938e-06\n",
      "Epoch 41/50\n",
      "33/33 [==============================] - 6s 176ms/step - loss: 0.0299 - mae: 1.6806e-06\n",
      "Epoch 42/50\n",
      "33/33 [==============================] - 6s 175ms/step - loss: 0.0259 - mae: 1.7198e-06\n",
      "Epoch 43/50\n",
      "33/33 [==============================] - 6s 175ms/step - loss: 0.0303 - mae: 1.6225e-06\n",
      "Epoch 44/50\n",
      "33/33 [==============================] - 6s 175ms/step - loss: 0.0268 - mae: 1.6214e-06\n",
      "Epoch 45/50\n",
      "33/33 [==============================] - 6s 175ms/step - loss: 0.0239 - mae: 1.5722e-06\n",
      "Epoch 46/50\n",
      "33/33 [==============================] - 6s 175ms/step - loss: 0.0239 - mae: 1.4812e-06\n",
      "Epoch 47/50\n",
      "33/33 [==============================] - 6s 176ms/step - loss: 0.0210 - mae: 1.2677e-06\n",
      "Epoch 48/50\n",
      "33/33 [==============================] - 6s 176ms/step - loss: 0.0183 - mae: 1.2078e-06\n",
      "Epoch 49/50\n",
      "33/33 [==============================] - 6s 175ms/step - loss: 0.0280 - mae: 1.6490e-06\n",
      "Epoch 50/50\n",
      "33/33 [==============================] - 6s 175ms/step - loss: 0.0279 - mae: 1.6471e-06\n",
      "-----------------Model /home/sanzharrko/Рабочий стол/Atom/creation_story/models/Multi_LSTM_RNN_Model_2_books.h5 saved.-----------------\n",
      "-----------Started learning-----------\n",
      "---23/69-----------\n",
      "Number of sequences: 7194 \n",
      "\n",
      "Epoch 1/50\n",
      "33/33 [==============================] - 10s 298ms/step - loss: 7.1719 - mae: 9.2161e-05\n",
      "Epoch 2/50\n",
      "33/33 [==============================] - 10s 298ms/step - loss: 5.3007 - mae: 8.8158e-05\n",
      "Epoch 3/50\n",
      "33/33 [==============================] - 10s 299ms/step - loss: 4.3076 - mae: 8.2047e-05\n",
      "Epoch 4/50\n",
      "33/33 [==============================] - 10s 298ms/step - loss: 3.4429 - mae: 7.4328e-05\n",
      "Epoch 5/50\n",
      "33/33 [==============================] - 10s 298ms/step - loss: 2.7089 - mae: 6.6899e-05\n",
      "Epoch 6/50\n",
      "33/33 [==============================] - 10s 298ms/step - loss: 2.0645 - mae: 5.8598e-05\n",
      "Epoch 7/50\n",
      "33/33 [==============================] - 10s 298ms/step - loss: 1.5374 - mae: 5.0457e-05\n",
      "Epoch 8/50\n",
      "33/33 [==============================] - 10s 298ms/step - loss: 1.0987 - mae: 4.2103e-05\n",
      "Epoch 9/50\n",
      "33/33 [==============================] - 10s 299ms/step - loss: 0.7738 - mae: 3.3755e-05\n",
      "Epoch 10/50\n",
      "33/33 [==============================] - 10s 298ms/step - loss: 0.5539 - mae: 2.6998e-05\n",
      "Epoch 11/50\n",
      "33/33 [==============================] - 10s 298ms/step - loss: 0.3920 - mae: 2.0926e-05\n",
      "Epoch 12/50\n",
      "33/33 [==============================] - 10s 298ms/step - loss: 0.2998 - mae: 1.6869e-05\n",
      "Epoch 13/50\n",
      "33/33 [==============================] - 10s 298ms/step - loss: 0.2277 - mae: 1.3747e-05\n",
      "Epoch 14/50\n",
      "33/33 [==============================] - 10s 298ms/step - loss: 0.1892 - mae: 1.1551e-05\n",
      "Epoch 15/50\n",
      "33/33 [==============================] - 10s 297ms/step - loss: 0.1532 - mae: 9.7780e-06\n",
      "Epoch 16/50\n",
      "33/33 [==============================] - 10s 298ms/step - loss: 0.1384 - mae: 8.5524e-06\n",
      "Epoch 17/50\n",
      "33/33 [==============================] - 10s 297ms/step - loss: 0.1223 - mae: 7.6602e-06\n",
      "Epoch 18/50\n",
      "33/33 [==============================] - 10s 297ms/step - loss: 0.1093 - mae: 6.9701e-06\n",
      "Epoch 19/50\n",
      "33/33 [==============================] - 10s 299ms/step - loss: 0.0876 - mae: 5.7943e-06\n",
      "Epoch 20/50\n",
      "33/33 [==============================] - 10s 298ms/step - loss: 0.0829 - mae: 5.3560e-06\n",
      "Epoch 21/50\n",
      "33/33 [==============================] - 10s 298ms/step - loss: 0.0788 - mae: 5.0373e-06\n",
      "Epoch 22/50\n",
      "33/33 [==============================] - 10s 299ms/step - loss: 0.0843 - mae: 5.2279e-06\n",
      "Epoch 23/50\n",
      "33/33 [==============================] - 10s 298ms/step - loss: 0.0747 - mae: 4.8095e-06\n",
      "Epoch 24/50\n",
      "33/33 [==============================] - 10s 298ms/step - loss: 0.0638 - mae: 4.1288e-06\n",
      "Epoch 25/50\n",
      "33/33 [==============================] - 10s 298ms/step - loss: 0.0598 - mae: 3.9828e-06\n",
      "Epoch 26/50\n",
      "33/33 [==============================] - 10s 299ms/step - loss: 0.0598 - mae: 3.7906e-06\n",
      "Epoch 27/50\n",
      "33/33 [==============================] - 10s 298ms/step - loss: 0.0577 - mae: 3.6273e-06\n",
      "Epoch 28/50\n",
      "33/33 [==============================] - 10s 298ms/step - loss: 0.0568 - mae: 3.5639e-06\n",
      "Epoch 29/50\n",
      "33/33 [==============================] - 10s 299ms/step - loss: 0.0574 - mae: 3.5758e-06\n",
      "Epoch 30/50\n",
      "33/33 [==============================] - 10s 299ms/step - loss: 0.0497 - mae: 3.0933e-06\n",
      "Epoch 31/50\n",
      "33/33 [==============================] - 10s 298ms/step - loss: 0.0455 - mae: 2.9968e-06\n",
      "Epoch 32/50\n",
      "33/33 [==============================] - 10s 298ms/step - loss: 0.0440 - mae: 2.8518e-06\n",
      "Epoch 33/50\n",
      "33/33 [==============================] - 10s 299ms/step - loss: 0.0487 - mae: 3.0209e-06\n",
      "Epoch 34/50\n",
      "33/33 [==============================] - 10s 298ms/step - loss: 0.0390 - mae: 2.5574e-06\n",
      "Epoch 35/50\n",
      "33/33 [==============================] - 10s 298ms/step - loss: 0.0388 - mae: 2.5003e-06\n",
      "Epoch 36/50\n",
      "33/33 [==============================] - 10s 298ms/step - loss: 0.0374 - mae: 2.3841e-06\n",
      "Epoch 37/50\n",
      "33/33 [==============================] - 10s 298ms/step - loss: 0.0471 - mae: 2.7899e-06\n",
      "Epoch 38/50\n",
      "33/33 [==============================] - 10s 297ms/step - loss: 0.0407 - mae: 2.5312e-06\n",
      "Epoch 39/50\n",
      "33/33 [==============================] - 10s 298ms/step - loss: 0.0386 - mae: 2.4307e-06\n",
      "Epoch 40/50\n",
      "33/33 [==============================] - 10s 299ms/step - loss: 0.0381 - mae: 2.3772e-06\n",
      "Epoch 41/50\n",
      "33/33 [==============================] - 10s 298ms/step - loss: 0.0339 - mae: 2.0596e-06\n",
      "Epoch 42/50\n",
      "33/33 [==============================] - 10s 298ms/step - loss: 0.0358 - mae: 2.2351e-06\n",
      "Epoch 43/50\n",
      "33/33 [==============================] - 10s 299ms/step - loss: 0.0298 - mae: 1.9276e-06\n",
      "Epoch 44/50\n",
      "33/33 [==============================] - 10s 298ms/step - loss: 0.0302 - mae: 1.9587e-06\n",
      "Epoch 45/50\n",
      "33/33 [==============================] - 10s 298ms/step - loss: 0.0329 - mae: 1.9903e-06\n",
      "Epoch 46/50\n",
      "33/33 [==============================] - 10s 298ms/step - loss: 0.0359 - mae: 2.0937e-06\n",
      "Epoch 47/50\n",
      "33/33 [==============================] - 10s 298ms/step - loss: 0.0274 - mae: 1.7202e-06\n",
      "Epoch 48/50\n",
      "33/33 [==============================] - 10s 299ms/step - loss: 0.0295 - mae: 1.8428e-06\n",
      "Epoch 49/50\n",
      "33/33 [==============================] - 10s 298ms/step - loss: 0.0312 - mae: 1.8464e-06\n",
      "Epoch 50/50\n",
      "33/33 [==============================] - 10s 298ms/step - loss: 0.0277 - mae: 1.7998e-06\n",
      "-----------------Model /home/sanzharrko/Рабочий стол/Atom/creation_story/models/Multi_LSTM_RNN_Model_2_books.h5 saved.-----------------\n",
      "-----------Started learning-----------\n",
      "---24/69-----------\n",
      "Number of sequences: 8826 \n",
      "\n",
      "Epoch 1/50\n",
      "33/33 [==============================] - 12s 355ms/step - loss: 7.2551 - mae: 9.2608e-05\n",
      "Epoch 2/50\n",
      "33/33 [==============================] - 12s 354ms/step - loss: 5.3802 - mae: 8.8557e-05\n",
      "Epoch 3/50\n",
      "33/33 [==============================] - 12s 355ms/step - loss: 4.4702 - mae: 8.3099e-05\n",
      "Epoch 4/50\n",
      "33/33 [==============================] - 12s 354ms/step - loss: 3.6633 - mae: 7.7076e-05\n",
      "Epoch 5/50\n",
      "33/33 [==============================] - 12s 355ms/step - loss: 2.9793 - mae: 6.9951e-05\n",
      "Epoch 6/50\n",
      "33/33 [==============================] - 12s 355ms/step - loss: 2.3554 - mae: 6.2944e-05\n",
      "Epoch 7/50\n",
      "33/33 [==============================] - 12s 355ms/step - loss: 1.8007 - mae: 5.4946e-05\n",
      "Epoch 8/50\n",
      "33/33 [==============================] - 12s 356ms/step - loss: 1.3634 - mae: 4.7339e-05\n",
      "Epoch 9/50\n",
      "33/33 [==============================] - 12s 355ms/step - loss: 0.9860 - mae: 3.9017e-05\n",
      "Epoch 10/50\n",
      "33/33 [==============================] - 12s 355ms/step - loss: 0.7260 - mae: 3.2042e-05\n",
      "Epoch 11/50\n",
      "33/33 [==============================] - 12s 355ms/step - loss: 0.5410 - mae: 2.5856e-05\n",
      "Epoch 12/50\n",
      "33/33 [==============================] - 12s 356ms/step - loss: 0.3857 - mae: 2.0544e-05\n",
      "Epoch 13/50\n",
      "33/33 [==============================] - 12s 355ms/step - loss: 0.2948 - mae: 1.6653e-05\n",
      "Epoch 14/50\n",
      "33/33 [==============================] - 12s 356ms/step - loss: 0.2327 - mae: 1.3905e-05\n",
      "Epoch 15/50\n",
      "33/33 [==============================] - 12s 356ms/step - loss: 0.1859 - mae: 1.1533e-05\n",
      "Epoch 16/50\n",
      "33/33 [==============================] - 12s 356ms/step - loss: 0.1582 - mae: 9.9034e-06\n",
      "Epoch 17/50\n",
      "33/33 [==============================] - 12s 356ms/step - loss: 0.1515 - mae: 9.3614e-06\n",
      "Epoch 18/50\n",
      "33/33 [==============================] - 12s 356ms/step - loss: 0.1294 - mae: 8.0058e-06\n",
      "Epoch 19/50\n",
      "33/33 [==============================] - 12s 355ms/step - loss: 0.1208 - mae: 7.6654e-06\n",
      "Epoch 20/50\n",
      "33/33 [==============================] - 12s 355ms/step - loss: 0.1027 - mae: 6.5357e-06\n",
      "Epoch 21/50\n",
      "33/33 [==============================] - 12s 355ms/step - loss: 0.0909 - mae: 5.9364e-06\n",
      "Epoch 22/50\n",
      "33/33 [==============================] - 12s 356ms/step - loss: 0.0789 - mae: 5.2085e-06\n",
      "Epoch 23/50\n",
      "33/33 [==============================] - 12s 356ms/step - loss: 0.0858 - mae: 5.4739e-06\n",
      "Epoch 24/50\n",
      "33/33 [==============================] - 12s 355ms/step - loss: 0.0851 - mae: 5.3028e-06\n",
      "Epoch 25/50\n",
      "33/33 [==============================] - 12s 355ms/step - loss: 0.0824 - mae: 5.0696e-06\n",
      "Epoch 26/50\n",
      "33/33 [==============================] - 12s 355ms/step - loss: 0.0705 - mae: 4.6108e-06\n",
      "Epoch 27/50\n",
      "33/33 [==============================] - 12s 355ms/step - loss: 0.0672 - mae: 4.1866e-06\n",
      "Epoch 28/50\n",
      "33/33 [==============================] - 12s 355ms/step - loss: 0.0631 - mae: 4.1357e-06\n",
      "Epoch 29/50\n",
      "33/33 [==============================] - 12s 355ms/step - loss: 0.0685 - mae: 4.1021e-06\n",
      "Epoch 30/50\n",
      "33/33 [==============================] - 12s 355ms/step - loss: 0.0590 - mae: 3.6463e-06\n",
      "Epoch 31/50\n",
      "33/33 [==============================] - 12s 355ms/step - loss: 0.0615 - mae: 3.8087e-06\n",
      "Epoch 32/50\n",
      "33/33 [==============================] - 12s 355ms/step - loss: 0.0587 - mae: 3.5483e-06\n",
      "Epoch 33/50\n",
      "33/33 [==============================] - 12s 356ms/step - loss: 0.0543 - mae: 3.4276e-06\n",
      "Epoch 34/50\n",
      "33/33 [==============================] - 12s 356ms/step - loss: 0.0522 - mae: 3.3628e-06\n",
      "Epoch 35/50\n",
      "33/33 [==============================] - 12s 355ms/step - loss: 0.0425 - mae: 2.9138e-06\n",
      "Epoch 36/50\n",
      "33/33 [==============================] - 12s 355ms/step - loss: 0.0444 - mae: 2.8497e-06\n",
      "Epoch 37/50\n",
      "33/33 [==============================] - 12s 355ms/step - loss: 0.0467 - mae: 3.0126e-06\n",
      "Epoch 38/50\n",
      "33/33 [==============================] - 12s 355ms/step - loss: 0.0419 - mae: 2.7040e-06\n",
      "Epoch 39/50\n",
      "33/33 [==============================] - 12s 356ms/step - loss: 0.0543 - mae: 3.1586e-06\n",
      "Epoch 40/50\n",
      "33/33 [==============================] - 12s 355ms/step - loss: 0.0449 - mae: 2.7586e-06\n",
      "Epoch 41/50\n",
      "33/33 [==============================] - 12s 356ms/step - loss: 0.0430 - mae: 2.6841e-06\n",
      "Epoch 42/50\n",
      "33/33 [==============================] - 12s 355ms/step - loss: 0.0400 - mae: 2.4935e-06\n",
      "Epoch 43/50\n",
      "33/33 [==============================] - 12s 356ms/step - loss: 0.0421 - mae: 2.5822e-06\n",
      "Epoch 44/50\n",
      "33/33 [==============================] - 12s 356ms/step - loss: 0.0361 - mae: 2.2796e-06\n",
      "Epoch 45/50\n",
      "33/33 [==============================] - 12s 356ms/step - loss: 0.0373 - mae: 2.3787e-06\n",
      "Epoch 46/50\n",
      "33/33 [==============================] - 12s 356ms/step - loss: 0.0411 - mae: 2.5018e-06\n",
      "Epoch 47/50\n",
      "33/33 [==============================] - 12s 356ms/step - loss: 0.0340 - mae: 2.2012e-06\n",
      "Epoch 48/50\n",
      "33/33 [==============================] - 12s 356ms/step - loss: 0.0356 - mae: 2.2723e-06\n",
      "Epoch 49/50\n",
      "33/33 [==============================] - 12s 356ms/step - loss: 0.0345 - mae: 2.1991e-06\n",
      "Epoch 50/50\n",
      "33/33 [==============================] - 12s 356ms/step - loss: 0.0366 - mae: 2.2018e-06\n",
      "-----------------Model /home/sanzharrko/Рабочий стол/Atom/creation_story/models/Multi_LSTM_RNN_Model_2_books.h5 saved.-----------------\n",
      "-----------Started learning-----------\n",
      "---25/69-----------\n",
      "Number of sequences: 3054 \n",
      "\n",
      "Epoch 1/50\n",
      "33/33 [==============================] - 6s 153ms/step - loss: 7.5216 - mae: 9.1439e-05\n",
      "Epoch 2/50\n",
      "33/33 [==============================] - 6s 152ms/step - loss: 5.0675 - mae: 8.4922e-05\n",
      "Epoch 3/50\n",
      "33/33 [==============================] - 5s 152ms/step - loss: 3.7692 - mae: 7.4862e-05\n",
      "Epoch 4/50\n",
      "33/33 [==============================] - 6s 153ms/step - loss: 2.6683 - mae: 6.3491e-05\n",
      "Epoch 5/50\n",
      "33/33 [==============================] - 5s 153ms/step - loss: 1.9215 - mae: 5.3846e-05\n",
      "Epoch 6/50\n",
      "33/33 [==============================] - 6s 153ms/step - loss: 1.3475 - mae: 4.4312e-05\n",
      "Epoch 7/50\n",
      "33/33 [==============================] - 5s 153ms/step - loss: 0.8843 - mae: 3.5204e-05\n",
      "Epoch 8/50\n",
      "33/33 [==============================] - 6s 153ms/step - loss: 0.5930 - mae: 2.6970e-05\n",
      "Epoch 9/50\n",
      "33/33 [==============================] - 6s 153ms/step - loss: 0.4142 - mae: 2.1274e-05\n",
      "Epoch 10/50\n",
      "33/33 [==============================] - 5s 153ms/step - loss: 0.3007 - mae: 1.6186e-05\n",
      "Epoch 11/50\n",
      "33/33 [==============================] - 5s 153ms/step - loss: 0.2175 - mae: 1.2313e-05\n",
      "Epoch 12/50\n",
      "33/33 [==============================] - 6s 153ms/step - loss: 0.1540 - mae: 9.2596e-06\n",
      "Epoch 13/50\n",
      "33/33 [==============================] - 6s 153ms/step - loss: 0.1309 - mae: 8.1633e-06\n",
      "Epoch 14/50\n",
      "33/33 [==============================] - 5s 153ms/step - loss: 0.1074 - mae: 6.9326e-06\n",
      "Epoch 15/50\n",
      "33/33 [==============================] - 6s 153ms/step - loss: 0.0922 - mae: 5.8535e-06\n",
      "Epoch 16/50\n",
      "33/33 [==============================] - 5s 153ms/step - loss: 0.0863 - mae: 5.1828e-06\n",
      "Epoch 17/50\n",
      "33/33 [==============================] - 6s 153ms/step - loss: 0.0805 - mae: 4.9185e-06\n",
      "Epoch 18/50\n",
      "33/33 [==============================] - 5s 153ms/step - loss: 0.0759 - mae: 4.6009e-06\n",
      "Epoch 19/50\n",
      "33/33 [==============================] - 6s 153ms/step - loss: 0.0748 - mae: 4.4574e-06\n",
      "Epoch 20/50\n",
      "33/33 [==============================] - 6s 153ms/step - loss: 0.0655 - mae: 4.1075e-06\n",
      "Epoch 21/50\n",
      "33/33 [==============================] - 5s 153ms/step - loss: 0.0711 - mae: 4.0601e-06\n",
      "Epoch 22/50\n",
      "33/33 [==============================] - 6s 153ms/step - loss: 0.0464 - mae: 3.1503e-06\n",
      "Epoch 23/50\n",
      "33/33 [==============================] - 6s 153ms/step - loss: 0.0478 - mae: 2.8826e-06\n",
      "Epoch 24/50\n",
      "33/33 [==============================] - 5s 153ms/step - loss: 0.0563 - mae: 3.3749e-06\n",
      "Epoch 25/50\n",
      "33/33 [==============================] - 5s 153ms/step - loss: 0.0464 - mae: 2.7796e-06\n",
      "Epoch 26/50\n",
      "33/33 [==============================] - 5s 153ms/step - loss: 0.0502 - mae: 3.0526e-06\n",
      "Epoch 27/50\n",
      "33/33 [==============================] - 6s 153ms/step - loss: 0.0493 - mae: 2.7863e-06\n",
      "Epoch 28/50\n",
      "33/33 [==============================] - 5s 153ms/step - loss: 0.0542 - mae: 2.9965e-06\n",
      "Epoch 29/50\n",
      "33/33 [==============================] - 6s 153ms/step - loss: 0.0450 - mae: 2.7567e-06\n",
      "Epoch 30/50\n",
      "33/33 [==============================] - 6s 153ms/step - loss: 0.0382 - mae: 2.4049e-06\n",
      "Epoch 31/50\n",
      "33/33 [==============================] - 5s 153ms/step - loss: 0.0423 - mae: 2.4683e-06\n",
      "Epoch 32/50\n",
      "33/33 [==============================] - 5s 153ms/step - loss: 0.0285 - mae: 1.9355e-06\n",
      "Epoch 33/50\n",
      "33/33 [==============================] - 5s 153ms/step - loss: 0.0356 - mae: 2.1661e-06\n",
      "Epoch 34/50\n",
      "33/33 [==============================] - 6s 153ms/step - loss: 0.0376 - mae: 2.3363e-06\n",
      "Epoch 35/50\n",
      "33/33 [==============================] - 5s 153ms/step - loss: 0.0250 - mae: 1.5839e-06\n",
      "Epoch 36/50\n",
      "33/33 [==============================] - 6s 153ms/step - loss: 0.0307 - mae: 1.8575e-06\n",
      "Epoch 37/50\n",
      "33/33 [==============================] - 6s 153ms/step - loss: 0.0463 - mae: 2.2379e-06\n",
      "Epoch 38/50\n",
      "33/33 [==============================] - 6s 153ms/step - loss: 0.0259 - mae: 1.6424e-06\n",
      "Epoch 39/50\n",
      "33/33 [==============================] - 6s 153ms/step - loss: 0.0263 - mae: 1.6383e-06\n",
      "Epoch 40/50\n",
      "33/33 [==============================] - 5s 153ms/step - loss: 0.0287 - mae: 1.5776e-06\n",
      "Epoch 41/50\n",
      "33/33 [==============================] - 5s 153ms/step - loss: 0.0357 - mae: 1.7980e-06\n",
      "Epoch 42/50\n",
      "33/33 [==============================] - 6s 153ms/step - loss: 0.0324 - mae: 1.8862e-06\n",
      "Epoch 43/50\n",
      "33/33 [==============================] - 6s 153ms/step - loss: 0.0284 - mae: 1.6188e-06\n",
      "Epoch 44/50\n",
      "33/33 [==============================] - 5s 153ms/step - loss: 0.0267 - mae: 1.7374e-06\n",
      "Epoch 45/50\n",
      "33/33 [==============================] - 5s 153ms/step - loss: 0.0357 - mae: 1.8432e-06\n",
      "Epoch 46/50\n",
      "33/33 [==============================] - 5s 153ms/step - loss: 0.0224 - mae: 1.3027e-06\n",
      "Epoch 47/50\n",
      "33/33 [==============================] - 6s 153ms/step - loss: 0.0319 - mae: 1.7519e-06\n",
      "Epoch 48/50\n",
      "33/33 [==============================] - 6s 153ms/step - loss: 0.0235 - mae: 1.3959e-06\n",
      "Epoch 49/50\n",
      "33/33 [==============================] - 6s 153ms/step - loss: 0.0283 - mae: 1.4799e-06\n",
      "Epoch 50/50\n",
      "33/33 [==============================] - 5s 153ms/step - loss: 0.0197 - mae: 1.3565e-06\n",
      "-----------------Model /home/sanzharrko/Рабочий стол/Atom/creation_story/models/Multi_LSTM_RNN_Model_2_books.h5 saved.-----------------\n",
      "-----------Started learning-----------\n",
      "---26/69-----------\n",
      "Number of sequences: 4667 \n",
      "\n",
      "Epoch 1/50\n",
      "33/33 [==============================] - 7s 209ms/step - loss: 7.9226 - mae: 9.2667e-05\n",
      "Epoch 2/50\n",
      "33/33 [==============================] - 7s 209ms/step - loss: 5.4024 - mae: 8.6941e-05\n",
      "Epoch 3/50\n",
      "33/33 [==============================] - 7s 209ms/step - loss: 4.2291 - mae: 7.9565e-05\n",
      "Epoch 4/50\n",
      "33/33 [==============================] - 7s 210ms/step - loss: 3.2619 - mae: 7.1065e-05\n",
      "Epoch 5/50\n",
      "33/33 [==============================] - 7s 210ms/step - loss: 2.4337 - mae: 6.1726e-05\n",
      "Epoch 6/50\n",
      "33/33 [==============================] - 7s 209ms/step - loss: 1.7605 - mae: 5.3050e-05\n",
      "Epoch 7/50\n",
      "33/33 [==============================] - 7s 209ms/step - loss: 1.2869 - mae: 4.4650e-05\n",
      "Epoch 8/50\n",
      "33/33 [==============================] - 7s 210ms/step - loss: 0.8538 - mae: 3.5383e-05\n",
      "Epoch 9/50\n",
      "33/33 [==============================] - 7s 209ms/step - loss: 0.6328 - mae: 2.8308e-05\n",
      "Epoch 10/50\n",
      "33/33 [==============================] - 7s 209ms/step - loss: 0.4312 - mae: 2.1511e-05\n",
      "Epoch 11/50\n",
      "33/33 [==============================] - 7s 210ms/step - loss: 0.3162 - mae: 1.7134e-05\n",
      "Epoch 12/50\n",
      "33/33 [==============================] - 7s 210ms/step - loss: 0.2457 - mae: 1.3879e-05\n",
      "Epoch 13/50\n",
      "33/33 [==============================] - 7s 210ms/step - loss: 0.1892 - mae: 1.1454e-05\n",
      "Epoch 14/50\n",
      "33/33 [==============================] - 7s 210ms/step - loss: 0.1741 - mae: 1.0305e-05\n",
      "Epoch 15/50\n",
      "33/33 [==============================] - 7s 210ms/step - loss: 0.1358 - mae: 8.1623e-06\n",
      "Epoch 16/50\n",
      "33/33 [==============================] - 7s 210ms/step - loss: 0.1467 - mae: 8.2687e-06\n",
      "Epoch 17/50\n",
      "33/33 [==============================] - 7s 210ms/step - loss: 0.1316 - mae: 7.3559e-06\n",
      "Epoch 18/50\n",
      "33/33 [==============================] - 7s 210ms/step - loss: 0.0958 - mae: 6.1281e-06\n",
      "Epoch 19/50\n",
      "33/33 [==============================] - 7s 211ms/step - loss: 0.0824 - mae: 5.2725e-06\n",
      "Epoch 20/50\n",
      "33/33 [==============================] - 7s 210ms/step - loss: 0.0786 - mae: 4.9793e-06\n",
      "Epoch 21/50\n",
      "33/33 [==============================] - 7s 209ms/step - loss: 0.0762 - mae: 4.6646e-06\n",
      "Epoch 22/50\n",
      "33/33 [==============================] - 7s 210ms/step - loss: 0.0659 - mae: 4.1715e-06\n",
      "Epoch 23/50\n",
      "33/33 [==============================] - 7s 210ms/step - loss: 0.0666 - mae: 4.2185e-06\n",
      "Epoch 24/50\n",
      "33/33 [==============================] - 7s 210ms/step - loss: 0.0639 - mae: 3.9481e-06\n",
      "Epoch 25/50\n",
      "33/33 [==============================] - 7s 210ms/step - loss: 0.0575 - mae: 3.4209e-06\n",
      "Epoch 26/50\n",
      "33/33 [==============================] - 7s 210ms/step - loss: 0.0619 - mae: 3.7551e-06\n",
      "Epoch 27/50\n",
      "33/33 [==============================] - 7s 210ms/step - loss: 0.0605 - mae: 3.6570e-06\n",
      "Epoch 28/50\n",
      "33/33 [==============================] - 7s 210ms/step - loss: 0.0514 - mae: 3.2463e-06\n",
      "Epoch 29/50\n",
      "33/33 [==============================] - 7s 210ms/step - loss: 0.0547 - mae: 3.3434e-06\n",
      "Epoch 30/50\n",
      "33/33 [==============================] - 7s 210ms/step - loss: 0.0566 - mae: 3.3515e-06\n",
      "Epoch 31/50\n",
      "33/33 [==============================] - 7s 210ms/step - loss: 0.0545 - mae: 3.0341e-06\n",
      "Epoch 32/50\n",
      "33/33 [==============================] - 7s 210ms/step - loss: 0.0457 - mae: 2.7537e-06\n",
      "Epoch 33/50\n",
      "33/33 [==============================] - 7s 210ms/step - loss: 0.0478 - mae: 2.8820e-06\n",
      "Epoch 34/50\n",
      "33/33 [==============================] - 7s 210ms/step - loss: 0.0461 - mae: 2.7230e-06\n",
      "Epoch 35/50\n",
      "33/33 [==============================] - 7s 210ms/step - loss: 0.0419 - mae: 2.5023e-06\n",
      "Epoch 36/50\n",
      "33/33 [==============================] - 7s 210ms/step - loss: 0.0526 - mae: 2.9527e-06\n",
      "Epoch 37/50\n",
      "33/33 [==============================] - 7s 210ms/step - loss: 0.0365 - mae: 2.3119e-06\n",
      "Epoch 38/50\n",
      "33/33 [==============================] - 7s 210ms/step - loss: 0.0363 - mae: 2.3243e-06\n",
      "Epoch 39/50\n",
      "33/33 [==============================] - 7s 210ms/step - loss: 0.0467 - mae: 2.5234e-06\n",
      "Epoch 40/50\n",
      "33/33 [==============================] - 7s 210ms/step - loss: 0.0418 - mae: 2.4112e-06\n",
      "Epoch 41/50\n",
      "33/33 [==============================] - 7s 210ms/step - loss: 0.0351 - mae: 1.9984e-06\n",
      "Epoch 42/50\n",
      "33/33 [==============================] - 7s 210ms/step - loss: 0.0433 - mae: 2.3953e-06\n",
      "Epoch 43/50\n",
      "33/33 [==============================] - 7s 210ms/step - loss: 0.0416 - mae: 2.2716e-06\n",
      "Epoch 44/50\n",
      "33/33 [==============================] - 7s 210ms/step - loss: 0.0267 - mae: 1.7070e-06\n",
      "Epoch 45/50\n",
      "33/33 [==============================] - 7s 210ms/step - loss: 0.0327 - mae: 1.8531e-06\n",
      "Epoch 46/50\n",
      "33/33 [==============================] - 7s 210ms/step - loss: 0.0350 - mae: 1.9669e-06\n",
      "Epoch 47/50\n",
      "33/33 [==============================] - 7s 210ms/step - loss: 0.0339 - mae: 2.0656e-06\n",
      "Epoch 48/50\n",
      "33/33 [==============================] - 7s 210ms/step - loss: 0.0346 - mae: 1.9975e-06\n",
      "Epoch 49/50\n",
      "33/33 [==============================] - 7s 210ms/step - loss: 0.0343 - mae: 1.8803e-06\n",
      "Epoch 50/50\n",
      "33/33 [==============================] - 7s 210ms/step - loss: 0.0315 - mae: 1.8529e-06\n",
      "-----------------Model /home/sanzharrko/Рабочий стол/Atom/creation_story/models/Multi_LSTM_RNN_Model_2_books.h5 saved.-----------------\n",
      "-----------Started learning-----------\n",
      "---27/69-----------\n",
      "Number of sequences: 10637 \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-14 17:42:16.332703: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 840237904 exceeds 10% of free system memory.\n",
      "2022-05-14 17:42:16.775616: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 840237904 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "33/33 [==============================] - 14s 410ms/step - loss: 7.9170 - mae: 9.4804e-05\n",
      "Epoch 2/50\n",
      "33/33 [==============================] - 14s 411ms/step - loss: 5.8234 - mae: 9.2101e-05\n",
      "Epoch 3/50\n",
      "33/33 [==============================] - 14s 411ms/step - loss: 5.0102 - mae: 8.8161e-05\n",
      "Epoch 4/50\n",
      "33/33 [==============================] - 14s 411ms/step - loss: 4.2802 - mae: 8.3135e-05\n",
      "Epoch 5/50\n",
      "33/33 [==============================] - 14s 411ms/step - loss: 3.6050 - mae: 7.7569e-05\n",
      "Epoch 6/50\n",
      "33/33 [==============================] - 14s 404ms/step - loss: 2.9852 - mae: 7.1211e-05\n",
      "Epoch 7/50\n",
      "33/33 [==============================] - 14s 405ms/step - loss: 2.3902 - mae: 6.4428e-05\n",
      "Epoch 8/50\n",
      "33/33 [==============================] - 14s 404ms/step - loss: 1.9058 - mae: 5.7756e-05\n",
      "Epoch 9/50\n",
      "33/33 [==============================] - 14s 405ms/step - loss: 1.4707 - mae: 5.0030e-05\n",
      "Epoch 10/50\n",
      "33/33 [==============================] - 14s 404ms/step - loss: 1.0990 - mae: 4.2504e-05\n",
      "Epoch 11/50\n",
      "33/33 [==============================] - 14s 404ms/step - loss: 0.8334 - mae: 3.5139e-05\n",
      "Epoch 12/50\n",
      "33/33 [==============================] - 14s 403ms/step - loss: 0.6350 - mae: 2.9197e-05\n",
      "Epoch 13/50\n",
      "33/33 [==============================] - 14s 404ms/step - loss: 0.4821 - mae: 2.3737e-05\n",
      "Epoch 14/50\n",
      "33/33 [==============================] - 14s 404ms/step - loss: 0.3976 - mae: 2.0444e-05\n",
      "Epoch 15/50\n",
      "33/33 [==============================] - 14s 403ms/step - loss: 0.3071 - mae: 1.6958e-05\n",
      "Epoch 16/50\n",
      "33/33 [==============================] - 14s 403ms/step - loss: 0.2719 - mae: 1.5129e-05\n",
      "Epoch 17/50\n",
      "33/33 [==============================] - 14s 404ms/step - loss: 0.2280 - mae: 1.2981e-05\n",
      "Epoch 18/50\n",
      "33/33 [==============================] - 14s 405ms/step - loss: 0.1750 - mae: 1.0636e-05\n",
      "Epoch 19/50\n",
      "33/33 [==============================] - 14s 404ms/step - loss: 0.1685 - mae: 1.0157e-05\n",
      "Epoch 20/50\n",
      "33/33 [==============================] - 14s 403ms/step - loss: 0.1502 - mae: 9.1232e-06\n",
      "Epoch 21/50\n",
      "33/33 [==============================] - 14s 404ms/step - loss: 0.1399 - mae: 8.4316e-06\n",
      "Epoch 22/50\n",
      "33/33 [==============================] - 14s 404ms/step - loss: 0.1383 - mae: 8.2310e-06\n",
      "Epoch 23/50\n",
      "33/33 [==============================] - 14s 403ms/step - loss: 0.1149 - mae: 7.1040e-06\n",
      "Epoch 24/50\n",
      "33/33 [==============================] - 14s 403ms/step - loss: 0.1047 - mae: 6.4860e-06\n",
      "Epoch 25/50\n",
      "33/33 [==============================] - 14s 404ms/step - loss: 0.0977 - mae: 5.9854e-06\n",
      "Epoch 26/50\n",
      "33/33 [==============================] - 14s 404ms/step - loss: 0.0936 - mae: 5.7472e-06\n",
      "Epoch 27/50\n",
      "33/33 [==============================] - 14s 403ms/step - loss: 0.0915 - mae: 5.6598e-06\n",
      "Epoch 28/50\n",
      "33/33 [==============================] - 14s 404ms/step - loss: 0.0926 - mae: 5.4994e-06\n",
      "Epoch 29/50\n",
      "33/33 [==============================] - 14s 404ms/step - loss: 0.0866 - mae: 5.2631e-06\n",
      "Epoch 30/50\n",
      "33/33 [==============================] - 14s 404ms/step - loss: 0.0872 - mae: 5.1623e-06\n",
      "Epoch 31/50\n",
      "33/33 [==============================] - 14s 404ms/step - loss: 0.0783 - mae: 4.7342e-06\n",
      "Epoch 32/50\n",
      "33/33 [==============================] - 14s 404ms/step - loss: 0.0817 - mae: 4.9334e-06\n",
      "Epoch 33/50\n",
      "33/33 [==============================] - 14s 404ms/step - loss: 0.0739 - mae: 4.4344e-06\n",
      "Epoch 34/50\n",
      "33/33 [==============================] - 14s 403ms/step - loss: 0.0681 - mae: 4.1380e-06\n",
      "Epoch 35/50\n",
      "33/33 [==============================] - 14s 403ms/step - loss: 0.0689 - mae: 4.2780e-06\n",
      "Epoch 36/50\n",
      "33/33 [==============================] - 14s 403ms/step - loss: 0.0632 - mae: 3.7517e-06\n",
      "Epoch 37/50\n",
      "33/33 [==============================] - 14s 402ms/step - loss: 0.0663 - mae: 3.8267e-06\n",
      "Epoch 38/50\n",
      "33/33 [==============================] - 14s 403ms/step - loss: 0.0592 - mae: 3.5320e-06\n",
      "Epoch 39/50\n",
      "33/33 [==============================] - 14s 403ms/step - loss: 0.0602 - mae: 3.5567e-06\n",
      "Epoch 40/50\n",
      "33/33 [==============================] - 14s 403ms/step - loss: 0.0599 - mae: 3.5813e-06\n",
      "Epoch 41/50\n",
      "33/33 [==============================] - 14s 404ms/step - loss: 0.0569 - mae: 3.5303e-06\n",
      "Epoch 42/50\n",
      "33/33 [==============================] - 14s 403ms/step - loss: 0.0624 - mae: 3.6883e-06\n",
      "Epoch 43/50\n",
      "33/33 [==============================] - 14s 402ms/step - loss: 0.0555 - mae: 3.2584e-06\n",
      "Epoch 44/50\n",
      "33/33 [==============================] - 14s 403ms/step - loss: 0.0565 - mae: 3.3833e-06\n",
      "Epoch 45/50\n",
      "33/33 [==============================] - 14s 402ms/step - loss: 0.0575 - mae: 3.2800e-06\n",
      "Epoch 46/50\n",
      "33/33 [==============================] - 14s 403ms/step - loss: 0.0533 - mae: 3.0469e-06\n",
      "Epoch 47/50\n",
      "33/33 [==============================] - 14s 404ms/step - loss: 0.0578 - mae: 3.2836e-06\n",
      "Epoch 48/50\n",
      "33/33 [==============================] - 14s 403ms/step - loss: 0.0519 - mae: 3.0560e-06\n",
      "Epoch 49/50\n",
      "33/33 [==============================] - 14s 403ms/step - loss: 0.0501 - mae: 2.9325e-06\n",
      "Epoch 50/50\n",
      "33/33 [==============================] - 14s 403ms/step - loss: 0.0509 - mae: 2.8154e-06\n",
      "-----------------Model /home/sanzharrko/Рабочий стол/Atom/creation_story/models/Multi_LSTM_RNN_Model_2_books.h5 saved.-----------------\n",
      "-----------Started learning-----------\n",
      "---28/69-----------\n",
      "Number of sequences: 4899 \n",
      "\n",
      "Epoch 1/50\n",
      "33/33 [==============================] - 7s 197ms/step - loss: 8.3267 - mae: 9.6341e-05\n",
      "Epoch 2/50\n",
      "33/33 [==============================] - 7s 197ms/step - loss: 5.7689 - mae: 9.1947e-05\n",
      "Epoch 3/50\n",
      "33/33 [==============================] - 7s 197ms/step - loss: 4.5957 - mae: 8.5113e-05\n",
      "Epoch 4/50\n",
      "33/33 [==============================] - 7s 197ms/step - loss: 3.5960 - mae: 7.7633e-05\n",
      "Epoch 5/50\n",
      "33/33 [==============================] - 7s 198ms/step - loss: 2.7624 - mae: 6.8672e-05\n",
      "Epoch 6/50\n",
      "33/33 [==============================] - 7s 198ms/step - loss: 2.0848 - mae: 5.9720e-05\n",
      "Epoch 7/50\n",
      "33/33 [==============================] - 7s 197ms/step - loss: 1.5208 - mae: 5.1097e-05\n",
      "Epoch 8/50\n",
      "33/33 [==============================] - 7s 198ms/step - loss: 1.0893 - mae: 4.1720e-05\n",
      "Epoch 9/50\n",
      "33/33 [==============================] - 7s 198ms/step - loss: 0.7872 - mae: 3.4144e-05\n",
      "Epoch 10/50\n",
      "33/33 [==============================] - 7s 198ms/step - loss: 0.5682 - mae: 2.6993e-05\n",
      "Epoch 11/50\n",
      "33/33 [==============================] - 7s 198ms/step - loss: 0.4006 - mae: 2.1049e-05\n",
      "Epoch 12/50\n",
      "33/33 [==============================] - 7s 197ms/step - loss: 0.3299 - mae: 1.7563e-05\n",
      "Epoch 13/50\n",
      "33/33 [==============================] - 7s 198ms/step - loss: 0.2531 - mae: 1.4315e-05\n",
      "Epoch 14/50\n",
      "33/33 [==============================] - 7s 197ms/step - loss: 0.2180 - mae: 1.2280e-05\n",
      "Epoch 15/50\n",
      "33/33 [==============================] - 7s 198ms/step - loss: 0.1830 - mae: 1.0602e-05\n",
      "Epoch 16/50\n",
      "33/33 [==============================] - 7s 198ms/step - loss: 0.1451 - mae: 8.9179e-06\n",
      "Epoch 17/50\n",
      "33/33 [==============================] - 7s 197ms/step - loss: 0.1297 - mae: 8.0153e-06\n",
      "Epoch 18/50\n",
      "33/33 [==============================] - 7s 198ms/step - loss: 0.1438 - mae: 7.8736e-06\n",
      "Epoch 19/50\n",
      "33/33 [==============================] - 7s 198ms/step - loss: 0.1301 - mae: 7.3933e-06\n",
      "Epoch 20/50\n",
      "33/33 [==============================] - 7s 198ms/step - loss: 0.1068 - mae: 6.2544e-06\n",
      "Epoch 21/50\n",
      "33/33 [==============================] - 7s 197ms/step - loss: 0.1031 - mae: 6.3075e-06\n",
      "Epoch 22/50\n",
      "33/33 [==============================] - 7s 197ms/step - loss: 0.0956 - mae: 5.7283e-06\n",
      "Epoch 23/50\n",
      "33/33 [==============================] - 7s 198ms/step - loss: 0.0952 - mae: 5.5605e-06\n",
      "Epoch 24/50\n",
      "33/33 [==============================] - 7s 198ms/step - loss: 0.0800 - mae: 4.7999e-06\n",
      "Epoch 25/50\n",
      "33/33 [==============================] - 7s 198ms/step - loss: 0.0796 - mae: 4.6722e-06\n",
      "Epoch 26/50\n",
      "33/33 [==============================] - 7s 198ms/step - loss: 0.0822 - mae: 4.8133e-06\n",
      "Epoch 27/50\n",
      "33/33 [==============================] - 7s 198ms/step - loss: 0.0766 - mae: 4.1663e-06\n",
      "Epoch 28/50\n",
      "33/33 [==============================] - 7s 198ms/step - loss: 0.0612 - mae: 3.7252e-06\n",
      "Epoch 29/50\n",
      "33/33 [==============================] - 7s 198ms/step - loss: 0.0709 - mae: 4.0637e-06\n",
      "Epoch 30/50\n",
      "33/33 [==============================] - 7s 198ms/step - loss: 0.0862 - mae: 4.4765e-06\n",
      "Epoch 31/50\n",
      "33/33 [==============================] - 7s 198ms/step - loss: 0.0611 - mae: 3.6641e-06\n",
      "Epoch 32/50\n",
      "33/33 [==============================] - 7s 197ms/step - loss: 0.0674 - mae: 3.7776e-06\n",
      "Epoch 33/50\n",
      "33/33 [==============================] - 7s 197ms/step - loss: 0.0537 - mae: 3.2258e-06\n",
      "Epoch 34/50\n",
      "33/33 [==============================] - 7s 197ms/step - loss: 0.0628 - mae: 3.3522e-06\n",
      "Epoch 35/50\n",
      "33/33 [==============================] - 7s 197ms/step - loss: 0.0505 - mae: 3.2071e-06\n",
      "Epoch 36/50\n",
      "33/33 [==============================] - 7s 198ms/step - loss: 0.0562 - mae: 3.1494e-06\n",
      "Epoch 37/50\n",
      "33/33 [==============================] - 7s 197ms/step - loss: 0.0534 - mae: 3.1636e-06\n",
      "Epoch 38/50\n",
      "33/33 [==============================] - 7s 198ms/step - loss: 0.0539 - mae: 3.0722e-06\n",
      "Epoch 39/50\n",
      "33/33 [==============================] - 7s 197ms/step - loss: 0.0440 - mae: 2.7596e-06\n",
      "Epoch 40/50\n",
      "33/33 [==============================] - 7s 198ms/step - loss: 0.0431 - mae: 2.5666e-06\n",
      "Epoch 41/50\n",
      "33/33 [==============================] - 7s 197ms/step - loss: 0.0486 - mae: 2.6668e-06\n",
      "Epoch 42/50\n",
      "33/33 [==============================] - 7s 198ms/step - loss: 0.0484 - mae: 2.7767e-06\n",
      "Epoch 43/50\n",
      "33/33 [==============================] - 7s 198ms/step - loss: 0.0453 - mae: 2.7589e-06\n",
      "Epoch 44/50\n",
      "33/33 [==============================] - 7s 198ms/step - loss: 0.0352 - mae: 2.1636e-06\n",
      "Epoch 45/50\n",
      "33/33 [==============================] - 7s 198ms/step - loss: 0.0457 - mae: 2.5371e-06\n",
      "Epoch 46/50\n",
      "33/33 [==============================] - 7s 197ms/step - loss: 0.0344 - mae: 2.1001e-06\n",
      "Epoch 47/50\n",
      "33/33 [==============================] - 7s 197ms/step - loss: 0.0444 - mae: 2.4170e-06\n",
      "Epoch 48/50\n",
      "33/33 [==============================] - 7s 198ms/step - loss: 0.0509 - mae: 2.7178e-06\n",
      "Epoch 49/50\n",
      "33/33 [==============================] - 7s 198ms/step - loss: 0.0354 - mae: 2.2295e-06\n",
      "Epoch 50/50\n",
      "33/33 [==============================] - 7s 197ms/step - loss: 0.0414 - mae: 2.4169e-06\n",
      "-----------------Model /home/sanzharrko/Рабочий стол/Atom/creation_story/models/Multi_LSTM_RNN_Model_2_books.h5 saved.-----------------\n",
      "-----------Started learning-----------\n",
      "---29/69-----------\n",
      "Number of sequences: 5372 \n",
      "\n",
      "Epoch 1/50\n",
      "33/33 [==============================] - 7s 198ms/step - loss: 7.9402 - mae: 9.1791e-05\n",
      "Epoch 2/50\n",
      "33/33 [==============================] - 7s 199ms/step - loss: 5.5278 - mae: 8.7209e-05\n",
      "Epoch 3/50\n",
      "33/33 [==============================] - 7s 198ms/step - loss: 4.3645 - mae: 8.0426e-05\n",
      "Epoch 4/50\n",
      "33/33 [==============================] - 7s 198ms/step - loss: 3.4380 - mae: 7.2907e-05\n",
      "Epoch 5/50\n",
      "33/33 [==============================] - 7s 199ms/step - loss: 2.6357 - mae: 6.4399e-05\n",
      "Epoch 6/50\n",
      "33/33 [==============================] - 7s 198ms/step - loss: 2.0000 - mae: 5.6683e-05\n",
      "Epoch 7/50\n",
      "33/33 [==============================] - 7s 199ms/step - loss: 1.4940 - mae: 4.8101e-05\n",
      "Epoch 8/50\n",
      "33/33 [==============================] - 7s 199ms/step - loss: 1.1021 - mae: 4.0691e-05\n",
      "Epoch 9/50\n",
      "33/33 [==============================] - 7s 198ms/step - loss: 0.7852 - mae: 3.2511e-05\n",
      "Epoch 10/50\n",
      "33/33 [==============================] - 7s 198ms/step - loss: 0.5755 - mae: 2.6704e-05\n",
      "Epoch 11/50\n",
      "33/33 [==============================] - 7s 199ms/step - loss: 0.4076 - mae: 2.1032e-05\n",
      "Epoch 12/50\n",
      "33/33 [==============================] - 7s 198ms/step - loss: 0.3267 - mae: 1.7432e-05\n",
      "Epoch 13/50\n",
      "33/33 [==============================] - 7s 199ms/step - loss: 0.2665 - mae: 1.4617e-05\n",
      "Epoch 14/50\n",
      "33/33 [==============================] - 7s 199ms/step - loss: 0.2262 - mae: 1.2556e-05\n",
      "Epoch 15/50\n",
      "33/33 [==============================] - 7s 199ms/step - loss: 0.1775 - mae: 1.0119e-05\n",
      "Epoch 16/50\n",
      "33/33 [==============================] - 7s 198ms/step - loss: 0.1385 - mae: 8.7168e-06\n",
      "Epoch 17/50\n",
      "33/33 [==============================] - 7s 199ms/step - loss: 0.1484 - mae: 8.5979e-06\n",
      "Epoch 18/50\n",
      "33/33 [==============================] - 7s 199ms/step - loss: 0.1242 - mae: 7.5949e-06\n",
      "Epoch 19/50\n",
      "33/33 [==============================] - 7s 199ms/step - loss: 0.1245 - mae: 7.1040e-06\n",
      "Epoch 20/50\n",
      "33/33 [==============================] - 7s 198ms/step - loss: 0.1123 - mae: 6.5097e-06\n",
      "Epoch 21/50\n",
      "33/33 [==============================] - 7s 199ms/step - loss: 0.0906 - mae: 5.5842e-06\n",
      "Epoch 22/50\n",
      "33/33 [==============================] - 7s 199ms/step - loss: 0.0971 - mae: 5.7925e-06\n",
      "Epoch 23/50\n",
      "33/33 [==============================] - 7s 198ms/step - loss: 0.0983 - mae: 5.5302e-06\n",
      "Epoch 24/50\n",
      "33/33 [==============================] - 7s 199ms/step - loss: 0.0789 - mae: 4.7304e-06\n",
      "Epoch 25/50\n",
      "33/33 [==============================] - 7s 199ms/step - loss: 0.0790 - mae: 4.6029e-06\n",
      "Epoch 26/50\n",
      "33/33 [==============================] - 7s 199ms/step - loss: 0.0721 - mae: 4.3393e-06\n",
      "Epoch 27/50\n",
      "33/33 [==============================] - 7s 199ms/step - loss: 0.0660 - mae: 3.9902e-06\n",
      "Epoch 28/50\n",
      "33/33 [==============================] - 7s 199ms/step - loss: 0.0660 - mae: 3.9284e-06\n",
      "Epoch 29/50\n",
      "33/33 [==============================] - 7s 199ms/step - loss: 0.0518 - mae: 3.4035e-06\n",
      "Epoch 30/50\n",
      "33/33 [==============================] - 7s 199ms/step - loss: 0.0666 - mae: 3.7715e-06\n",
      "Epoch 31/50\n",
      "33/33 [==============================] - 7s 199ms/step - loss: 0.0599 - mae: 3.4835e-06\n",
      "Epoch 32/50\n",
      "33/33 [==============================] - 7s 199ms/step - loss: 0.0530 - mae: 3.1683e-06\n",
      "Epoch 33/50\n",
      "33/33 [==============================] - 7s 199ms/step - loss: 0.0539 - mae: 3.2695e-06\n",
      "Epoch 34/50\n",
      "33/33 [==============================] - 7s 199ms/step - loss: 0.0599 - mae: 3.3476e-06\n",
      "Epoch 35/50\n",
      "33/33 [==============================] - 7s 199ms/step - loss: 0.0534 - mae: 2.9893e-06\n",
      "Epoch 36/50\n",
      "33/33 [==============================] - 7s 199ms/step - loss: 0.0535 - mae: 3.0162e-06\n",
      "Epoch 37/50\n",
      "33/33 [==============================] - 7s 199ms/step - loss: 0.0442 - mae: 2.7176e-06\n",
      "Epoch 38/50\n",
      "33/33 [==============================] - 7s 199ms/step - loss: 0.0472 - mae: 2.8099e-06\n",
      "Epoch 39/50\n",
      "33/33 [==============================] - 7s 199ms/step - loss: 0.0490 - mae: 2.5789e-06\n",
      "Epoch 40/50\n",
      "33/33 [==============================] - 7s 199ms/step - loss: 0.0434 - mae: 2.6021e-06\n",
      "Epoch 41/50\n",
      "33/33 [==============================] - 7s 199ms/step - loss: 0.0493 - mae: 2.7076e-06\n",
      "Epoch 42/50\n",
      "33/33 [==============================] - 7s 199ms/step - loss: 0.0507 - mae: 2.8553e-06\n",
      "Epoch 43/50\n",
      "33/33 [==============================] - 7s 199ms/step - loss: 0.0471 - mae: 2.6907e-06\n",
      "Epoch 44/50\n",
      "33/33 [==============================] - 7s 198ms/step - loss: 0.0485 - mae: 2.7431e-06\n",
      "Epoch 45/50\n",
      "33/33 [==============================] - 7s 199ms/step - loss: 0.0372 - mae: 2.2813e-06\n",
      "Epoch 46/50\n",
      "33/33 [==============================] - 7s 199ms/step - loss: 0.0413 - mae: 2.4075e-06\n",
      "Epoch 47/50\n",
      "33/33 [==============================] - 7s 199ms/step - loss: 0.0443 - mae: 2.3495e-06\n",
      "Epoch 48/50\n",
      "33/33 [==============================] - 7s 199ms/step - loss: 0.0367 - mae: 2.1623e-06\n",
      "Epoch 49/50\n",
      "33/33 [==============================] - 7s 199ms/step - loss: 0.0389 - mae: 2.1098e-06\n",
      "Epoch 50/50\n",
      "33/33 [==============================] - 7s 199ms/step - loss: 0.0294 - mae: 1.9227e-06\n",
      "-----------------Model /home/sanzharrko/Рабочий стол/Atom/creation_story/models/Multi_LSTM_RNN_Model_2_books.h5 saved.-----------------\n",
      "-----------Started learning-----------\n",
      "---30/69-----------\n",
      "Number of sequences: 7377 \n",
      "\n",
      "Epoch 1/50\n",
      "33/33 [==============================] - 10s 280ms/step - loss: 7.9401 - mae: 9.3762e-05\n",
      "Epoch 2/50\n",
      "33/33 [==============================] - 10s 281ms/step - loss: 5.7432 - mae: 9.0205e-05\n",
      "Epoch 3/50\n",
      "33/33 [==============================] - 10s 281ms/step - loss: 4.7644 - mae: 8.5344e-05\n",
      "Epoch 4/50\n",
      "33/33 [==============================] - 10s 281ms/step - loss: 3.9360 - mae: 7.9282e-05\n",
      "Epoch 5/50\n",
      "33/33 [==============================] - 10s 280ms/step - loss: 3.1617 - mae: 7.2154e-05\n",
      "Epoch 6/50\n",
      "33/33 [==============================] - 10s 281ms/step - loss: 2.5133 - mae: 6.5025e-05\n",
      "Epoch 7/50\n",
      "33/33 [==============================] - 10s 280ms/step - loss: 1.9557 - mae: 5.7108e-05\n",
      "Epoch 8/50\n",
      "33/33 [==============================] - 10s 281ms/step - loss: 1.4800 - mae: 4.9076e-05\n",
      "Epoch 9/50\n",
      "33/33 [==============================] - 10s 281ms/step - loss: 1.0931 - mae: 4.1314e-05\n",
      "Epoch 10/50\n",
      "33/33 [==============================] - 10s 280ms/step - loss: 0.8357 - mae: 3.4649e-05\n",
      "Epoch 11/50\n",
      "33/33 [==============================] - 10s 281ms/step - loss: 0.6251 - mae: 2.8423e-05\n",
      "Epoch 12/50\n",
      "33/33 [==============================] - 10s 281ms/step - loss: 0.4723 - mae: 2.3402e-05\n",
      "Epoch 13/50\n",
      "33/33 [==============================] - 10s 281ms/step - loss: 0.3701 - mae: 1.9191e-05\n",
      "Epoch 14/50\n",
      "33/33 [==============================] - 10s 280ms/step - loss: 0.2881 - mae: 1.5831e-05\n",
      "Epoch 15/50\n",
      "33/33 [==============================] - 10s 281ms/step - loss: 0.2571 - mae: 1.4279e-05\n",
      "Epoch 16/50\n",
      "33/33 [==============================] - 10s 281ms/step - loss: 0.2052 - mae: 1.1981e-05\n",
      "Epoch 17/50\n",
      "33/33 [==============================] - 10s 281ms/step - loss: 0.1939 - mae: 1.0951e-05\n",
      "Epoch 18/50\n",
      "33/33 [==============================] - 10s 281ms/step - loss: 0.1651 - mae: 9.6523e-06\n",
      "Epoch 19/50\n",
      "33/33 [==============================] - 10s 281ms/step - loss: 0.1534 - mae: 8.9653e-06\n",
      "Epoch 20/50\n",
      "33/33 [==============================] - 10s 282ms/step - loss: 0.1363 - mae: 7.9808e-06\n",
      "Epoch 21/50\n",
      "33/33 [==============================] - 10s 281ms/step - loss: 0.1270 - mae: 7.4771e-06\n",
      "Epoch 22/50\n",
      "33/33 [==============================] - 10s 281ms/step - loss: 0.1204 - mae: 7.0508e-06\n",
      "Epoch 23/50\n",
      "33/33 [==============================] - 10s 280ms/step - loss: 0.1081 - mae: 6.4162e-06\n",
      "Epoch 24/50\n",
      "33/33 [==============================] - 10s 281ms/step - loss: 0.1091 - mae: 6.2271e-06\n",
      "Epoch 25/50\n",
      "33/33 [==============================] - 10s 282ms/step - loss: 0.1061 - mae: 6.1105e-06\n",
      "Epoch 26/50\n",
      "33/33 [==============================] - 10s 280ms/step - loss: 0.0845 - mae: 4.9756e-06\n",
      "Epoch 27/50\n",
      "33/33 [==============================] - 10s 281ms/step - loss: 0.0925 - mae: 5.3049e-06\n",
      "Epoch 28/50\n",
      "33/33 [==============================] - 10s 282ms/step - loss: 0.0858 - mae: 5.1132e-06\n",
      "Epoch 29/50\n",
      "33/33 [==============================] - 10s 281ms/step - loss: 0.0780 - mae: 4.7681e-06\n",
      "Epoch 30/50\n",
      "33/33 [==============================] - 10s 281ms/step - loss: 0.0724 - mae: 4.3263e-06\n",
      "Epoch 31/50\n",
      "33/33 [==============================] - 10s 281ms/step - loss: 0.0727 - mae: 4.3034e-06\n",
      "Epoch 32/50\n",
      "33/33 [==============================] - 10s 281ms/step - loss: 0.0756 - mae: 4.1480e-06\n",
      "Epoch 33/50\n",
      "33/33 [==============================] - 10s 281ms/step - loss: 0.0661 - mae: 3.9985e-06\n",
      "Epoch 34/50\n",
      "33/33 [==============================] - 10s 282ms/step - loss: 0.0762 - mae: 4.2861e-06\n",
      "Epoch 35/50\n",
      "33/33 [==============================] - 10s 281ms/step - loss: 0.0639 - mae: 3.8516e-06\n",
      "Epoch 36/50\n",
      "33/33 [==============================] - 10s 281ms/step - loss: 0.0710 - mae: 3.8779e-06\n",
      "Epoch 37/50\n",
      "33/33 [==============================] - 10s 282ms/step - loss: 0.0599 - mae: 3.4517e-06\n",
      "Epoch 38/50\n",
      "33/33 [==============================] - 10s 282ms/step - loss: 0.0567 - mae: 3.4772e-06\n",
      "Epoch 39/50\n",
      "33/33 [==============================] - 10s 281ms/step - loss: 0.0608 - mae: 3.4657e-06\n",
      "Epoch 40/50\n",
      "33/33 [==============================] - 10s 281ms/step - loss: 0.0566 - mae: 3.4252e-06\n",
      "Epoch 41/50\n",
      "33/33 [==============================] - 10s 281ms/step - loss: 0.0587 - mae: 3.4259e-06\n",
      "Epoch 42/50\n",
      "33/33 [==============================] - 10s 281ms/step - loss: 0.0580 - mae: 3.1825e-06\n",
      "Epoch 43/50\n",
      "33/33 [==============================] - 10s 281ms/step - loss: 0.0521 - mae: 2.9393e-06\n",
      "Epoch 44/50\n",
      "33/33 [==============================] - 10s 281ms/step - loss: 0.0510 - mae: 2.9226e-06\n",
      "Epoch 45/50\n",
      "33/33 [==============================] - 10s 281ms/step - loss: 0.0544 - mae: 3.0245e-06\n",
      "Epoch 46/50\n",
      "33/33 [==============================] - 10s 281ms/step - loss: 0.0437 - mae: 2.7305e-06\n",
      "Epoch 47/50\n",
      "33/33 [==============================] - 10s 281ms/step - loss: 0.0455 - mae: 2.7211e-06\n",
      "Epoch 48/50\n",
      "33/33 [==============================] - 10s 282ms/step - loss: 0.0491 - mae: 2.8885e-06\n",
      "Epoch 49/50\n",
      "33/33 [==============================] - 10s 281ms/step - loss: 0.0458 - mae: 2.6903e-06\n",
      "Epoch 50/50\n",
      "33/33 [==============================] - 10s 281ms/step - loss: 0.0407 - mae: 2.3078e-06\n",
      "-----------------Model /home/sanzharrko/Рабочий стол/Atom/creation_story/models/Multi_LSTM_RNN_Model_2_books.h5 saved.-----------------\n",
      "-----------Started learning-----------\n",
      "---31/69-----------\n",
      "Number of sequences: 6662 \n",
      "\n",
      "Epoch 1/50\n",
      "33/33 [==============================] - 8s 244ms/step - loss: 8.3818 - mae: 9.2819e-05\n",
      "Epoch 2/50\n",
      "33/33 [==============================] - 8s 243ms/step - loss: 5.8083 - mae: 8.8960e-05\n",
      "Epoch 3/50\n",
      "33/33 [==============================] - 8s 243ms/step - loss: 4.6104 - mae: 8.2785e-05\n",
      "Epoch 4/50\n",
      "33/33 [==============================] - 9s 244ms/step - loss: 3.7081 - mae: 7.6274e-05\n",
      "Epoch 5/50\n",
      "33/33 [==============================] - 8s 244ms/step - loss: 2.9440 - mae: 6.8850e-05\n",
      "Epoch 6/50\n",
      "33/33 [==============================] - 8s 244ms/step - loss: 2.3196 - mae: 6.1654e-05\n",
      "Epoch 7/50\n",
      "33/33 [==============================] - 9s 243ms/step - loss: 1.7686 - mae: 5.3374e-05\n",
      "Epoch 8/50\n",
      "33/33 [==============================] - 8s 244ms/step - loss: 1.3304 - mae: 4.6016e-05\n",
      "Epoch 9/50\n",
      "33/33 [==============================] - 9s 244ms/step - loss: 0.9807 - mae: 3.8273e-05\n",
      "Epoch 10/50\n",
      "33/33 [==============================] - 9s 244ms/step - loss: 0.7234 - mae: 3.1354e-05\n",
      "Epoch 11/50\n",
      "33/33 [==============================] - 8s 243ms/step - loss: 0.5378 - mae: 2.5383e-05\n",
      "Epoch 12/50\n",
      "33/33 [==============================] - 9s 244ms/step - loss: 0.4202 - mae: 2.1174e-05\n",
      "Epoch 13/50\n",
      "33/33 [==============================] - 8s 244ms/step - loss: 0.3395 - mae: 1.7844e-05\n",
      "Epoch 14/50\n",
      "33/33 [==============================] - 8s 244ms/step - loss: 0.2685 - mae: 1.4943e-05\n",
      "Epoch 15/50\n",
      "33/33 [==============================] - 9s 244ms/step - loss: 0.2239 - mae: 1.2526e-05\n",
      "Epoch 16/50\n",
      "33/33 [==============================] - 9s 244ms/step - loss: 0.2117 - mae: 1.1770e-05\n",
      "Epoch 17/50\n",
      "33/33 [==============================] - 8s 244ms/step - loss: 0.1818 - mae: 1.0478e-05\n",
      "Epoch 18/50\n",
      "33/33 [==============================] - 9s 244ms/step - loss: 0.1525 - mae: 9.0606e-06\n",
      "Epoch 19/50\n",
      "33/33 [==============================] - 8s 244ms/step - loss: 0.1353 - mae: 8.1540e-06\n",
      "Epoch 20/50\n",
      "33/33 [==============================] - 8s 244ms/step - loss: 0.1317 - mae: 7.6701e-06\n",
      "Epoch 21/50\n",
      "33/33 [==============================] - 8s 244ms/step - loss: 0.1230 - mae: 7.2868e-06\n",
      "Epoch 22/50\n",
      "33/33 [==============================] - 9s 244ms/step - loss: 0.1051 - mae: 6.3294e-06\n",
      "Epoch 23/50\n",
      "33/33 [==============================] - 8s 244ms/step - loss: 0.1004 - mae: 6.1105e-06\n",
      "Epoch 24/50\n",
      "33/33 [==============================] - 8s 244ms/step - loss: 0.1038 - mae: 5.9172e-06\n",
      "Epoch 25/50\n",
      "33/33 [==============================] - 8s 244ms/step - loss: 0.0968 - mae: 5.3146e-06\n",
      "Epoch 26/50\n",
      "33/33 [==============================] - 9s 244ms/step - loss: 0.0991 - mae: 5.4910e-06\n",
      "Epoch 27/50\n",
      "33/33 [==============================] - 8s 244ms/step - loss: 0.0975 - mae: 5.3586e-06\n",
      "Epoch 28/50\n",
      "33/33 [==============================] - 8s 244ms/step - loss: 0.0766 - mae: 4.5896e-06\n",
      "Epoch 29/50\n",
      "33/33 [==============================] - 8s 244ms/step - loss: 0.0781 - mae: 4.5466e-06\n",
      "Epoch 30/50\n",
      "33/33 [==============================] - 9s 244ms/step - loss: 0.0771 - mae: 4.5126e-06\n",
      "Epoch 31/50\n",
      "33/33 [==============================] - 8s 244ms/step - loss: 0.0685 - mae: 4.1660e-06\n",
      "Epoch 32/50\n",
      "33/33 [==============================] - 9s 244ms/step - loss: 0.0607 - mae: 3.8944e-06\n",
      "Epoch 33/50\n",
      "33/33 [==============================] - 9s 244ms/step - loss: 0.0700 - mae: 4.0039e-06\n",
      "Epoch 34/50\n",
      "33/33 [==============================] - 9s 244ms/step - loss: 0.0667 - mae: 3.9676e-06\n",
      "Epoch 35/50\n",
      "33/33 [==============================] - 8s 244ms/step - loss: 0.0710 - mae: 3.8502e-06\n",
      "Epoch 36/50\n",
      "33/33 [==============================] - 9s 244ms/step - loss: 0.0613 - mae: 3.4732e-06\n",
      "Epoch 37/50\n",
      "33/33 [==============================] - 8s 244ms/step - loss: 0.0543 - mae: 3.3447e-06\n",
      "Epoch 38/50\n",
      "33/33 [==============================] - 8s 244ms/step - loss: 0.0573 - mae: 3.4313e-06\n",
      "Epoch 39/50\n",
      "33/33 [==============================] - 8s 244ms/step - loss: 0.0599 - mae: 3.3097e-06\n",
      "Epoch 40/50\n",
      "33/33 [==============================] - 9s 244ms/step - loss: 0.0540 - mae: 3.1526e-06\n",
      "Epoch 41/50\n",
      "33/33 [==============================] - 8s 244ms/step - loss: 0.0488 - mae: 3.0055e-06\n",
      "Epoch 42/50\n",
      "33/33 [==============================] - 9s 244ms/step - loss: 0.0515 - mae: 2.9036e-06\n",
      "Epoch 43/50\n",
      "33/33 [==============================] - 9s 244ms/step - loss: 0.0515 - mae: 3.0404e-06\n",
      "Epoch 44/50\n",
      "33/33 [==============================] - 8s 245ms/step - loss: 0.0544 - mae: 3.0097e-06\n",
      "Epoch 45/50\n",
      "33/33 [==============================] - 9s 244ms/step - loss: 0.0401 - mae: 2.5364e-06\n",
      "Epoch 46/50\n",
      "33/33 [==============================] - 9s 245ms/step - loss: 0.0489 - mae: 2.6455e-06\n",
      "Epoch 47/50\n",
      "33/33 [==============================] - 8s 244ms/step - loss: 0.0471 - mae: 2.7485e-06\n",
      "Epoch 48/50\n",
      "33/33 [==============================] - 8s 244ms/step - loss: 0.0405 - mae: 2.4950e-06\n",
      "Epoch 49/50\n",
      "33/33 [==============================] - 8s 244ms/step - loss: 0.0438 - mae: 2.4439e-06\n",
      "Epoch 50/50\n",
      "33/33 [==============================] - 8s 244ms/step - loss: 0.0342 - mae: 2.2494e-06\n",
      "-----------------Model /home/sanzharrko/Рабочий стол/Atom/creation_story/models/Multi_LSTM_RNN_Model_2_books.h5 saved.-----------------\n",
      "-----------Started learning-----------\n",
      "---32/69-----------\n",
      "Number of sequences: 7709 \n",
      "\n",
      "Epoch 1/50\n",
      "33/33 [==============================] - 10s 273ms/step - loss: 8.1445 - mae: 9.5022e-05\n",
      "Epoch 2/50\n",
      "33/33 [==============================] - 9s 272ms/step - loss: 5.8739 - mae: 9.1369e-05\n",
      "Epoch 3/50\n",
      "33/33 [==============================] - 9s 273ms/step - loss: 4.9081 - mae: 8.6401e-05\n",
      "Epoch 4/50\n",
      "33/33 [==============================] - 9s 273ms/step - loss: 4.0726 - mae: 8.0729e-05\n",
      "Epoch 5/50\n",
      "33/33 [==============================] - 9s 272ms/step - loss: 3.3176 - mae: 7.4148e-05\n",
      "Epoch 6/50\n",
      "33/33 [==============================] - 10s 273ms/step - loss: 2.6650 - mae: 6.6865e-05\n",
      "Epoch 7/50\n",
      "33/33 [==============================] - 9s 273ms/step - loss: 2.1217 - mae: 6.0238e-05\n",
      "Epoch 8/50\n",
      "33/33 [==============================] - 9s 273ms/step - loss: 1.6478 - mae: 5.2190e-05\n",
      "Epoch 9/50\n",
      "33/33 [==============================] - 9s 273ms/step - loss: 1.2611 - mae: 4.4788e-05\n",
      "Epoch 10/50\n",
      "33/33 [==============================] - 9s 272ms/step - loss: 0.9129 - mae: 3.6601e-05\n",
      "Epoch 11/50\n",
      "33/33 [==============================] - 9s 273ms/step - loss: 0.7182 - mae: 3.0691e-05\n",
      "Epoch 12/50\n",
      "33/33 [==============================] - 9s 272ms/step - loss: 0.5343 - mae: 2.4718e-05\n",
      "Epoch 13/50\n",
      "33/33 [==============================] - 9s 273ms/step - loss: 0.4066 - mae: 2.0647e-05\n",
      "Epoch 14/50\n",
      "33/33 [==============================] - 9s 273ms/step - loss: 0.3513 - mae: 1.7953e-05\n",
      "Epoch 15/50\n",
      "33/33 [==============================] - 9s 273ms/step - loss: 0.2937 - mae: 1.5679e-05\n",
      "Epoch 16/50\n",
      "33/33 [==============================] - 10s 273ms/step - loss: 0.2398 - mae: 1.3324e-05\n",
      "Epoch 17/50\n",
      "33/33 [==============================] - 10s 273ms/step - loss: 0.2290 - mae: 1.2504e-05\n",
      "Epoch 18/50\n",
      "33/33 [==============================] - 9s 273ms/step - loss: 0.1927 - mae: 1.0642e-05\n",
      "Epoch 19/50\n",
      "33/33 [==============================] - 10s 273ms/step - loss: 0.1676 - mae: 9.3971e-06\n",
      "Epoch 20/50\n",
      "33/33 [==============================] - 9s 273ms/step - loss: 0.1479 - mae: 8.8070e-06\n",
      "Epoch 21/50\n",
      "33/33 [==============================] - 9s 272ms/step - loss: 0.1447 - mae: 8.4098e-06\n",
      "Epoch 22/50\n",
      "33/33 [==============================] - 9s 273ms/step - loss: 0.1329 - mae: 7.7447e-06\n",
      "Epoch 23/50\n",
      "33/33 [==============================] - 9s 273ms/step - loss: 0.1243 - mae: 6.9630e-06\n",
      "Epoch 24/50\n",
      "33/33 [==============================] - 9s 273ms/step - loss: 0.1211 - mae: 6.5997e-06\n",
      "Epoch 25/50\n",
      "33/33 [==============================] - 9s 273ms/step - loss: 0.1034 - mae: 6.2130e-06\n",
      "Epoch 26/50\n",
      "33/33 [==============================] - 10s 273ms/step - loss: 0.1043 - mae: 6.0806e-06\n",
      "Epoch 27/50\n",
      "33/33 [==============================] - 9s 273ms/step - loss: 0.0957 - mae: 5.5843e-06\n",
      "Epoch 28/50\n",
      "33/33 [==============================] - 9s 273ms/step - loss: 0.1020 - mae: 5.7589e-06\n",
      "Epoch 29/50\n",
      "33/33 [==============================] - 9s 272ms/step - loss: 0.0954 - mae: 5.2537e-06\n",
      "Epoch 30/50\n",
      "33/33 [==============================] - 10s 273ms/step - loss: 0.0847 - mae: 4.9175e-06\n",
      "Epoch 31/50\n",
      "33/33 [==============================] - 9s 273ms/step - loss: 0.0843 - mae: 4.8537e-06\n",
      "Epoch 32/50\n",
      "33/33 [==============================] - 9s 274ms/step - loss: 0.0810 - mae: 4.5695e-06\n",
      "Epoch 33/50\n",
      "33/33 [==============================] - 10s 273ms/step - loss: 0.0786 - mae: 4.3336e-06\n",
      "Epoch 34/50\n",
      "33/33 [==============================] - 9s 273ms/step - loss: 0.0637 - mae: 3.9407e-06\n",
      "Epoch 35/50\n",
      "33/33 [==============================] - 9s 273ms/step - loss: 0.0802 - mae: 4.3956e-06\n",
      "Epoch 36/50\n",
      "33/33 [==============================] - 9s 273ms/step - loss: 0.0693 - mae: 3.9672e-06\n",
      "Epoch 37/50\n",
      "33/33 [==============================] - 9s 273ms/step - loss: 0.0680 - mae: 3.9467e-06\n",
      "Epoch 38/50\n",
      "33/33 [==============================] - 9s 273ms/step - loss: 0.0666 - mae: 3.7129e-06\n",
      "Epoch 39/50\n",
      "33/33 [==============================] - 9s 272ms/step - loss: 0.0680 - mae: 3.7214e-06\n",
      "Epoch 40/50\n",
      "33/33 [==============================] - 9s 273ms/step - loss: 0.0566 - mae: 3.3745e-06\n",
      "Epoch 41/50\n",
      "33/33 [==============================] - 9s 273ms/step - loss: 0.0555 - mae: 3.2599e-06\n",
      "Epoch 42/50\n",
      "33/33 [==============================] - 10s 273ms/step - loss: 0.0639 - mae: 3.6533e-06\n",
      "Epoch 43/50\n",
      "33/33 [==============================] - 9s 272ms/step - loss: 0.0586 - mae: 3.3102e-06\n",
      "Epoch 44/50\n",
      "33/33 [==============================] - 10s 274ms/step - loss: 0.0600 - mae: 3.5045e-06\n",
      "Epoch 45/50\n",
      "33/33 [==============================] - 9s 273ms/step - loss: 0.0547 - mae: 3.0651e-06\n",
      "Epoch 46/50\n",
      "33/33 [==============================] - 9s 273ms/step - loss: 0.0485 - mae: 2.8812e-06\n",
      "Epoch 47/50\n",
      "33/33 [==============================] - 10s 273ms/step - loss: 0.0568 - mae: 3.1650e-06\n",
      "Epoch 48/50\n",
      "33/33 [==============================] - 9s 273ms/step - loss: 0.0515 - mae: 3.0659e-06\n",
      "Epoch 49/50\n",
      "33/33 [==============================] - 10s 273ms/step - loss: 0.0574 - mae: 3.1086e-06\n",
      "Epoch 50/50\n",
      "33/33 [==============================] - 10s 273ms/step - loss: 0.0479 - mae: 2.6937e-06\n",
      "-----------------Model /home/sanzharrko/Рабочий стол/Atom/creation_story/models/Multi_LSTM_RNN_Model_2_books.h5 saved.-----------------\n",
      "-----------Started learning-----------\n",
      "---33/69-----------\n",
      "Number of sequences: 11563 \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-14 18:29:02.674085: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 913384496 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-14 18:29:04.007112: I tensorflow/stream_executor/cuda/cuda_driver.cc:739] failed to allocate 343.63M (360327936 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "2022-05-14 18:29:04.007445: I tensorflow/stream_executor/cuda/cuda_driver.cc:739] failed to allocate 343.63M (360327936 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "2022-05-14 18:29:14.009011: I tensorflow/stream_executor/cuda/cuda_driver.cc:739] failed to allocate 343.63M (360327936 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "2022-05-14 18:29:14.010132: I tensorflow/stream_executor/cuda/cuda_driver.cc:739] failed to allocate 343.63M (360327936 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "2022-05-14 18:29:14.010206: W tensorflow/core/common_runtime/bfc_allocator.cc:462] Allocator (GPU_0_bfc) ran out of memory trying to allocate 141.02MiB (rounded to 147865856)requested by op CudnnRNN\n",
      "If the cause is memory fragmentation maybe the environment variable 'TF_GPU_ALLOCATOR=cuda_malloc_async' will improve the situation. \n",
      "Current allocation summary follows.\n",
      "Current allocation summary follows.\n",
      "2022-05-14 18:29:14.010240: I tensorflow/core/common_runtime/bfc_allocator.cc:1010] BFCAllocator dump for GPU_0_bfc\n",
      "2022-05-14 18:29:14.010267: I tensorflow/core/common_runtime/bfc_allocator.cc:1017] Bin (256): \tTotal Chunks: 35, Chunks in use: 35. 8.8KiB allocated for chunks. 8.8KiB in use in bin. 168B client-requested in use in bin.\n",
      "2022-05-14 18:29:14.010288: I tensorflow/core/common_runtime/bfc_allocator.cc:1017] Bin (512): \tTotal Chunks: 1, Chunks in use: 1. 768B allocated for chunks. 768B in use in bin. 712B client-requested in use in bin.\n",
      "2022-05-14 18:29:14.010309: I tensorflow/core/common_runtime/bfc_allocator.cc:1017] Bin (1024): \tTotal Chunks: 1, Chunks in use: 1. 1.2KiB allocated for chunks. 1.2KiB in use in bin. 1.0KiB client-requested in use in bin.\n",
      "2022-05-14 18:29:14.010329: I tensorflow/core/common_runtime/bfc_allocator.cc:1017] Bin (2048): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2022-05-14 18:29:14.010347: I tensorflow/core/common_runtime/bfc_allocator.cc:1017] Bin (4096): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2022-05-14 18:29:14.010368: I tensorflow/core/common_runtime/bfc_allocator.cc:1017] Bin (8192): \tTotal Chunks: 1, Chunks in use: 0. 12.8KiB allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2022-05-14 18:29:14.010395: I tensorflow/core/common_runtime/bfc_allocator.cc:1017] Bin (16384): \tTotal Chunks: 10, Chunks in use: 9. 193.0KiB allocated for chunks. 168.5KiB in use in bin. 156.2KiB client-requested in use in bin.\n",
      "2022-05-14 18:29:14.010415: I tensorflow/core/common_runtime/bfc_allocator.cc:1017] Bin (32768): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2022-05-14 18:29:14.010438: I tensorflow/core/common_runtime/bfc_allocator.cc:1017] Bin (65536): \tTotal Chunks: 3, Chunks in use: 3. 280.8KiB allocated for chunks. 280.8KiB in use in bin. 231.4KiB client-requested in use in bin.\n",
      "2022-05-14 18:29:14.010464: I tensorflow/core/common_runtime/bfc_allocator.cc:1017] Bin (131072): \tTotal Chunks: 1, Chunks in use: 0. 216.0KiB allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2022-05-14 18:29:14.010484: I tensorflow/core/common_runtime/bfc_allocator.cc:1017] Bin (262144): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2022-05-14 18:29:14.010509: I tensorflow/core/common_runtime/bfc_allocator.cc:1017] Bin (524288): \tTotal Chunks: 2, Chunks in use: 0. 1.30MiB allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2022-05-14 18:29:14.010532: I tensorflow/core/common_runtime/bfc_allocator.cc:1017] Bin (1048576): \tTotal Chunks: 8, Chunks in use: 8. 11.84MiB allocated for chunks. 11.84MiB in use in bin. 11.05MiB client-requested in use in bin.\n",
      "2022-05-14 18:29:14.010557: I tensorflow/core/common_runtime/bfc_allocator.cc:1017] Bin (2097152): \tTotal Chunks: 3, Chunks in use: 3. 6.95MiB allocated for chunks. 6.95MiB in use in bin. 4.58MiB client-requested in use in bin.\n",
      "2022-05-14 18:29:14.010579: I tensorflow/core/common_runtime/bfc_allocator.cc:1017] Bin (4194304): \tTotal Chunks: 1, Chunks in use: 1. 7.81MiB allocated for chunks. 7.81MiB in use in bin. 7.81MiB client-requested in use in bin.\n",
      "2022-05-14 18:29:14.010610: I tensorflow/core/common_runtime/bfc_allocator.cc:1017] Bin (8388608): \tTotal Chunks: 6, Chunks in use: 3. 71.22MiB allocated for chunks. 36.96MiB in use in bin. 29.40MiB client-requested in use in bin.\n",
      "2022-05-14 18:29:14.010661: I tensorflow/core/common_runtime/bfc_allocator.cc:1017] Bin (16777216): \tTotal Chunks: 13, Chunks in use: 13. 283.21MiB allocated for chunks. 283.21MiB in use in bin. 252.45MiB client-requested in use in bin.\n",
      "2022-05-14 18:29:14.010707: I tensorflow/core/common_runtime/bfc_allocator.cc:1017] Bin (33554432): \tTotal Chunks: 6, Chunks in use: 6. 219.05MiB allocated for chunks. 219.05MiB in use in bin. 190.96MiB client-requested in use in bin.\n",
      "2022-05-14 18:29:14.010733: I tensorflow/core/common_runtime/bfc_allocator.cc:1017] Bin (67108864): \tTotal Chunks: 3, Chunks in use: 2. 288.38MiB allocated for chunks. 202.69MiB in use in bin. 154.28MiB client-requested in use in bin.\n",
      "2022-05-14 18:29:14.010756: I tensorflow/core/common_runtime/bfc_allocator.cc:1017] Bin (134217728): \tTotal Chunks: 2, Chunks in use: 2. 362.12MiB allocated for chunks. 362.12MiB in use in bin. 218.16MiB client-requested in use in bin.\n",
      "2022-05-14 18:29:14.010778: I tensorflow/core/common_runtime/bfc_allocator.cc:1017] Bin (268435456): \tTotal Chunks: 3, Chunks in use: 3. 1.68GiB allocated for chunks. 1.68GiB in use in bin. 1.58GiB client-requested in use in bin.\n",
      "2022-05-14 18:29:14.010800: I tensorflow/core/common_runtime/bfc_allocator.cc:1033] Bin for 141.02MiB was 128.00MiB, Chunk State: \n",
      "2022-05-14 18:29:14.010816: I tensorflow/core/common_runtime/bfc_allocator.cc:1046] Next region of size 969295872\n",
      "2022-05-14 18:29:14.010839: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7fcf7c000000 of size 608949504 next 94\n",
      "2022-05-14 18:29:14.010856: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7fcfa04bd500 of size 120914176 next 103\n",
      "2022-05-14 18:29:14.010874: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7fcfa780d600 of size 239432192 next 18446744073709551615\n",
      "2022-05-14 18:29:14.010892: I tensorflow/core/common_runtime/bfc_allocator.cc:1046] Next region of size 1073741824\n",
      "2022-05-14 18:29:14.010910: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7fd030000000 of size 2290944 next 69\n",
      "2022-05-14 18:29:14.010926: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7fd03022f500 of size 15725824 next 123\n",
      "2022-05-14 18:29:14.010943: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7fd03112ea00 of size 2064384 next 97\n",
      "2022-05-14 18:29:14.010958: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7fd031326a00 of size 913384704 next 104\n",
      "2022-05-14 18:29:14.010975: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7fd067a38f00 of size 140275968 next 18446744073709551615\n",
      "2022-05-14 18:29:14.010994: I tensorflow/core/common_runtime/bfc_allocator.cc:1046] Next region of size 536870912\n",
      "2022-05-14 18:29:14.011010: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7fd10a000000 of size 1478656 next 120\n",
      "2022-05-14 18:29:14.011026: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7fd10a169000 of size 1478656 next 98\n",
      "2022-05-14 18:29:14.011041: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] Free  at 7fd10a2d2000 of size 9428992 next 56\n",
      "2022-05-14 18:29:14.011057: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7fd10abd0000 of size 21168128 next 55\n",
      "2022-05-14 18:29:14.011073: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7fd10c000000 of size 8192000 next 92\n",
      "2022-05-14 18:29:14.011089: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7fd10c7d0000 of size 14440192 next 83\n",
      "2022-05-14 18:29:14.011106: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7fd10d595700 of size 39496192 next 30\n",
      "2022-05-14 18:29:14.011122: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7fd10fb40100 of size 25001984 next 115\n",
      "2022-05-14 18:29:14.011138: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7fd111318100 of size 41445632 next 101\n",
      "2022-05-14 18:29:14.011156: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7fd113a9ea00 of size 91623936 next 119\n",
      "2022-05-14 18:29:14.011172: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7fd1191ffc00 of size 283116544 next 18446744073709551615\n",
      "2022-05-14 18:29:14.011189: I tensorflow/core/common_runtime/bfc_allocator.cc:1046] Next region of size 268435456\n",
      "2022-05-14 18:29:14.011210: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7fd140000000 of size 39496192 next 33\n",
      "2022-05-14 18:29:14.011250: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7fd1425aaa00 of size 29573120 next 47\n",
      "2022-05-14 18:29:14.011268: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] Free  at 7fd1441dea00 of size 12582912 next 58\n",
      "2022-05-14 18:29:14.011284: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7fd144ddea00 of size 29573120 next 77\n",
      "2022-05-14 18:29:14.011299: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7fd146a12a00 of size 1478656 next 74\n",
      "2022-05-14 18:29:14.011316: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7fd146b7ba00 of size 2715648 next 72\n",
      "2022-05-14 18:29:14.011332: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7fd146e12a00 of size 33587200 next 46\n",
      "2022-05-14 18:29:14.011347: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7fd148e1aa00 of size 29573120 next 67\n",
      "2022-05-14 18:29:14.011363: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] Free  at 7fd14aa4ea00 of size 89855488 next 18446744073709551615\n",
      "2022-05-14 18:29:14.011380: I tensorflow/core/common_runtime/bfc_allocator.cc:1046] Next region of size 134217728\n",
      "2022-05-14 18:29:14.011396: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7fd150000000 of size 1478656 next 31\n",
      "2022-05-14 18:29:14.011411: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7fd150169000 of size 1478656 next 107\n",
      "2022-05-14 18:29:14.011426: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7fd1502d2000 of size 1478656 next 84\n",
      "2022-05-14 18:29:14.011442: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7fd15043b000 of size 1478656 next 45\n",
      "2022-05-14 18:29:14.011457: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7fd1505a4000 of size 2277376 next 114\n",
      "2022-05-14 18:29:14.011474: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7fd1507d0000 of size 8585216 next 52\n",
      "2022-05-14 18:29:14.011490: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7fd151000000 of size 25001984 next 122\n",
      "2022-05-14 18:29:14.011505: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7fd1527d8000 of size 16777216 next 60\n",
      "2022-05-14 18:29:14.011522: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7fd1537d8000 of size 16777216 next 66\n",
      "2022-05-14 18:29:14.011537: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7fd1547d8000 of size 16777216 next 57\n",
      "2022-05-14 18:29:14.011556: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7fd1557d8000 of size 42106880 next 18446744073709551615\n",
      "2022-05-14 18:29:14.011573: I tensorflow/core/common_runtime/bfc_allocator.cc:1046] Next region of size 67108864\n",
      "2022-05-14 18:29:14.011589: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7fd158000000 of size 16777216 next 34\n",
      "2022-05-14 18:29:14.011609: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7fd159000000 of size 16777216 next 108\n",
      "2022-05-14 18:29:14.011626: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7fd15a000000 of size 33554432 next 18446744073709551615\n",
      "2022-05-14 18:29:14.011641: I tensorflow/core/common_runtime/bfc_allocator.cc:1046] Next region of size 67108864\n",
      "2022-05-14 18:29:14.011657: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7fd15c000000 of size 19660800 next 86\n",
      "2022-05-14 18:29:14.011674: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7fd15d2c0000 of size 33526016 next 75\n",
      "2022-05-14 18:29:14.011690: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] Free  at 7fd15f2b9100 of size 13922048 next 18446744073709551615\n",
      "2022-05-14 18:29:14.011705: I tensorflow/core/common_runtime/bfc_allocator.cc:1046] Next region of size 2097152\n",
      "2022-05-14 18:29:14.011721: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7fd1bba00000 of size 1280 next 1\n",
      "2022-05-14 18:29:14.011739: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7fd1bba00500 of size 256 next 2\n",
      "2022-05-14 18:29:14.011755: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7fd1bba00600 of size 256 next 3\n",
      "2022-05-14 18:29:14.011770: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7fd1bba00700 of size 256 next 8\n",
      "2022-05-14 18:29:14.011786: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7fd1bba00800 of size 256 next 9\n",
      "2022-05-14 18:29:14.011802: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7fd1bba00900 of size 256 next 10\n",
      "2022-05-14 18:29:14.011817: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7fd1bba00a00 of size 256 next 13\n",
      "2022-05-14 18:29:14.011833: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7fd1bba00b00 of size 256 next 16\n",
      "2022-05-14 18:29:14.011848: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7fd1bba00c00 of size 256 next 17\n",
      "2022-05-14 18:29:14.011863: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7fd1bba00d00 of size 256 next 21\n",
      "2022-05-14 18:29:14.011878: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7fd1bba00e00 of size 256 next 26\n",
      "2022-05-14 18:29:14.011893: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7fd1bba00f00 of size 256 next 25\n",
      "2022-05-14 18:29:14.011909: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7fd1bba01000 of size 256 next 32\n",
      "2022-05-14 18:29:14.011924: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7fd1bba01100 of size 256 next 27\n",
      "2022-05-14 18:29:14.011939: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7fd1bba01200 of size 256 next 24\n",
      "2022-05-14 18:29:14.011955: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7fd1bba01300 of size 256 next 61\n",
      "2022-05-14 18:29:14.011971: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7fd1bba01400 of size 256 next 20\n",
      "2022-05-14 18:29:14.011986: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7fd1bba01500 of size 256 next 11\n",
      "2022-05-14 18:29:14.012001: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7fd1bba01600 of size 256 next 37\n",
      "2022-05-14 18:29:14.012020: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7fd1bba01700 of size 256 next 38\n",
      "2022-05-14 18:29:14.012035: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7fd1bba01800 of size 256 next 39\n",
      "2022-05-14 18:29:14.012050: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7fd1bba01900 of size 256 next 40\n",
      "2022-05-14 18:29:14.012067: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7fd1bba01a00 of size 256 next 41\n",
      "2022-05-14 18:29:14.012082: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7fd1bba01b00 of size 256 next 14\n",
      "2022-05-14 18:29:14.012097: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7fd1bba01c00 of size 256 next 15\n",
      "2022-05-14 18:29:14.012114: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7fd1bba01d00 of size 256 next 105\n",
      "2022-05-14 18:29:14.012129: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7fd1bba01e00 of size 256 next 102\n",
      "2022-05-14 18:29:14.012144: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7fd1bba01f00 of size 256 next 111\n",
      "2022-05-14 18:29:14.012161: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7fd1bba02000 of size 256 next 90\n",
      "2022-05-14 18:29:14.012176: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7fd1bba02100 of size 256 next 80\n",
      "2022-05-14 18:29:14.012191: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7fd1bba02200 of size 256 next 48\n",
      "2022-05-14 18:29:14.012210: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7fd1bba02300 of size 256 next 82\n",
      "2022-05-14 18:29:14.012226: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7fd1bba02400 of size 256 next 49\n",
      "2022-05-14 18:29:14.012241: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7fd1bba02500 of size 256 next 109\n",
      "2022-05-14 18:29:14.012258: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7fd1bba02600 of size 256 next 65\n",
      "2022-05-14 18:29:14.012273: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7fd1bba02700 of size 768 next 68\n",
      "2022-05-14 18:29:14.012289: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] Free  at 7fd1bba02a00 of size 13056 next 23\n",
      "2022-05-14 18:29:14.012308: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7fd1bba05d00 of size 256 next 42\n",
      "2022-05-14 18:29:14.012324: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] Free  at 7fd1bba05e00 of size 831488 next 85\n",
      "2022-05-14 18:29:14.012341: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7fd1bbad0e00 of size 118784 next 91\n",
      "2022-05-14 18:29:14.012357: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] Free  at 7fd1bbaede00 of size 535296 next 117\n",
      "2022-05-14 18:29:14.012373: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7fd1bbb70900 of size 16384 next 96\n",
      "2022-05-14 18:29:14.012389: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7fd1bbb74900 of size 16384 next 50\n",
      "2022-05-14 18:29:14.012405: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7fd1bbb78900 of size 16384 next 93\n",
      "2022-05-14 18:29:14.012420: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7fd1bbb7c900 of size 86784 next 71\n",
      "2022-05-14 18:29:14.012440: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7fd1bbb91c00 of size 16384 next 44\n",
      "2022-05-14 18:29:14.012456: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] Free  at 7fd1bbb95c00 of size 25088 next 22\n",
      "2022-05-14 18:29:14.012472: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7fd1bbb9be00 of size 16384 next 78\n",
      "2022-05-14 18:29:14.012487: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7fd1bbb9fe00 of size 16384 next 28\n",
      "2022-05-14 18:29:14.012506: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7fd1bbba3e00 of size 81920 next 106\n",
      "2022-05-14 18:29:14.012521: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7fd1bbbb7e00 of size 16384 next 113\n",
      "2022-05-14 18:29:14.012539: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7fd1bbbbbe00 of size 28928 next 88\n",
      "2022-05-14 18:29:14.012554: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7fd1bbbc2f00 of size 28928 next 62\n",
      "2022-05-14 18:29:14.012570: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] Free  at 7fd1bbbca000 of size 221184 next 18446744073709551615\n",
      "2022-05-14 18:29:14.012589: I tensorflow/core/common_runtime/bfc_allocator.cc:1071]      Summary of in-use Chunks by size: \n",
      "2022-05-14 18:29:14.012610: I tensorflow/core/common_runtime/bfc_allocator.cc:1074] 35 Chunks of size 256 totalling 8.8KiB\n",
      "2022-05-14 18:29:14.012632: I tensorflow/core/common_runtime/bfc_allocator.cc:1074] 1 Chunks of size 768 totalling 768B\n",
      "2022-05-14 18:29:14.012650: I tensorflow/core/common_runtime/bfc_allocator.cc:1074] 1 Chunks of size 1280 totalling 1.2KiB\n",
      "2022-05-14 18:29:14.012668: I tensorflow/core/common_runtime/bfc_allocator.cc:1074] 7 Chunks of size 16384 totalling 112.0KiB\n",
      "2022-05-14 18:29:14.012686: I tensorflow/core/common_runtime/bfc_allocator.cc:1074] 2 Chunks of size 28928 totalling 56.5KiB\n",
      "2022-05-14 18:29:14.012705: I tensorflow/core/common_runtime/bfc_allocator.cc:1074] 1 Chunks of size 81920 totalling 80.0KiB\n",
      "2022-05-14 18:29:14.012723: I tensorflow/core/common_runtime/bfc_allocator.cc:1074] 1 Chunks of size 86784 totalling 84.8KiB\n",
      "2022-05-14 18:29:14.012745: I tensorflow/core/common_runtime/bfc_allocator.cc:1074] 1 Chunks of size 118784 totalling 116.0KiB\n",
      "2022-05-14 18:29:14.012762: I tensorflow/core/common_runtime/bfc_allocator.cc:1074] 7 Chunks of size 1478656 totalling 9.87MiB\n",
      "2022-05-14 18:29:14.012784: I tensorflow/core/common_runtime/bfc_allocator.cc:1074] 1 Chunks of size 2064384 totalling 1.97MiB\n",
      "2022-05-14 18:29:14.012801: I tensorflow/core/common_runtime/bfc_allocator.cc:1074] 1 Chunks of size 2277376 totalling 2.17MiB\n",
      "2022-05-14 18:29:14.012820: I tensorflow/core/common_runtime/bfc_allocator.cc:1074] 1 Chunks of size 2290944 totalling 2.18MiB\n",
      "2022-05-14 18:29:14.012837: I tensorflow/core/common_runtime/bfc_allocator.cc:1074] 1 Chunks of size 2715648 totalling 2.59MiB\n",
      "2022-05-14 18:29:14.012855: I tensorflow/core/common_runtime/bfc_allocator.cc:1074] 1 Chunks of size 8192000 totalling 7.81MiB\n",
      "2022-05-14 18:29:14.012872: I tensorflow/core/common_runtime/bfc_allocator.cc:1074] 1 Chunks of size 8585216 totalling 8.19MiB\n",
      "2022-05-14 18:29:14.012895: I tensorflow/core/common_runtime/bfc_allocator.cc:1074] 1 Chunks of size 14440192 totalling 13.77MiB\n",
      "2022-05-14 18:29:14.012913: I tensorflow/core/common_runtime/bfc_allocator.cc:1074] 1 Chunks of size 15725824 totalling 15.00MiB\n",
      "2022-05-14 18:29:14.012935: I tensorflow/core/common_runtime/bfc_allocator.cc:1074] 5 Chunks of size 16777216 totalling 80.00MiB\n",
      "2022-05-14 18:29:14.012961: I tensorflow/core/common_runtime/bfc_allocator.cc:1074] 1 Chunks of size 19660800 totalling 18.75MiB\n",
      "2022-05-14 18:29:14.013000: I tensorflow/core/common_runtime/bfc_allocator.cc:1074] 1 Chunks of size 21168128 totalling 20.19MiB\n",
      "2022-05-14 18:29:14.013039: I tensorflow/core/common_runtime/bfc_allocator.cc:1074] 2 Chunks of size 25001984 totalling 47.69MiB\n",
      "2022-05-14 18:29:14.013080: I tensorflow/core/common_runtime/bfc_allocator.cc:1074] 3 Chunks of size 29573120 totalling 84.61MiB\n",
      "2022-05-14 18:29:14.013121: I tensorflow/core/common_runtime/bfc_allocator.cc:1074] 1 Chunks of size 33526016 totalling 31.97MiB\n",
      "2022-05-14 18:29:14.013129: I tensorflow/core/common_runtime/bfc_allocator.cc:1074] 1 Chunks of size 33554432 totalling 32.00MiB\n",
      "2022-05-14 18:29:14.013137: I tensorflow/core/common_runtime/bfc_allocator.cc:1074] 1 Chunks of size 33587200 totalling 32.03MiB\n",
      "2022-05-14 18:29:14.013145: I tensorflow/core/common_runtime/bfc_allocator.cc:1074] 2 Chunks of size 39496192 totalling 75.33MiB\n",
      "2022-05-14 18:29:14.013154: I tensorflow/core/common_runtime/bfc_allocator.cc:1074] 1 Chunks of size 41445632 totalling 39.53MiB\n",
      "2022-05-14 18:29:14.013162: I tensorflow/core/common_runtime/bfc_allocator.cc:1074] 1 Chunks of size 42106880 totalling 40.16MiB\n",
      "2022-05-14 18:29:14.013170: I tensorflow/core/common_runtime/bfc_allocator.cc:1074] 1 Chunks of size 91623936 totalling 87.38MiB\n",
      "2022-05-14 18:29:14.013179: I tensorflow/core/common_runtime/bfc_allocator.cc:1074] 1 Chunks of size 120914176 totalling 115.31MiB\n",
      "2022-05-14 18:29:14.013188: I tensorflow/core/common_runtime/bfc_allocator.cc:1074] 1 Chunks of size 140275968 totalling 133.78MiB\n",
      "2022-05-14 18:29:14.013196: I tensorflow/core/common_runtime/bfc_allocator.cc:1074] 1 Chunks of size 239432192 totalling 228.34MiB\n",
      "2022-05-14 18:29:14.013204: I tensorflow/core/common_runtime/bfc_allocator.cc:1074] 1 Chunks of size 283116544 totalling 270.00MiB\n",
      "2022-05-14 18:29:14.013213: I tensorflow/core/common_runtime/bfc_allocator.cc:1074] 1 Chunks of size 608949504 totalling 580.74MiB\n",
      "2022-05-14 18:29:14.013221: I tensorflow/core/common_runtime/bfc_allocator.cc:1074] 1 Chunks of size 913384704 totalling 871.07MiB\n",
      "2022-05-14 18:29:14.013228: I tensorflow/core/common_runtime/bfc_allocator.cc:1078] Sum Total of in-use chunks: 2.79GiB\n",
      "2022-05-14 18:29:14.013235: I tensorflow/core/common_runtime/bfc_allocator.cc:1080] total_region_allocated_bytes_: 3118876672 memory_limit_: 3479204659 available bytes: 360327987 curr_region_allocation_bytes_: 4294967296\n",
      "2022-05-14 18:29:14.013244: I tensorflow/core/common_runtime/bfc_allocator.cc:1086] Stats: \n",
      "Limit:                      3479204659\n",
      "InUse:                      2991461120\n",
      "MaxInUse:                   2991461120\n",
      "NumAllocs:                    11307282\n",
      "MaxAllocSize:               1046298368\n",
      "Reserved:                            0\n",
      "PeakReserved:                        0\n",
      "LargestFreeBlock:                    0\n",
      "\n",
      "2022-05-14 18:29:14.013259: W tensorflow/core/common_runtime/bfc_allocator.cc:474] *****************************xx*********************************x***************xx*******__*********\n",
      "2022-05-14 18:29:14.013290: E tensorflow/stream_executor/dnn.cc:868] OOM when allocating tensor with shape[36966404] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n",
      "2022-05-14 18:29:14.013318: W tensorflow/core/framework/op_kernel.cc:1745] OP_REQUIRES failed at cudnn_rnn_ops.cc:1563 : INTERNAL: Failed to call ThenRnnForward with model config: [rnn_mode, rnn_input_mode, rnn_direction_mode]: 2, 0, 0 , [num_layers, input_size, num_units, dir_count, max_seq_length, batch_size, cell_num_units]: [1, 1024, 1024, 1, 20, 361, 1024] \n"
     ]
    },
    {
     "ename": "InternalError",
     "evalue": "Graph execution error:\n\nFailed to call ThenRnnForward with model config: [rnn_mode, rnn_input_mode, rnn_direction_mode]: 2, 0, 0 , [num_layers, input_size, num_units, dir_count, max_seq_length, batch_size, cell_num_units]: [1, 1024, 1024, 1, 20, 361, 1024] \n\t [[{{node CudnnRNN}}]]\n\t [[model/lstm_1/PartitionedCall]] [Op:__inference_train_function_5723]",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mInternalError\u001B[0m                             Traceback (most recent call last)",
      "Input \u001B[0;32mIn [10]\u001B[0m, in \u001B[0;36m<cell line: 12>\u001B[0;34m()\u001B[0m\n\u001B[1;32m     21\u001B[0m num_batches \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mint\u001B[39m(\u001B[38;5;28mlen\u001B[39m(X) \u001B[38;5;241m/\u001B[39m batch_size)\n\u001B[1;32m     22\u001B[0m callback \u001B[38;5;241m=\u001B[39m LambdaCallback(on_epoch_end\u001B[38;5;241m=\u001B[39mon_epoch_end)\n\u001B[0;32m---> 23\u001B[0m \u001B[43mmodel\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfit\u001B[49m\u001B[43m(\u001B[49m\u001B[43mX\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43my\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mepochs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m50\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mbatch_size\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mnum_batches\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcallbacks\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcallback\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43msave\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m)\u001B[49m\n\u001B[1;32m     24\u001B[0m count_shapes\u001B[38;5;241m.\u001B[39mappend([X\u001B[38;5;241m.\u001B[39mshape, y\u001B[38;5;241m.\u001B[39mshape])\n\u001B[1;32m     25\u001B[0m \u001B[38;5;28;01mpass\u001B[39;00m\n",
      "File \u001B[0;32m~/Рабочий стол/Atom/creation_story/src/model/rnn.py:54\u001B[0m, in \u001B[0;36mMultiLSTMModel.fit\u001B[0;34m(self, X, y, epochs, batch_size, shuffle, callbacks, save)\u001B[0m\n\u001B[1;32m     52\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mfit\u001B[39m(\u001B[38;5;28mself\u001B[39m, X, y, epochs\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m5\u001B[39m, batch_size\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m16\u001B[39m, shuffle\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mFalse\u001B[39;00m, callbacks\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m, save\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mFalse\u001B[39;00m):\n\u001B[1;32m     53\u001B[0m     epochs_on_epoch \u001B[38;5;241m=\u001B[39m LambdaCallback(on_epoch_end\u001B[38;5;241m=\u001B[39mepoch_on_epoch)\n\u001B[0;32m---> 54\u001B[0m     \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmodel\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfit\u001B[49m\u001B[43m(\u001B[49m\u001B[43mX\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43my\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mepochs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mepochs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mbatch_size\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mbatch_size\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcallbacks\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m[\u001B[49m\u001B[43mepochs_on_epoch\u001B[49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mshuffle\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mshuffle\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     55\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m save:\n\u001B[1;32m     56\u001B[0m         \u001B[38;5;28;01mtry\u001B[39;00m:\n",
      "File \u001B[0;32m~/.local/lib/python3.8/site-packages/keras/utils/traceback_utils.py:67\u001B[0m, in \u001B[0;36mfilter_traceback.<locals>.error_handler\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m     65\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mException\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m e:  \u001B[38;5;66;03m# pylint: disable=broad-except\u001B[39;00m\n\u001B[1;32m     66\u001B[0m   filtered_tb \u001B[38;5;241m=\u001B[39m _process_traceback_frames(e\u001B[38;5;241m.\u001B[39m__traceback__)\n\u001B[0;32m---> 67\u001B[0m   \u001B[38;5;28;01mraise\u001B[39;00m e\u001B[38;5;241m.\u001B[39mwith_traceback(filtered_tb) \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;28mNone\u001B[39m\n\u001B[1;32m     68\u001B[0m \u001B[38;5;28;01mfinally\u001B[39;00m:\n\u001B[1;32m     69\u001B[0m   \u001B[38;5;28;01mdel\u001B[39;00m filtered_tb\n",
      "File \u001B[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/eager/execute.py:54\u001B[0m, in \u001B[0;36mquick_execute\u001B[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001B[0m\n\u001B[1;32m     52\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m     53\u001B[0m   ctx\u001B[38;5;241m.\u001B[39mensure_initialized()\n\u001B[0;32m---> 54\u001B[0m   tensors \u001B[38;5;241m=\u001B[39m pywrap_tfe\u001B[38;5;241m.\u001B[39mTFE_Py_Execute(ctx\u001B[38;5;241m.\u001B[39m_handle, device_name, op_name,\n\u001B[1;32m     55\u001B[0m                                       inputs, attrs, num_outputs)\n\u001B[1;32m     56\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m core\u001B[38;5;241m.\u001B[39m_NotOkStatusException \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[1;32m     57\u001B[0m   \u001B[38;5;28;01mif\u001B[39;00m name \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n",
      "\u001B[0;31mInternalError\u001B[0m: Graph execution error:\n\nFailed to call ThenRnnForward with model config: [rnn_mode, rnn_input_mode, rnn_direction_mode]: 2, 0, 0 , [num_layers, input_size, num_units, dir_count, max_seq_length, batch_size, cell_num_units]: [1, 1024, 1024, 1, 20, 361, 1024] \n\t [[{{node CudnnRNN}}]]\n\t [[model/lstm_1/PartitionedCall]] [Op:__inference_train_function_5723]"
     ]
    }
   ],
   "source": [
    "def on_epoch_end(epoch, logs):\n",
    "    gc.collect()\n",
    "    k.clear_session()\n",
    "    pass\n",
    "\n",
    "\n",
    "model = MultiLSTMModel('Multi_LSTM_RNN_Model_2_books.h5', total_words, embedding_size=500)\n",
    "\n",
    "step = 1\n",
    "seq_length = 20\n",
    "count_shapes = []\n",
    "for i in range(len(text_dataframe)):\n",
    "    print(\"-----------Started learning-----------\")\n",
    "    print(fr\"---{i}/{len(text_dataframe)}-----------\")\n",
    "    X, y, num_seq = generate_sequences(token_list[i], step)\n",
    "\n",
    "\n",
    "    X = np.array(X)\n",
    "    y = np.array(y)\n",
    "    batch_size = 32\n",
    "    num_batches = int(len(X) / batch_size)\n",
    "    callback = LambdaCallback(on_epoch_end=on_epoch_end)\n",
    "    model.fit(X, y, epochs=50, batch_size=num_batches, callbacks=callback, save=True)\n",
    "    count_shapes.append([X.shape, y.shape])\n",
    "    pass\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "model.save()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "def sample_with_temp(preds, temperature=1.0):\n",
    "\n",
    "    preds = np.asarray(preds).astype('float6`4')\n",
    "    preds = np.log(preds) / temperature\n",
    "    exp_preds = np.exp(preds)\n",
    "    preds = exp_preds / np.sum(exp_preds)\n",
    "    probas = np.random.multinomial(1, preds, 1)\n",
    "    return np.argmax(probas)\n",
    "\n",
    "def generate_text(seed_text, next_words, model, max_sequence_len, temp):\n",
    "    output_text = seed_text\n",
    "\n",
    "    seed_text = start_story + seed_text\n",
    "\n",
    "    for _ in range(next_words):\n",
    "        token_list = tokenizer.texts_to_sequences([seed_text])[0]\n",
    "        token_list = token_list[-max_sequence_len:]\n",
    "        token_list = np.reshape(token_list, (1, max_sequence_len))\n",
    "\n",
    "        probs = model.model.predict(token_list, verbose=0)[0]\n",
    "        y_class = sample_with_temp(probs, temperature = temp)\n",
    "\n",
    "        if y_class == 0:\n",
    "            output_word = ''\n",
    "        else:\n",
    "            output_word = tokenizer.index_word[y_class]\n",
    "\n",
    "        if output_word == \"|\":\n",
    "            break\n",
    "\n",
    "        if token_type == 'word':\n",
    "            output_text += output_word + ' '\n",
    "            seed_text += output_word + ' '\n",
    "        else:\n",
    "            output_text += output_word + ' '\n",
    "            seed_text += output_word + ' '\n",
    "\n",
    "\n",
    "    return output_text"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [
    "\n",
    "train_model = False\n",
    "if train_model:\n",
    "    epochs = 1\n",
    "    batch_size = 32\n",
    "    num_batches = int(len(X) / batch_size)\n",
    "    callback = LambdaCallback(on_epoch_end=on_epoch_end)\n",
    "    model.fit(X, y, epochs=epochs, batch_size=batch_size, shuffle = True)\n",
    "    # model.partial_fit(X, y, epochs=epochs, batch_size=batch_size, shuffle = True)\n",
    "    model.save(os.path.dirname(os.path.abspath(os.getcwd())) + \"/models/rnn_model.h5\")\n",
    "    print(\"Model saved\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Input \u001B[0;32mIn [5]\u001B[0m, in \u001B[0;36m<cell line: 5>\u001B[0;34m()\u001B[0m\n\u001B[1;32m      2\u001B[0m gen_words \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m100\u001B[39m\n\u001B[1;32m      3\u001B[0m temp \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m1.0\u001B[39m\n\u001B[0;32m----> 5\u001B[0m \u001B[38;5;28mprint\u001B[39m (generate_text(seed_text, gen_words, \u001B[43mmodel\u001B[49m\u001B[38;5;241m.\u001B[39mmodel, seq_length, temp))\n",
      "\u001B[0;31mNameError\u001B[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "seed_text = \"When you can to say  \"\n",
    "gen_words = 100\n",
    "temp = 1.0\n",
    "\n",
    "print (generate_text(seed_text, gen_words, model.model, seq_length, temp))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}